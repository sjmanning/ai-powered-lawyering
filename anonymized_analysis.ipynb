{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Tuple, List\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from config import master_folder\n",
    "\n",
    "#Alternative master_folder import for the repository that also has non-anonymized data: \n",
    "#sys.path.append('..')\n",
    "#from config import anonymized_folder as master_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful variables and functions that will be used repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create other necessary directories\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create other necessary directories with timestamp only on analysis folder\n",
    "analysis_path = os.path.join(master_folder, \"analysis\", \"data\", f\"working_{timestamp}\")\n",
    "figures_path = os.path.join(analysis_path, \"figures\") \n",
    "tables_path = os.path.join(analysis_path, \"tables\")   \n",
    "debug_path = os.path.join(master_folder, 'analysis', 'debug')  \n",
    "\n",
    "for path in [analysis_path, figures_path, tables_path, debug_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Task descriptions used across multiple functions\n",
    "task_descriptions = {\n",
    "    1: \"Draft Client Email\",\n",
    "    2: \"Draft Legal Memo\",\n",
    "    3: \"Analysis of Complaint\",\n",
    "    4: \"Draft NDA\",\n",
    "    5: \"Draft Motion to Consolidate\",\n",
    "    6: \"Draft CNC Enforcement Letter\"\n",
    "}\n",
    "\n",
    "# Student type mapping used in balance tables and controls\n",
    "student_type_mapping = {\n",
    "    1: \"2L Student\",\n",
    "    2: \"3L Student\",\n",
    "    3: \"LLM Student\"\n",
    "}\n",
    "\n",
    "# AI use mapping used in balance tables and controls\n",
    "ai_use_mapping = {\n",
    "    1: \"0 times\",\n",
    "    2: \"1-5 times\",\n",
    "    3: \"6-10 times\",\n",
    "    4: \"11-20 times\",\n",
    "    5: \"More than 20 times\"\n",
    "}\n",
    "\n",
    "# Time columns mapping used in multiple analyses\n",
    "time_cols = {\n",
    "    1: 'Time_Spent_Assignment_1',\n",
    "    2: 'Time_Spent_Assignment_2',\n",
    "    3: 'Time_Spent_Assignment_3',\n",
    "    4: 'Time_Spent_Assignment_4',\n",
    "    5: 'Time_Spent_Assignment_5',\n",
    "    6: 'Time_Spent_Assignment_6'\n",
    "}\n",
    "\n",
    "# Dictionary for mapping outcome variables with standardized column names\n",
    "outcome_mappings = {\n",
    "    'Accuracy': {i: f'P{i}_Criteria_1_Accuracy' for i in range(1, 7)},\n",
    "    'Analysis': {i: f'P{i}_Criteria_2_Analysis' for i in range(1, 7)},\n",
    "    'Organization': {i: f'P{i}_Criteria_3_Organization' for i in range(1, 7)},\n",
    "    'Clarity': {i: f'P{i}_Criteria_4_Clarity' for i in range(1, 7)},\n",
    "    'Professionalism': {i: f'P{i}_Criteria_5_Professionalism' for i in range(1, 7)},\n",
    "    'Total Score': {i: f'P{i}_Total_Score' for i in range(1, 7)},\n",
    "    'Time Spent': {i: f'Time_Spent_Assignment_{i}' for i in range(1, 7)},\n",
    "    'Productivity': {i: f'P{i}_Productivity' for i in range(1, 7)}\n",
    "}\n",
    "\n",
    "\n",
    "# Commonly used formatting functions\n",
    "def format_coefficient(coef, se, pval):\n",
    "    \"\"\"Format coefficient with stars and standard error.\"\"\"\n",
    "    stars = ''\n",
    "    if pval < 0.01:\n",
    "        stars = '^{***}'\n",
    "    elif pval < 0.05:\n",
    "        stars = '^{**}'\n",
    "    elif pval < 0.1:\n",
    "        stars = '^{*}'\n",
    "    return f\"${coef:.2f}{stars}$\", f\"(${se:.2f}$)\"\n",
    "\n",
    "def format_pct_change(pct_change):\n",
    "    \"\"\"Format percentage change with explicit plus sign for positive values.\"\"\"\n",
    "    if pct_change is None or pd.isna(pct_change):\n",
    "        return \"N/A\"\n",
    "    sign = '+' if pct_change > 0 else ''\n",
    "    return f\"${sign}{pct_change:.1f}\\\\%$\"\n",
    "\n",
    "def setup_plot_style():\n",
    "    \"\"\"Configure a consistent plot style.\"\"\"\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'figure.figsize': (10, 8),\n",
    "        'axes.grid': True,\n",
    "        'grid.color': 'lightgray',\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.alpha': 0.5,\n",
    "        'axes.axisbelow': True\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Student identifiers with the group assignment file so we can get each observations group assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name matching report saved as 'C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\name_matching_report.xlsx'.\n",
      "\n",
      "Total students in time_spent file: 153\n",
      "Successfully matched with groups: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_51124\\4283168432.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  report_df['Matched'] = report_df['group'].notna()\n"
     ]
    }
   ],
   "source": [
    "time_file_path = os.path.join(master_folder, \"Time Spent on Assignments completed 12.3.24 ac.xlsx\")\n",
    "group_file_path = os.path.join(master_folder, \"Group Assignments.xlsx\")\n",
    "\n",
    "time_df = pd.read_excel(time_file_path)\n",
    "group_df = pd.read_excel(group_file_path)\n",
    "\n",
    "# Merge the dataframes directly using student name columns\n",
    "merged_df = time_df.merge(\n",
    "    group_df[['Q5', 'group']], \n",
    "    left_on='Student name',\n",
    "    right_on='Q5',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Remove the redundant Q5 column\n",
    "merged_df = merged_df.drop('Q5', axis=1)\n",
    "\n",
    "# Create a basic matching report\n",
    "report_df = merged_df[['Student name', 'group']]\n",
    "report_df['Matched'] = report_df['group'].notna()\n",
    "\n",
    "# Save the report as an Excel file instead of CSV\n",
    "#report_output_path = os.path.join(master_folder, \"name_matching_report.xlsx\")\n",
    "#report_df.to_excel(report_output_path, index=False)\n",
    "#print(f\"Name matching report saved as '{report_output_path}'.\")\n",
    "\n",
    "# Check for any unmatched students\n",
    "unmatched = merged_df[merged_df['group'].isna()]\n",
    "if len(unmatched) > 0:\n",
    "    print(\"\\nUnmatched students:\")\n",
    "    print(unmatched[['Student name']])\n",
    "\n",
    "# Display matching statistics\n",
    "print(f\"\\nTotal students in time_spent file: {len(time_df)}\")\n",
    "print(f\"Successfully matched with groups: {len(merged_df.dropna(subset=['group']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n",
      "C    51\n",
      "A    51\n",
      "B    51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count observations in each group\n",
    "print(merged_df['group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in all of the grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4 columns after first renaming: ['Student #', 'Criteria 1', 'Criteria 2', 'Criteria 3', 'Criteria 4', 'Criteria 5', 'Total Score', 'Grade', 'Hallucination', 'Notes', 'Unnamed: 10']\n",
      "\n",
      "Problem 4 columns after rename_grade_columns: ['Student #', 'P4_Criteria 1', 'P4_Criteria 2', 'P4_Criteria 3', 'P4_Criteria 4', 'P4_Criteria 5', 'P4_Total Score', 'P4_Grade', 'P4_Hallucination', 'P4_Notes', 'P4_Unnamed: 10']\n",
      "\n",
      "Relevant columns in final_df:\n",
      "['P4_Criteria 1', 'P4_Criteria 2', 'P4_Criteria 3', 'P4_Criteria 4', 'P4_Criteria 5', 'P4_Total Score', 'P4_Grade', 'P4_Hallucination', 'P4_Notes', 'P4_Unnamed: 10']\n",
      "\n",
      "Final dataset shape: (154, 73)\n",
      "\n",
      "Number of students with grades:\n",
      "Problem 1: 145 students\n",
      "Problem 2: 125 students\n",
      "Problem 3: 127 students\n",
      "Problem 4: 128 students\n",
      "Problem 5: 127 students\n",
      "Problem 6: 127 students\n",
      "\n",
      "First few rows of final dataset:\n",
      "     Student Number      Student name  Completion of Experiment  \\\n",
      "0  c1f9916910cd4128  c1f9916910cd4128                       0.0   \n",
      "1  7316aefcd59a0b74  7316aefcd59a0b74                       0.0   \n",
      "2  1167a8417b14a001  1167a8417b14a001                       0.0   \n",
      "3  ec2ed9ca82601e42  ec2ed9ca82601e42                       NaN   \n",
      "4  5eb1b92aee244e2a  5eb1b92aee244e2a                       0.0   \n",
      "\n",
      "   Time Spent on Assignment One (4177421)  \\\n",
      "0                                    60.0   \n",
      "1                                    40.0   \n",
      "2                                    49.0   \n",
      "3                                     NaN   \n",
      "4                                    37.0   \n",
      "\n",
      "   Time Spent on Assignment Two (4177422)  \\\n",
      "0                                   240.0   \n",
      "1                                    53.0   \n",
      "2                                    42.0   \n",
      "3                                     NaN   \n",
      "4                                   190.0   \n",
      "\n",
      "   Time Spent on Assignment Three (4177428)  \\\n",
      "0                                     120.0   \n",
      "1                                      42.0   \n",
      "2                                      45.0   \n",
      "3                                       NaN   \n",
      "4                                      95.0   \n",
      "\n",
      "   Time Spent on Assignment Four (4177442)  \\\n",
      "0                                     90.0   \n",
      "1                                     45.0   \n",
      "2                                     88.0   \n",
      "3                                      NaN   \n",
      "4                                    125.0   \n",
      "\n",
      "   Time Spent on Assignment Five (4177448)  \\\n",
      "0                                     75.0   \n",
      "1                                     29.0   \n",
      "2                                     47.0   \n",
      "3                                      NaN   \n",
      "4                                    112.0   \n",
      "\n",
      "   Time Spent on Assignment Six (4177449) group  ... P6_Organization  \\\n",
      "0                                   150.0     C  ...             4.0   \n",
      "1                                    48.0     A  ...             7.0   \n",
      "2                                    74.0     A  ...             5.0   \n",
      "3                                     NaN     A  ...             NaN   \n",
      "4                                   110.0     A  ...             4.0   \n",
      "\n",
      "  P6_Clarity P6_Professionalism P6_Total Score P6_Grade P6_Hallucination  \\\n",
      "0        5.0                3.0             18        B              NaN   \n",
      "1        7.0                7.0             34        A              NaN   \n",
      "2        5.0                5.0             25       B+              NaN   \n",
      "3        NaN                NaN                     NaN              NaN   \n",
      "4        3.0                3.0             15       B-              NaN   \n",
      "\n",
      "  P6_Hallu_note P6_Notes P6_Unnamed: 11 P6_Unnamed: 12  \n",
      "0           NaN      NaN        33-35=A            NaN  \n",
      "1           NaN      NaN       28-32=A-            NaN  \n",
      "2           NaN      NaN       23-27=B+            NaN  \n",
      "3           NaN      NaN        18-22=B            NaN  \n",
      "4           NaN      NaN       13-17=B-            NaN  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read all grading sheets\n",
    "problems = {}\n",
    "for i in range(1, 7):\n",
    "    file_suffix = \"_12-8-2024\" if i == 2 else \"_12-8-24\" if i == 5 else \"\"\n",
    "    problems[i] = pd.read_excel(f\"{master_folder}/Grading Sheet Vincent v.1 Problem {i}{file_suffix}.xlsx\")\n",
    "\n",
    "# Rename Problem 4's specific columns\n",
    "problem4_rename = {\n",
    "    'Criteria 1: Accuracy: How accurate and legally sound was your drafting of the nondisclosure agreement? ': 'Criteria 1',\n",
    "    'Criteria 2: Analysis: How sound and thoughtful was your approach to the drafting and enforceability of the NDA? ': 'Criteria 2',\n",
    "    'Criteria 3: Organization: How well-organized and structured was your NDA draft?\\n': 'Criteria 3',\n",
    "    'Criteria 4: Clarity: How clear and readable was your NDA?': 'Criteria 4',\n",
    "    'Criteria 5: Professionalism: How well did you follow the assignments instructions and professional drafting standards?': 'Criteria 5'\n",
    "}\n",
    "problems[4] = problems[4].rename(columns=problem4_rename)\n",
    "\n",
    "print(\"Problem 4 columns after first renaming:\", problems[4].columns.tolist())\n",
    "\n",
    "# Rename all columns to include problem number\n",
    "def rename_grade_columns(df, problem_num):\n",
    "    return df.rename(columns={col: f'P{problem_num}_{col}' for col in df.columns if col != 'Student #'})\n",
    "\n",
    "# Apply renaming to all problems\n",
    "problems = {num: rename_grade_columns(df, num) for num, df in problems.items()}\n",
    "\n",
    "print(\"\\nProblem 4 columns after rename_grade_columns:\", problems[4].columns.tolist())\n",
    "\n",
    "# Merge all datasets\n",
    "final_df = merged_df.copy()\n",
    "for i in range(1, 7):\n",
    "    final_df = final_df.merge(problems[i], left_on='Student Number', right_on='Student #', how='left')\n",
    "    final_df = final_df.drop('Student #', axis=1)\n",
    "\n",
    "# Print diagnostics\n",
    "print(\"\\nRelevant columns in final_df:\")\n",
    "p4_cols = [col for col in final_df.columns if 'P4_' in col]\n",
    "print(p4_cols)\n",
    "\n",
    "print(\"\\nFinal dataset shape:\", final_df.shape)\n",
    "print(\"\\nNumber of students with grades:\")\n",
    "for i in range(1, 7):\n",
    "    grade_col = f'P{i}_Grade'\n",
    "    print(f\"Problem {i}: {final_df[grade_col].notna().sum()} students\")\n",
    "\n",
    "print(\"\\nFirst few rows of final dataset:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bit more cleaning\n",
    "final_df = final_df.drop(['P1_Unnamed: 11', 'P3_Column 1', 'P4_Unnamed: 10', 'P6_Unnamed: 11', 'P6_Unnamed: 12'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dfs for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing task dataframes...\n",
      "\n",
      "Processing Task 1:\n",
      "Total rows: 153\n",
      "AI Condition distribution:\n",
      "AI_Condition\n",
      "Vincent    51\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Name: count, dtype: int64\n",
      "Saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808/task1_data.csv\n",
      "\n",
      "Processing Task 2:\n",
      "Total rows: 153\n",
      "AI Condition distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "No AI      51\n",
      "Name: count, dtype: int64\n",
      "Saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808/task2_data.csv\n",
      "\n",
      "Processing Task 3:\n",
      "Total rows: 153\n",
      "AI Condition distribution:\n",
      "AI_Condition\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "Saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808/task3_data.csv\n",
      "\n",
      "Processing Task 4:\n",
      "Total rows: 153\n",
      "AI Condition distribution:\n",
      "AI_Condition\n",
      "Vincent    51\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Name: count, dtype: int64\n",
      "Saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808/task4_data.csv\n",
      "\n",
      "Processing Task 5:\n",
      "Total rows: 153\n",
      "AI Condition distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "No AI      51\n",
      "Name: count, dtype: int64\n",
      "Saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808/task5_data.csv\n",
      "\n",
      "Processing Task 6:\n",
      "Total rows: 153\n",
      "AI Condition distribution:\n",
      "AI_Condition\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "Saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808/task6_data.csv\n",
      "\n",
      "Verification after processing:\n",
      "Task counts:\n",
      "Task 1:\n",
      "  Total rows: 153\n",
      "  Students with AI condition: 153\n",
      "  Duplicate student numbers: 0\n",
      "  AI Condition distribution:\n",
      "AI_Condition\n",
      "Vincent    51\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Task 2:\n",
      "  Total rows: 153\n",
      "  Students with AI condition: 153\n",
      "  Duplicate student numbers: 0\n",
      "  AI Condition distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "No AI      51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Task 3:\n",
      "  Total rows: 153\n",
      "  Students with AI condition: 153\n",
      "  Duplicate student numbers: 0\n",
      "  AI Condition distribution:\n",
      "AI_Condition\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Task 4:\n",
      "  Total rows: 153\n",
      "  Students with AI condition: 153\n",
      "  Duplicate student numbers: 0\n",
      "  AI Condition distribution:\n",
      "AI_Condition\n",
      "Vincent    51\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Task 5:\n",
      "  Total rows: 153\n",
      "  Students with AI condition: 153\n",
      "  Duplicate student numbers: 0\n",
      "  AI Condition distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "No AI      51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Task 6:\n",
      "  Total rows: 153\n",
      "  Students with AI condition: 153\n",
      "  Duplicate student numbers: 0\n",
      "  AI Condition distribution:\n",
      "AI_Condition\n",
      "No AI      51\n",
      "GPT 01     51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Clean up group values before processing\n",
    "final_df['group'] = final_df['group'].apply(lambda x: str(x).strip().upper() if pd.notna(x) else x)\n",
    "\n",
    "# Modified function to handle NaN and invalid groups\n",
    "def get_ai_condition(group, task_num):\n",
    "    conditions = {\n",
    "        1: {'A': 'No AI', 'B': 'GPT 01', 'C': 'Vincent'},\n",
    "        2: {'A': 'Vincent', 'B': 'No AI', 'C': 'GPT 01'},\n",
    "        3: {'A': 'GPT 01', 'B': 'Vincent', 'C': 'No AI'},\n",
    "        4: {'A': 'No AI', 'B': 'GPT 01', 'C': 'Vincent'},\n",
    "        5: {'A': 'Vincent', 'B': 'No AI', 'C': 'GPT 01'},\n",
    "        6: {'A': 'GPT 01', 'B': 'Vincent', 'C': 'No AI'}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if pd.isna(group):\n",
    "            return np.nan\n",
    "        group_str = str(group).strip().upper()\n",
    "        if group_str not in ['A', 'B', 'C']:\n",
    "            print(f\"Warning: Invalid group value found: {group}\")\n",
    "            return np.nan\n",
    "        return conditions[task_num][group_str]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {group} for task {task_num}: {str(e)}\")\n",
    "        return np.nan\n",
    "\n",
    "# Remove duplicates from final_df first, keeping the first occurrence\n",
    "final_df = final_df.drop_duplicates(subset=['Student Number'], keep='first')\n",
    "\n",
    "print(\"\\nProcessing task dataframes...\")\n",
    "\n",
    "# Function to create task dataframe\n",
    "def create_task_df(task_num, time_col):\n",
    "    task_cols = ['Student Number'] + [col for col in final_df.columns if f'P{task_num}_' in col] + [time_col, 'group']\n",
    "    task_df = final_df[task_cols].copy()\n",
    "    task_df['AI_Condition'] = task_df['group'].apply(lambda x: get_ai_condition(x, task_num))\n",
    "    return task_df\n",
    "\n",
    "# Create all task dataframes\n",
    "task_dfs = {}\n",
    "time_columns = {\n",
    "    1: 'Time Spent on Assignment One (4177421)',\n",
    "    2: 'Time Spent on Assignment Two (4177422)',\n",
    "    3: 'Time Spent on Assignment Three (4177428)',\n",
    "    4: 'Time Spent on Assignment Four (4177442)',\n",
    "    5: 'Time Spent on Assignment Five (4177448)',\n",
    "    6: 'Time Spent on Assignment Six (4177449)'\n",
    "}\n",
    "\n",
    "for task_num in range(1, 7):\n",
    "    print(f\"\\nProcessing Task {task_num}:\")\n",
    "    task_df = create_task_df(task_num, time_columns[task_num])\n",
    "    task_dfs[task_num] = task_df\n",
    "    \n",
    "    # Print diagnostics for each task\n",
    "    print(f\"Total rows: {len(task_df)}\")\n",
    "    print(\"AI Condition distribution:\")\n",
    "    print(task_df['AI_Condition'].value_counts(dropna=False))\n",
    "    \n",
    "    # Save the dataframe\n",
    "    output_path = f\"{analysis_path}/task{task_num}_data.csv\"\n",
    "    task_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved to: {output_path}\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\nVerification after processing:\")\n",
    "print(\"Task counts:\")\n",
    "for task_num in range(1, 7):\n",
    "    task_df = task_dfs[task_num]\n",
    "    print(f\"Task {task_num}:\")\n",
    "    print(f\"  Total rows: {len(task_df)}\")\n",
    "    print(f\"  Students with AI condition: {task_df['AI_Condition'].notna().sum()}\")\n",
    "    print(f\"  Duplicate student numbers: {task_df['Student Number'].duplicated().sum()}\")\n",
    "    print(\"  AI Condition distribution:\")\n",
    "    print(task_df['AI_Condition'].value_counts(dropna=False))\n",
    "    print()\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students without groups:\n",
      "[]\n",
      "\n",
      "Sample data for students without groups:\n",
      "Empty DataFrame\n",
      "Columns: [Student Number, Student name, Completion of Experiment, Time Spent on Assignment One (4177421), Time Spent on Assignment Two (4177422), Time Spent on Assignment Three (4177428), Time Spent on Assignment Four (4177442), Time Spent on Assignment Five (4177448), Time Spent on Assignment Six (4177449), group, P1_Accuracy, P1_Analysis, P1_Organization, P1_Clarity, P1_Professionalism, P1_Total #, P1_Grade, P1_Hallucination, P1_Hallu_note, P1_Notes, P2_Criteria 1, P2_Criteria 2, P2_Criteria 3, P2_Criteria 4, P2_Criteria 5, P2_Total Score, P2_Grade, P2_Hallucination, P2_Hallu_note, P2_Notes, P3_Criteria 1: Accuracy, P3_Criteria 2: Analysis, P3_Criteria 3: Organization, P3_Criteria 4: Clarity, P3_Criteria 5: Professionalism, P3_Total Score, P3_Grade, P3_Hallucination, P3_Notes, P4_Criteria 1, P4_Criteria 2, P4_Criteria 3, P4_Criteria 4, P4_Criteria 5, P4_Total Score, P4_Grade, P4_Hallucination, P4_Notes, P5_Criteria 1, P5_Criteria 2, P5_Criteria 3, P5_Criteria 4, P5_Criteria 5, P5_Total Score, P5_Grade, P5_Hallucination, P5_Hallu_note, P5_Notes, P6_Accuracy, P6_Analysis, P6_Organization, P6_Clarity, P6_Professionalism, P6_Total Score, P6_Grade, P6_Hallucination, P6_Hallu_note, P6_Notes]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify students with missing groups\n",
    "students_without_groups = final_df[final_df['group'].isna()]\n",
    "\n",
    "print(\"Students without groups:\")\n",
    "print(students_without_groups['Student Number'].tolist())\n",
    "\n",
    "# Check if these students have any data\n",
    "print(\"\\nSample data for students without groups:\")\n",
    "print(students_without_groups.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure outcome variable data is ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data processing and distribution analysis...\n",
      "\n",
      "Initial distribution analysis:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: task1_data.csv\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: task2_data.csv\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: task3_data.csv\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: task4_data.csv\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: task5_data.csv\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: task6_data.csv\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Processing task DataFrames:\n",
      "\n",
      "Processing Task 1 Data:\n",
      "==================================================\n",
      "\n",
      "Before conversion:\n",
      "Student_Number                    object\n",
      "P1_Criteria_1_Accuracy            object\n",
      "P1_Criteria_2_Analysis            object\n",
      "P1_Criteria_3_Organization        object\n",
      "P1_Criteria_4_Clarity             object\n",
      "P1_Criteria_5_Professionalism     object\n",
      "P1_Total_Score                    object\n",
      "P1_Grade                          object\n",
      "P1_Hallucination                  object\n",
      "P1_Hallucination_Note             object\n",
      "P1_Notes                          object\n",
      "Time_Spent_Assignment_1          float64\n",
      "Group                             object\n",
      "AI_Condition                      object\n",
      "dtype: object\n",
      "\n",
      "Unique values in P1_Criteria_1_Accuracy:\n",
      "['2' '6' nan '5' '1' '4' '7' ' ' '3']\n",
      "\n",
      "Unique values in P1_Criteria_2_Analysis:\n",
      "['2' '6' nan '4' '5' '3' '7' ' ' '1']\n",
      "\n",
      "Unique values in P1_Criteria_3_Organization:\n",
      "['3' '2' '7' nan '5' '4' '6' ' ' '1']\n",
      "\n",
      "Unique values in P1_Criteria_4_Clarity:\n",
      "['3' '2' '7' nan '6' '4' '5' ' ' '1']\n",
      "\n",
      "Unique values in P1_Criteria_5_Professionalism:\n",
      "['6' '3' nan '2' '4' '5' '7' ' ' '1']\n",
      "\n",
      "Unique values in P1_Total_Score:\n",
      "['16' '11' '32' ' ' '10' '24' '14' '26' '19' '30' '22' '31' '33' '17' '18'\n",
      " '20' '23' '15' '29' '25' '21' '28' '8' '12' '27' '5' '13' '7' '9' nan '0']\n",
      "\n",
      "Distributions after processing:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: Task 1 (After Processing)\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "Group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "Group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "Saved processed data to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task1_data_numeric.csv\n",
      "\n",
      "Processing Task 2 Data:\n",
      "==================================================\n",
      "\n",
      "Before conversion:\n",
      "Student_Number                    object\n",
      "P2_Criteria_1_Accuracy           float64\n",
      "P2_Criteria_2_Analysis           float64\n",
      "P2_Criteria_3_Organization       float64\n",
      "P2_Criteria_4_Clarity            float64\n",
      "P2_Criteria_5_Professionalism    float64\n",
      "P2_Total_Score                   float64\n",
      "P2_Grade                          object\n",
      "P2_Hallucination                 float64\n",
      "P2_Hallucination_Note             object\n",
      "P2_Notes                          object\n",
      "Time_Spent_Assignment_2          float64\n",
      "Group                             object\n",
      "AI_Condition                      object\n",
      "dtype: object\n",
      "\n",
      "Distributions after processing:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: Task 2 (After Processing)\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "Group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "Group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "Saved processed data to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task2_data_numeric.csv\n",
      "\n",
      "Processing Task 3 Data:\n",
      "==================================================\n",
      "\n",
      "Before conversion:\n",
      "Student_Number                    object\n",
      "P3_Criteria_1_Accuracy           float64\n",
      "P3_Criteria_2_Analysis           float64\n",
      "P3_Criteria_3_Organization       float64\n",
      "P3_Criteria_4_Clarity            float64\n",
      "P3_Criteria_5_Professionalism    float64\n",
      "P3_Total_Score                   float64\n",
      "P3_Grade                          object\n",
      "P3_Hallucination                 float64\n",
      "P3_Notes                          object\n",
      "Time_Spent_Assignment_3          float64\n",
      "Group                             object\n",
      "AI_Condition                      object\n",
      "dtype: object\n",
      "\n",
      "Distributions after processing:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: Task 3 (After Processing)\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "Group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "Group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "Saved processed data to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task3_data_numeric.csv\n",
      "\n",
      "Processing Task 4 Data:\n",
      "==================================================\n",
      "\n",
      "Before conversion:\n",
      "Student_Number                    object\n",
      "P4_Criteria_1_Accuracy           float64\n",
      "P4_Criteria_2_Analysis           float64\n",
      "P4_Criteria_3_Organization       float64\n",
      "P4_Criteria_4_Clarity            float64\n",
      "P4_Criteria_5_Professionalism    float64\n",
      "P4_Total_Score                   float64\n",
      "P4_Grade                          object\n",
      "P4_Hallucination                 float64\n",
      "P4_Notes                          object\n",
      "Time_Spent_Assignment_4          float64\n",
      "Group                             object\n",
      "AI_Condition                      object\n",
      "dtype: object\n",
      "\n",
      "Distributions after processing:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: Task 4 (After Processing)\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "Group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "Group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "Saved processed data to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task4_data_numeric.csv\n",
      "\n",
      "Processing Task 5 Data:\n",
      "==================================================\n",
      "\n",
      "Before conversion:\n",
      "Student_Number                    object\n",
      "P5_Criteria_1_Accuracy           float64\n",
      "P5_Criteria_2_Analysis           float64\n",
      "P5_Criteria_3_Organization       float64\n",
      "P5_Criteria_4_Clarity            float64\n",
      "P5_Criteria_5_Professionalism    float64\n",
      "P5_Total_Score                   float64\n",
      "P5_Grade                          object\n",
      "P5_Hallucination                  object\n",
      "P5_Hallucination_Note             object\n",
      "P5_Notes                          object\n",
      "Time_Spent_Assignment_5          float64\n",
      "Group                             object\n",
      "AI_Condition                      object\n",
      "dtype: object\n",
      "\n",
      "Distributions after processing:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: Task 5 (After Processing)\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "Group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "Group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "Saved processed data to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task5_data_numeric.csv\n",
      "\n",
      "Processing Task 6 Data:\n",
      "==================================================\n",
      "\n",
      "Before conversion:\n",
      "Student_Number                    object\n",
      "P6_Criteria_1_Accuracy           float64\n",
      "P6_Criteria_2_Analysis           float64\n",
      "P6_Criteria_3_Organization       float64\n",
      "P6_Criteria_4_Clarity            float64\n",
      "P6_Criteria_5_Professionalism    float64\n",
      "P6_Total_Score                    object\n",
      "P6_Grade                          object\n",
      "P6_Hallucination                 float64\n",
      "P6_Hallucination_Note             object\n",
      "P6_Notes                          object\n",
      "Time_Spent_Assignment_6          float64\n",
      "Group                             object\n",
      "AI_Condition                      object\n",
      "dtype: object\n",
      "\n",
      "Unique values in P6_Total_Score:\n",
      "['18' '34' '25' ' ' '15' '27' '20' '29' '31' '11' '28' '33' '12' '23' '10'\n",
      " '8' '21' '7' '14' '13' '16' '19' '24' '32' '17' '30' '26' '6' '9' '22'\n",
      " nan]\n",
      "\n",
      "Distributions after processing:\n",
      "\n",
      "==================================================\n",
      "Distribution Analysis for: Task 6 (After Processing)\n",
      "Total rows: 153\n",
      "\n",
      "Group Distribution:\n",
      "Group\n",
      "A    51\n",
      "B    51\n",
      "C    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Group Distribution (Percentages):\n",
      "Group\n",
      "A    33.33\n",
      "B    33.33\n",
      "C    33.33\n",
      "Name: count, dtype: float64\n",
      "\n",
      "AI_Condition Distribution:\n",
      "AI_Condition\n",
      "GPT 01     51\n",
      "No AI      51\n",
      "Vincent    51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AI_Condition Distribution (Percentages):\n",
      "AI_Condition\n",
      "GPT 01     33.33\n",
      "No AI      33.33\n",
      "Vincent    33.33\n",
      "Name: count, dtype: float64\n",
      "Saved processed data to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task6_data_numeric.csv\n",
      "\n",
      "Conversion and distribution analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Define column mapping\n",
    "col_mapping = {\n",
    "    # Student Info\n",
    "    \"Student Number\": \"Student_Number\",\n",
    "    \"group\": \"Group\",\n",
    "    \"AI_Condition\": \"AI_Condition\",\n",
    "    \n",
    "    # Task 1\n",
    "    \"P1_Accuracy\": \"P1_Criteria_1_Accuracy\",\n",
    "    \"P1_Analysis\": \"P1_Criteria_2_Analysis\", \n",
    "    \"P1_Organization\": \"P1_Criteria_3_Organization\",\n",
    "    \"P1_Clarity\": \"P1_Criteria_4_Clarity\",\n",
    "    \"P1_Professionalism\": \"P1_Criteria_5_Professionalism\",\n",
    "    \"P1_Total #\": \"P1_Total_Score\",\n",
    "    \"P1_Grade\": \"P1_Grade\",\n",
    "    \"P1_Hallu?\": \"P1_Hallucination\",\n",
    "    \"P1_Hallu_note\": \"P1_Hallucination_Note\",\n",
    "    \"P1_Notes\": \"P1_Notes\",\n",
    "    \"Time Spent on Assignment One (4177421)\": \"Time_Spent_Assignment_1\",\n",
    "    \n",
    "    # Task 2\n",
    "    \"P2_Criteria 1\": \"P2_Criteria_1_Accuracy\",\n",
    "    \"P2_Criteria 2\": \"P2_Criteria_2_Analysis\",\n",
    "    \"P2_Criteria 3\": \"P2_Criteria_3_Organization\",\n",
    "    \"P2_Criteria 4\": \"P2_Criteria_4_Clarity\",\n",
    "    \"P2_Criteria 5\": \"P2_Criteria_5_Professionalism\",\n",
    "    \"P2_Total Score\": \"P2_Total_Score\",\n",
    "    \"P2_Grade\": \"P2_Grade\",\n",
    "    \"P2_Hallucination\": \"P2_Hallucination\",\n",
    "    \"P2_Hallu_note\": \"P2_Hallucination_Note\",\n",
    "    \"P2_Notes\": \"P2_Notes\",\n",
    "    \"Time Spent on Assignment Two (4177422)\": \"Time_Spent_Assignment_2\",\n",
    "    \n",
    "    # Task 3\n",
    "    \"P3_Criteria 1: Accuracy\": \"P3_Criteria_1_Accuracy\",\n",
    "    \"P3_Criteria 2: Analysis\": \"P3_Criteria_2_Analysis\",\n",
    "    \"P3_Criteria 3: Organization\": \"P3_Criteria_3_Organization\",\n",
    "    \"P3_Criteria 4: Clarity\": \"P3_Criteria_4_Clarity\",\n",
    "    \"P3_Criteria 5: Professionalism\": \"P3_Criteria_5_Professionalism\",\n",
    "    \"P3_Total Score\": \"P3_Total_Score\",\n",
    "    \"P3_Grade\": \"P3_Grade\",\n",
    "    \"P3_Hallucination\": \"P3_Hallucination\",\n",
    "    \"P3_Notes\": \"P3_Notes\",\n",
    "    \"Time Spent on Assignment Three (4177428)\": \"Time_Spent_Assignment_3\",\n",
    "    \n",
    "    # Task 4\n",
    "    \"P4_Criteria 1\": \"P4_Criteria_1_Accuracy\",\n",
    "    \"P4_Criteria 2\": \"P4_Criteria_2_Analysis\",\n",
    "    \"P4_Criteria 3\": \"P4_Criteria_3_Organization\",\n",
    "    \"P4_Criteria 4\": \"P4_Criteria_4_Clarity\",\n",
    "    \"P4_Criteria 5\": \n",
    "        \"P4_Criteria_5_Professionalism\",\n",
    "    \"P4_Total Score\": \"P4_Total_Score\",\n",
    "    \"P4_Grade\": \"P4_Grade\",\n",
    "    \"P4_Hallucination\": \"P4_Hallucination\",\n",
    "    \"P4_Notes\": \"P4_Notes\",\n",
    "    \"Time Spent on Assignment Four (4177442)\": \"Time_Spent_Assignment_4\",\n",
    "    \n",
    "    # Task 5\n",
    "    \"P5_Criteria 1\": \"P5_Criteria_1_Accuracy\",\n",
    "    \"P5_Criteria 2\": \"P5_Criteria_2_Analysis\",\n",
    "    \"P5_Criteria 3\": \"P5_Criteria_3_Organization\",\n",
    "    \"P5_Criteria 4\": \"P5_Criteria_4_Clarity\",\n",
    "    \"P5_Criteria 5\": \"P5_Criteria_5_Professionalism\",\n",
    "    \"P5_Total Score\": \"P5_Total_Score\",\n",
    "    \"P5_Grade\": \"P5_Grade\",\n",
    "    \"P5_Hallucination\": \"P5_Hallucination\",\n",
    "    \"P5_Hallu_note\": \"P5_Hallucination_Note\",\n",
    "    \"P5_Notes\": \"P5_Notes\",\n",
    "    \"Time Spent on Assignment Five (4177448)\": \"Time_Spent_Assignment_5\",\n",
    "    \n",
    "    # Task 6\n",
    "    \"P6_Accuracy\": \"P6_Criteria_1_Accuracy\",\n",
    "    \"P6_Analysis\": \"P6_Criteria_2_Analysis\",\n",
    "    \"P6_Organization\": \"P6_Criteria_3_Organization\",\n",
    "    \"P6_Clarity\": \"P6_Criteria_4_Clarity\",\n",
    "    \"P6_Professionalism\": \"P6_Criteria_5_Professionalism\",\n",
    "    \"P6_Total Score\": \"P6_Total_Score\",\n",
    "    \"P6_Grade\": \"P6_Grade\",\n",
    "    \"P6_Hallucination\": \"P6_Hallucination\",\n",
    "    \"P6_Hallu_note\": \"P6_Hallucination_Note\",\n",
    "    \"P6_Notes\": \"P6_Notes\",\n",
    "    \"Time Spent on Assignment Six (4177449)\": \"Time_Spent_Assignment_6\"\n",
    "}\n",
    "\n",
    "def analyze_group_distribution(df, file_name):\n",
    "    \"\"\"Analyze and print the distribution of Group and AI_Condition columns.\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Distribution Analysis for: {file_name}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    \n",
    "    # Analyze Group distribution\n",
    "    if 'group' in df.columns or 'Group' in df.columns:\n",
    "        group_col = 'group' if 'group' in df.columns else 'Group'\n",
    "        print(\"\\nGroup Distribution:\")\n",
    "        group_dist = df[group_col].value_counts(dropna=False).sort_index()\n",
    "        print(group_dist)\n",
    "        print(\"\\nGroup Distribution (Percentages):\")\n",
    "        print((group_dist / len(df) * 100).round(2))\n",
    "    \n",
    "    # Analyze AI_Condition distribution\n",
    "    if 'AI_Condition' in df.columns:\n",
    "        print(\"\\nAI_Condition Distribution:\")\n",
    "        ai_dist = df['AI_Condition'].value_counts(dropna=False).sort_index()\n",
    "        print(ai_dist)\n",
    "        print(\"\\nAI_Condition Distribution (Percentages):\")\n",
    "        print((ai_dist / len(df) * 100).round(2))\n",
    "\n",
    "def convert_to_numeric(df):\n",
    "    \"\"\"\n",
    "    Converts columns to numeric, skipping certain columns.\n",
    "    \"\"\"\n",
    "    skip_list = ['Group', 'AI_Condition', 'Grade', 'Hallucination', 'Note', 'Notes', 'Email', 'Student']\n",
    "    \n",
    "    df_converted = df.copy()\n",
    "    for col in df_converted.columns:\n",
    "        if not any(skip in col for skip in skip_list):\n",
    "            df_converted[col] = pd.to_numeric(df_converted[col], errors='coerce')\n",
    "    return df_converted\n",
    "\n",
    "def check_before_conversion(df):\n",
    "    \"\"\"Check and print column types and unique values before conversion.\"\"\"\n",
    "    print(\"\\nBefore conversion:\")\n",
    "    print(df.dtypes)\n",
    "    object_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in object_cols:\n",
    "        if not any(skip in col for skip in ['Group', 'AI_Condition', 'Grade', 'Hallucination', 'Note', 'Notes', 'Email', 'Student']):\n",
    "            print(f\"\\nUnique values in {col}:\")\n",
    "            print(df[col].unique())\n",
    "\n",
    "def robust_rename_columns(df):\n",
    "    \"\"\"Apply column renaming with special handling for problematic columns.\"\"\"\n",
    "    # First, handle the problematic P4 column specifically\n",
    "    p4_prof_col = [col for col in df.columns if \"P4_Criteria 5\" in col and \"Professionalism\" in col]\n",
    "    if p4_prof_col:\n",
    "        df = df.rename(columns={p4_prof_col[0]: \"P4_Criteria_5_Professionalism\"})\n",
    "    \n",
    "    # Then apply the standard mapping for other columns\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main processing\n",
    "print(\"\\nStarting data processing and distribution analysis...\")\n",
    "\n",
    "# Get list of CSV files\n",
    "csv_files = [f for f in os.listdir(analysis_path) if f.endswith('.csv')]\n",
    "dataframes = []\n",
    "\n",
    "# First pass: Load and analyze distributions\n",
    "print(\"\\nInitial distribution analysis:\")\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(analysis_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    analyze_group_distribution(df, file)\n",
    "    \n",
    "    # Apply the robust renaming function instead of direct renaming\n",
    "    df = robust_rename_columns(df)\n",
    "    \n",
    "    dataframes.append(df)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Second pass: Process each task DataFrame\n",
    "print(\"\\nProcessing task DataFrames:\")\n",
    "for i, df in enumerate(dataframes, 1):\n",
    "    print(f\"\\nProcessing Task {i} Data:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check data before conversion\n",
    "    check_before_conversion(df)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    converted_df = convert_to_numeric(df)\n",
    "    \n",
    "    # Calculate productivity\n",
    "    total_score_col = f\"P{i}_Total_Score\"\n",
    "    time_spent_col = f\"Time_Spent_Assignment_{i}\"\n",
    "    productivity_col = f\"P{i}_Productivity\"\n",
    "    \n",
    "    if total_score_col in converted_df.columns and time_spent_col in converted_df.columns:\n",
    "        converted_df[productivity_col] = converted_df[total_score_col] / converted_df[time_spent_col]\n",
    "    \n",
    "    # Show distributions after processing\n",
    "    print(\"\\nDistributions after processing:\")\n",
    "    analyze_group_distribution(converted_df, f\"Task {i} (After Processing)\")\n",
    "    \n",
    "    # Save the converted dataframe\n",
    "    out_path = os.path.join(analysis_path, f\"task{i}_data_numeric.csv\")\n",
    "    converted_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved processed data to: {out_path}\")\n",
    "\n",
    "print(\"\\nConversion and distribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 before filtering - Count: 153\n",
      "Rows with Total Score = 0: 1\n",
      "Found 1 rows with exact zero Total Score in task 1:\n",
      "     P1_Total_Score    Student_Number\n",
      "152             0.0  a067276138a65c6a\n",
      "Verification passed: No zero values remain in the dataset.\n",
      "Task 1: Cleaned data saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task1_data_cleaned.csv\n",
      "Original rows: 153, Cleaned rows: 135\n",
      "Removed rows: 18\n",
      "--------------------------------------------------\n",
      "Task 2 before filtering - Count: 153\n",
      "Rows with Total Score = 0: 1\n",
      "Found 1 rows with exact zero Total Score in task 2:\n",
      "     P2_Total_Score    Student_Number\n",
      "142             0.0  d8bb952342c588bb\n",
      "Verification passed: No zero values remain in the dataset.\n",
      "Task 2: Cleaned data saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task2_data_cleaned.csv\n",
      "Original rows: 153, Cleaned rows: 125\n",
      "Removed rows: 28\n",
      "--------------------------------------------------\n",
      "Task 3 before filtering - Count: 153\n",
      "Rows with Total Score = 0: 0\n",
      "Verification passed: No zero values remain in the dataset.\n",
      "Task 3: Cleaned data saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task3_data_cleaned.csv\n",
      "Original rows: 153, Cleaned rows: 127\n",
      "Removed rows: 26\n",
      "--------------------------------------------------\n",
      "Task 4 before filtering - Count: 153\n",
      "Rows with Total Score = 0: 0\n",
      "Verification passed: No zero values remain in the dataset.\n",
      "Task 4: Cleaned data saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task4_data_cleaned.csv\n",
      "Original rows: 153, Cleaned rows: 127\n",
      "Removed rows: 26\n",
      "--------------------------------------------------\n",
      "Task 5 before filtering - Count: 153\n",
      "Rows with Total Score = 0: 0\n",
      "Verification passed: No zero values remain in the dataset.\n",
      "Task 5: Cleaned data saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task5_data_cleaned.csv\n",
      "Original rows: 153, Cleaned rows: 127\n",
      "Removed rows: 26\n",
      "--------------------------------------------------\n",
      "Task 6 before filtering - Count: 153\n",
      "Rows with Total Score = 0: 0\n",
      "Verification passed: No zero values remain in the dataset.\n",
      "Task 6: Cleaned data saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\task6_data_cleaned.csv\n",
      "Original rows: 153, Cleaned rows: 126\n",
      "Removed rows: 27\n",
      "--------------------------------------------------\n",
      "Cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over tasks 1-6\n",
    "for i in range(1, 7):\n",
    "    file_path = os.path.join(analysis_path, f\"task{i}_data_numeric.csv\")\n",
    "    cleaned_file_path = os.path.join(analysis_path, f\"task{i}_data_cleaned.csv\")\n",
    "    \n",
    "    try:\n",
    "        # Load the numeric dataset\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Define the total score column name\n",
    "        total_score_col = f\"P{i}_Total_Score\"\n",
    "        \n",
    "        # Store original row count\n",
    "        original_count = len(df)\n",
    "        \n",
    "        # Make sure the total score column is numeric\n",
    "        df[total_score_col] = pd.to_numeric(df[total_score_col], errors='coerce')\n",
    "        \n",
    "        # Print initial stats\n",
    "        print(f\"Task {i} before filtering - Count: {len(df)}\")\n",
    "        print(f\"Rows with Total Score = 0: {len(df[df[total_score_col] == 0])}\")\n",
    "        \n",
    "        # First check: Find problematic rows with exact zero values and print them\n",
    "        zero_rows = df[df[total_score_col] == 0]\n",
    "        if len(zero_rows) > 0:\n",
    "            print(f\"Found {len(zero_rows)} rows with exact zero Total Score in task {i}:\")\n",
    "            print(zero_rows[[total_score_col, 'Student_Number']].head())\n",
    "        \n",
    "        # Drop rows where P{i}_Total_Score is NaN\n",
    "        df_cleaned = df.dropna(subset=[total_score_col])\n",
    "        \n",
    "        # Explicitly filter out EXACT zero values using boolean indexing\n",
    "        # This should catch any value that is precisely 0 (integer or float)\n",
    "        df_cleaned = df_cleaned[df_cleaned[total_score_col] != 0]\n",
    "        \n",
    "        # Extra safety: Also filter out any near-zero values\n",
    "        threshold = 1e-6\n",
    "        df_cleaned = df_cleaned[df_cleaned[total_score_col] > threshold]\n",
    "        \n",
    "        # Verification step after filtering\n",
    "        zero_check = df_cleaned[df_cleaned[total_score_col] == 0]\n",
    "        if len(zero_check) > 0:\n",
    "            print(f\"WARNING: Still found {len(zero_check)} zero values after filtering!\")\n",
    "            print(zero_check[[total_score_col, 'Student_Number']].head())\n",
    "        else:\n",
    "            print(f\"Verification passed: No zero values remain in the dataset.\")\n",
    "        \n",
    "        # Save the cleaned dataset\n",
    "        df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "        \n",
    "        print(f\"Task {i}: Cleaned data saved to {cleaned_file_path}\")\n",
    "        print(f\"Original rows: {original_count}, Cleaned rows: {len(df_cleaned)}\")\n",
    "        print(f\"Removed rows: {original_count - len(df_cleaned)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find file {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing task {i}: {str(e)}\")\n",
    "\n",
    "print(\"Cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: No zero values in Total Score column. Data is clean.\n",
      "Task 1: Min Total Score = 5.0\n",
      "Task 1: Number of rows = 135\n",
      "--------------------------------------------------\n",
      "Task 2: No zero values in Total Score column. Data is clean.\n",
      "Task 2: Min Total Score = 5.0\n",
      "Task 2: Number of rows = 125\n",
      "--------------------------------------------------\n",
      "Task 3: No zero values in Total Score column. Data is clean.\n",
      "Task 3: Min Total Score = 7.0\n",
      "Task 3: Number of rows = 127\n",
      "--------------------------------------------------\n",
      "Task 4: No zero values in Total Score column. Data is clean.\n",
      "Task 4: Min Total Score = 12.0\n",
      "Task 4: Number of rows = 127\n",
      "--------------------------------------------------\n",
      "Task 5: No zero values in Total Score column. Data is clean.\n",
      "Task 5: Min Total Score = 2.0\n",
      "Task 5: Number of rows = 127\n",
      "--------------------------------------------------\n",
      "Task 6: No zero values in Total Score column. Data is clean.\n",
      "Task 6: Min Total Score = 6.0\n",
      "Task 6: Number of rows = 126\n",
      "--------------------------------------------------\n",
      "All tasks checked. No zero values found in any Total Score columns.\n"
     ]
    }
   ],
   "source": [
    "# Assuming analysis_path is defined\n",
    "zero_scores_found = False\n",
    "\n",
    "for i in range(1, 7):\n",
    "    cleaned_file_path = os.path.join(analysis_path, f\"task{i}_data_cleaned.csv\")\n",
    "    \n",
    "    try:\n",
    "        # Load the cleaned dataset\n",
    "        task_df = pd.read_csv(cleaned_file_path)\n",
    "        \n",
    "        # Check for zero values in Total Score column\n",
    "        zero_scores = task_df[task_df[f\"P{i}_Total_Score\"] == 0]\n",
    "        zero_count = len(zero_scores)\n",
    "        \n",
    "        if zero_count > 0:\n",
    "            zero_scores_found = True\n",
    "            print(f\"Task {i}: Found {zero_count} rows with zero Total Score!\")\n",
    "            print(zero_scores.head())  # Show the first few problematic rows\n",
    "        else:\n",
    "            print(f\"Task {i}: No zero values in Total Score column. Data is clean.\")\n",
    "        \n",
    "        # Additional validation stats\n",
    "        print(f\"Task {i}: Min Total Score = {task_df[f'P{i}_Total_Score'].min()}\")\n",
    "        print(f\"Task {i}: Number of rows = {len(task_df)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find cleaned file {cleaned_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking task {i}: {str(e)}\")\n",
    "\n",
    "if not zero_scores_found:\n",
    "    print(\"All tasks checked. No zero values found in any Total Score columns.\")\n",
    "else:\n",
    "    print(\"WARNING: Zero values found in some Total Score columns! Check the logs above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now going to create a table that shows the differences in productivity for each of the six tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\productivity_treatment_effects_with_pct.tex\n",
      "\n",
      "Treatment Effects on Task Productivity\n",
      "=====================================\n",
      "\n",
      "Draft Client Email:\n",
      "Control Mean: $0.393$ points per minute\n",
      "Vincent: $0.216^{***}$ ($0.055$) (+$55.0\\%$ change) | N = 134\n",
      "o1-preview: $0.135^{***}$ ($0.047$) (+$34.3\\%$ change) | N = 134\n",
      "\n",
      "Draft Legal Memo:\n",
      "Control Mean: $0.100$ points per minute\n",
      "Vincent: $0.058^{***}$ ($0.018$) (+$57.4\\%$ change) | N = 124\n",
      "o1-preview: $0.074^{***}$ ($0.021$) (+$73.5\\%$ change) | N = 124\n",
      "\n",
      "Analysis of Complaint:\n",
      "Control Mean: $0.238$ points per minute\n",
      "Vincent: $0.273^{***}$ ($0.058$) (+$114.6\\%$ change) | N = 126\n",
      "o1-preview: $0.206^{***}$ ($0.047$) (+$86.7\\%$ change) | N = 126\n",
      "\n",
      "Draft NDA:\n",
      "Control Mean: $0.373$ points per minute\n",
      "Vincent: $0.070$ ($0.070$) (+$18.7\\%$ change) | N = 127\n",
      "o1-preview: $0.038$ ($0.060$) (+$10.3\\%$ change) | N = 127\n",
      "\n",
      "Draft Motion to Consolidate:\n",
      "Control Mean: $0.235$ points per minute\n",
      "Vincent: $0.090^{*}$ ($0.048$) (+$38.3\\%$ change) | N = 127\n",
      "o1-preview: $0.172^{***}$ ($0.062$) (+$73.3\\%$ change) | N = 127\n",
      "\n",
      "Draft CNC Enforcement Letter:\n",
      "Control Mean: $0.193$ points per minute\n",
      "Vincent: $0.158^{***}$ ($0.043$) (+$82.1\\%$ change) | N = 126\n",
      "o1-preview: $0.271^{***}$ ($0.087$) (+$140.5\\%$ change) | N = 126\n"
     ]
    }
   ],
   "source": [
    "# Load the updated task DataFrames from the saved numeric files\n",
    "task_dfs = {}\n",
    "for task_num in range(1, 7):\n",
    "    file_path = os.path.join(analysis_path, f\"task{task_num}_data_cleaned.csv\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        task_dfs[task_num] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}. Skipping task {task_num}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}. Skipping task {task_num}.\")\n",
    "        continue\n",
    "\n",
    "def extract_treatment_effects(task_num, outcome):\n",
    "    \"\"\"Extract treatment effects for a given task and outcome variable.\"\"\"\n",
    "    \n",
    "    # Ensure task data exists\n",
    "    if task_num not in task_dfs:\n",
    "        raise ValueError(f\"Data for task {task_num} is not available.\")\n",
    "\n",
    "    df = task_dfs[task_num].copy()\n",
    "\n",
    "    # Check required columns\n",
    "    required_cols = ['AI_Condition', outcome]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns {missing_cols} in task {task_num} data.\")\n",
    "\n",
    "    # Create dummy variables for AI conditions\n",
    "    df['Vincent_dummy'] = (df['AI_Condition'] == 'Vincent').astype(int)\n",
    "    df['GPT01_dummy'] = (df['AI_Condition'] == 'GPT 01').astype(int)\n",
    "\n",
    "    # Drop rows with missing outcome values\n",
    "    df_clean = df.dropna(subset=[outcome])\n",
    "    if df_clean.empty:\n",
    "        raise ValueError(f\"No data available for outcome '{outcome}' in task {task_num}.\")\n",
    "\n",
    "    # Prepare regression inputs\n",
    "    X = sm.add_constant(df_clean[['Vincent_dummy', 'GPT01_dummy']])\n",
    "    y = df_clean[outcome]\n",
    "\n",
    "    # Fit model\n",
    "    try:\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit(cov_type='HC1')\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error fitting model for task {task_num} and outcome '{outcome}': {e}\")\n",
    "\n",
    "    # Compute control group mean\n",
    "    control_group = df_clean[df_clean['AI_Condition'] == 'No AI']\n",
    "    if control_group.empty:\n",
    "        raise ValueError(f\"No control group ('No AI') data found for task {task_num}.\")\n",
    "    control_mean = control_group[outcome].mean()\n",
    "\n",
    "    # Calculate percent change while handling division by zero\n",
    "    pct_change_vincent = (results.params['Vincent_dummy'] / control_mean) * 100 if control_mean else np.nan\n",
    "    pct_change_gpt = (results.params['GPT01_dummy'] / control_mean) * 100 if control_mean else np.nan\n",
    "\n",
    "    sample_size = len(df_clean)\n",
    "\n",
    "    # Construct results dictionary\n",
    "    vincent_effect = {\n",
    "        'coef': results.params['Vincent_dummy'],\n",
    "        'se': results.bse['Vincent_dummy'],\n",
    "        'pval': results.pvalues['Vincent_dummy'],\n",
    "        'pct_change': pct_change_vincent,\n",
    "        'N': sample_size\n",
    "    }\n",
    "\n",
    "    gpt_effect = {\n",
    "        'coef': results.params['GPT01_dummy'],\n",
    "        'se': results.bse['GPT01_dummy'],\n",
    "        'pval': results.pvalues['GPT01_dummy'],\n",
    "        'pct_change': pct_change_gpt,\n",
    "        'N': sample_size\n",
    "    }\n",
    "\n",
    "    return vincent_effect, gpt_effect, control_mean, sample_size\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# Loop over tasks to extract treatment effects and compile results\n",
    "for task_num in range(1, 7):\n",
    "    outcome = f'P{task_num}_Productivity'\n",
    "    try:\n",
    "        vincent_effect, gpt_effect, control_mean, sample_size = extract_treatment_effects(task_num, outcome)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping task {task_num} due to error: {e}\")\n",
    "        continue\n",
    "    \n",
    "    def format_coef(coef, pval):\n",
    "        stars = ''\n",
    "        if pval < 0.01:\n",
    "            stars = '^{***}'\n",
    "        elif pval < 0.05:\n",
    "            stars = '^{**}'\n",
    "        elif pval < 0.1:\n",
    "            stars = '^{*}'\n",
    "        return f\"${coef:.3f}{stars}$\"\n",
    "    \n",
    "    # Append Vincent's results\n",
    "    results_data.append({\n",
    "        'Task': task_descriptions.get(task_num, f\"Task {task_num}\"),\n",
    "        'Control Mean': f\"${control_mean:.3f}$\",\n",
    "        'Model': 'Vincent',\n",
    "        'Effect': format_coef(vincent_effect['coef'], vincent_effect['pval']),\n",
    "        'SE': f\"(${vincent_effect['se']:.3f}$)\",\n",
    "        'Pct Change': f\"+${vincent_effect['pct_change']:.1f}\\\\%$\" if not pd.isna(vincent_effect['pct_change']) else \"N/A\",\n",
    "        'N': sample_size\n",
    "    })\n",
    "    \n",
    "    # Append GPT-01's results\n",
    "    results_data.append({\n",
    "        'Task': task_descriptions.get(task_num, f\"Task {task_num}\"),\n",
    "        'Control Mean': f\"${control_mean:.3f}$\",\n",
    "        'Model': 'o1-preview',\n",
    "        'Effect': format_coef(gpt_effect['coef'], gpt_effect['pval']),\n",
    "        'SE': f\"(${gpt_effect['se']:.3f}$)\",\n",
    "        'Pct Change': f\"+${gpt_effect['pct_change']:.1f}\\\\%$\" if not pd.isna(gpt_effect['pct_change']) else \"N/A\",\n",
    "        'N': sample_size\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Generate LaTeX table string with the correct number of columns (7)\n",
    "latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "latex_table += \"\\\\caption{Treatment Effects on Task Productivity (Points per Minute)}\\n\"\n",
    "latex_table += \"\\\\label{tab:productivity_effects}\\n\"\n",
    "latex_table += \"\\\\begin{tabular}{lcccccc}\\n\"  # Now 7 columns: l c c c c c c\n",
    "latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "latex_table += \"Task & Control Mean & Model & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "# Loop over tasks to create table rows\n",
    "for task in task_descriptions.values():\n",
    "    task_rows = results_df[results_df['Task'] == task]\n",
    "    if task_rows.empty:\n",
    "        continue\n",
    "    first_row = True\n",
    "    for _, row in task_rows.iterrows():\n",
    "        if first_row:\n",
    "            latex_table += f\"\\\\multirow{{2}}{{*}}{{{row['Task']}}} & \"\n",
    "            latex_table += f\"\\\\multirow{{2}}{{*}}{{{row['Control Mean']}}} \"\n",
    "            first_row = False\n",
    "        else:\n",
    "            latex_table += \"& \"\n",
    "        latex_table += f\"& {row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "latex_table += (\"\\\\multicolumn{7}{p{0.95\\\\linewidth}}{\\\\footnotesize \\\\textit{Notes:} \"\n",
    "                \"Effects shown as absolute increase in points per minute relative to No AI control group. \"\n",
    "                \"Percent changes calculated relative to control group mean. \"\n",
    "                \"Robust standard errors in parentheses. \"\n",
    "                \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$. Sample size (N) represents the number of observations used in the regression.}\\n\")\n",
    "latex_table += \"\\\\end{tabular}\\n\"\n",
    "latex_table += \"\\\\end{table}\"\n",
    "\n",
    "# Save LaTeX table to file with the specified path\n",
    "table_file_path = os.path.join(tables_path, \"productivity_treatment_effects_with_pct.tex\")\n",
    "try:\n",
    "    with open(table_file_path, \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "    print(f\"\\nTable saved to: {table_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving LaTeX table: {e}\")\n",
    "\n",
    "# Print a readable version of the results\n",
    "print(\"\\nTreatment Effects on Task Productivity\")\n",
    "print(\"=====================================\")\n",
    "for task_num in range(1, 7):\n",
    "    task_name = task_descriptions.get(task_num)\n",
    "    if task_name not in results_df['Task'].unique():\n",
    "        continue\n",
    "    task_rows = results_df[results_df['Task'] == task_name]\n",
    "    print(f\"\\n{task_name}:\")\n",
    "    print(f\"Control Mean: {task_rows['Control Mean'].iloc[0]} points per minute\")\n",
    "    for _, row in task_rows.iterrows():\n",
    "        print(f\"{row['Model']}: {row['Effect']} {row['SE']} ({row['Pct Change']} change) | N = {row['N']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the other outcome variables to create results tables for each on each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating table for Accuracy...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\accuracy_effects.tex\n",
      "\n",
      "Generating table for Analysis...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\analysis_effects.tex\n",
      "\n",
      "Generating table for Organization...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\organization_effects.tex\n",
      "\n",
      "Generating table for Clarity...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\clarity_effects.tex\n",
      "\n",
      "Generating table for Professionalism...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\professionalism_effects.tex\n",
      "\n",
      "Generating table for Total Score...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\total_score_effects.tex\n",
      "\n",
      "Generating table for Time Spent...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\time_spent_effects.tex\n",
      "\n",
      "Generating table for Productivity...\n",
      "Table saved: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\productivity_effects.tex\n",
      "✅ All outcome tables have been generated and saved.\n"
     ]
    }
   ],
   "source": [
    "# Load task dataframes\n",
    "task_dfs = {i: pd.read_csv(os.path.join(analysis_path, f\"task{i}_data_cleaned.csv\")) for i in range(1, 7)}\n",
    "\n",
    "def create_outcome_tables():\n",
    "    for outcome in outcome_mappings.keys():\n",
    "        print(f\"\\nGenerating table for {outcome}...\")\n",
    "\n",
    "        results_data = []\n",
    "\n",
    "        for task_num in range(1, 7):\n",
    "            outcome_var = outcome_mappings[outcome][task_num]\n",
    "            vincent_effect, gpt_effect, control_mean, sample_size = extract_treatment_effects(task_num, outcome_var)\n",
    "\n",
    "            def format_coef(coef, pval):\n",
    "                stars = ''\n",
    "                if pval < 0.01:\n",
    "                    stars = '^{***}'\n",
    "                elif pval < 0.05:\n",
    "                    stars = '^{**}'\n",
    "                elif pval < 0.1:\n",
    "                    stars = '^{*}'\n",
    "                return f\"${coef:.3f}{stars}$\"\n",
    "\n",
    "            results_data.append({\n",
    "                'Task': task_descriptions[task_num],\n",
    "                'Control Mean': f\"${control_mean:.3f}$\",\n",
    "                'Model': 'Vincent',\n",
    "                'Effect': format_coef(vincent_effect['coef'], vincent_effect['pval']),\n",
    "                'SE': f\"(${vincent_effect['se']:.3f}$)\",\n",
    "                'Pct Change': format_pct_change(vincent_effect['pct_change']),\n",
    "                'N': sample_size\n",
    "            })\n",
    "\n",
    "            results_data.append({\n",
    "                'Task': task_descriptions[task_num],\n",
    "                'Control Mean': f\"${control_mean:.3f}$\",\n",
    "                'Model': 'o1-preview',\n",
    "                'Effect': format_coef(gpt_effect['coef'], gpt_effect['pval']),\n",
    "                'SE': f\"(${gpt_effect['se']:.3f}$)\",\n",
    "                'Pct Change': format_pct_change(gpt_effect['pct_change']),\n",
    "                'N': sample_size\n",
    "            })\n",
    "\n",
    "        results_df = pd.DataFrame(results_data)\n",
    "\n",
    "        # Generate LaTeX table\n",
    "        latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "        latex_table += f\"\\\\caption{{Treatment Effects on {outcome} Across Tasks}}\\n\"\n",
    "        latex_table += f\"\\\\label{{tab:{outcome.lower().replace(' ', '_')}_effects}}\\n\"\n",
    "        latex_table += \"\\\\begin{tabular}{lcccccc}\\n\"\n",
    "        latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "        latex_table += \"Task & Control Mean & Model & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "        for task in task_descriptions.values():\n",
    "            task_rows = results_df[results_df['Task'] == task]\n",
    "            first_row = True\n",
    "            for _, row in task_rows.iterrows():\n",
    "                if first_row:\n",
    "                    latex_table += f\"\\\\multirow{{2}}{{*}}{{{row['Task']}}} & \"\n",
    "                    latex_table += f\"\\\\multirow{{2}}{{*}}{{{row['Control Mean']}}} \"\n",
    "                    first_row = False\n",
    "                else:\n",
    "                    latex_table += \"& \"\n",
    "                latex_table += f\"& {row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "            latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "        latex_table += \"\\\\multicolumn{7}{p{0.95\\\\linewidth}}{\\\\footnotesize \\\\textit{Notes:} \"\n",
    "        latex_table += \"Effects shown as absolute increase relative to No AI control group. \"\n",
    "        latex_table += \"Percent changes calculated relative to control group mean. \"\n",
    "        latex_table += \"Robust standard errors in parentheses. \"\n",
    "        latex_table += \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$. Sample size (N) represents the number of observations used in the regression.}\\n\"\n",
    "        latex_table += \"\\\\end{tabular}\\n\"\n",
    "        latex_table += \"\\\\end{table}\"\n",
    "\n",
    "        # Save LaTeX table to file\n",
    "        table_file_path = os.path.join(tables_path, f\"{outcome.lower().replace(' ', '_')}_effects.tex\")\n",
    "        with open(table_file_path, \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "\n",
    "        print(f\"Table saved: {table_file_path}\")\n",
    "\n",
    "# Run the function to generate all outcome tables\n",
    "create_outcome_tables()\n",
    "\n",
    "print(\"✅ All outcome tables have been generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming analysis_path is defined\n",
    "task1_df = pd.read_csv(os.path.join(analysis_path, \"task1_data_cleaned.csv\"))\n",
    "task2_df = pd.read_csv(os.path.join(analysis_path, \"task2_data_cleaned.csv\"))\n",
    "task3_df = pd.read_csv(os.path.join(analysis_path, \"task3_data_cleaned.csv\"))\n",
    "task4_df = pd.read_csv(os.path.join(analysis_path, \"task4_data_cleaned.csv\"))\n",
    "task5_df = pd.read_csv(os.path.join(analysis_path, \"task5_data_cleaned.csv\"))\n",
    "task6_df = pd.read_csv(os.path.join(analysis_path, \"task6_data_cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating table for Task 1: Draft Client Email\n",
      "Table saved as task1_all_effects.tex\n",
      "\n",
      "Generating table for Task 2: Draft Legal Memo\n",
      "Table saved as task2_all_effects.tex\n",
      "\n",
      "Generating table for Task 3: Analysis of Complaint\n",
      "Table saved as task3_all_effects.tex\n",
      "\n",
      "Generating table for Task 4: Draft NDA\n",
      "Table saved as task4_all_effects.tex\n",
      "\n",
      "Generating table for Task 5: Draft Motion to Consolidate\n",
      "Table saved as task5_all_effects.tex\n",
      "\n",
      "Generating table for Task 6: Draft CNC Enforcement Letter\n",
      "Table saved as task6_all_effects.tex\n"
     ]
    }
   ],
   "source": [
    "def format_effect(coef, pval):\n",
    "    stars = get_stars(pval)\n",
    "    if stars:\n",
    "        return f\"${coef:.2f}^{{{stars}}}$\"\n",
    "    else:\n",
    "        return f\"${coef:.2f}$\"\n",
    "\n",
    "def create_task_table(task_num, task_name):\n",
    "    # List of outcomes including Productivity\n",
    "    outcomes = ['Accuracy', 'Analysis', 'Organization', 'Clarity', 'Professionalism',\n",
    "                'Total Score', 'Time Spent', 'Productivity']\n",
    "\n",
    "    results_data = []\n",
    "\n",
    "    # Get all outcome columns for this task\n",
    "    outcome_cols = {\n",
    "        'Accuracy': outcome_mappings['Accuracy'][task_num],\n",
    "        'Analysis': outcome_mappings['Analysis'][task_num],\n",
    "        'Organization': outcome_mappings['Organization'][task_num],\n",
    "        'Clarity': outcome_mappings['Clarity'][task_num],\n",
    "        'Professionalism': outcome_mappings['Professionalism'][task_num],\n",
    "        'Total Score': outcome_mappings['Total Score'][task_num],\n",
    "        'Time Spent': outcome_mappings['Time Spent'][task_num],\n",
    "        'Productivity': f'P{task_num}_Productivity'\n",
    "    }\n",
    "\n",
    "    # Get results for each outcome\n",
    "    for outcome in outcomes:\n",
    "        col = outcome_cols[outcome]\n",
    "        vincent_effect, gpt_effect, control_mean, x = extract_treatment_effects(task_num, col)\n",
    "\n",
    "        # Extract sample size (N) for each outcome\n",
    "        df = eval(f'task{task_num}_df')\n",
    "        sample_size = df[col].notna().sum()\n",
    "\n",
    "        # Add Vincent results\n",
    "        results_data.append({\n",
    "            'Outcome': outcome,\n",
    "            'Control Mean': f\"${control_mean:.2f}$\",\n",
    "            'Model': 'Vincent',\n",
    "            'Effect': format_effect(vincent_effect['coef'], vincent_effect['pval']),\n",
    "            'SE': f\"(${vincent_effect['se']:.2f}$)\",\n",
    "            'Pct Change': format_pct_change(vincent_effect['pct_change']),\n",
    "            'N': sample_size  # Include sample size\n",
    "        })\n",
    "\n",
    "        # Add o1-preview results\n",
    "        results_data.append({\n",
    "            'Outcome': outcome,\n",
    "            'Control Mean': f\"${control_mean:.2f}$\",\n",
    "            'Model': 'o1-preview',\n",
    "            'Effect': format_effect(gpt_effect['coef'], gpt_effect['pval']),\n",
    "            'SE': f\"(${gpt_effect['se']:.2f}$)\",\n",
    "            'Pct Change': format_pct_change(gpt_effect['pct_change']),\n",
    "            'N': sample_size  # Include sample size\n",
    "        })\n",
    "\n",
    "    # Create LaTeX table\n",
    "    latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "    latex_table += f\"\\\\caption{{Treatment Effects for {task_name}}}\\n\"\n",
    "    latex_table += f\"\\\\label{{tab:task{task_num}_effects}}\\n\"\n",
    "    latex_table += \"\\\\begin{tabular}{lcccccc}\\n\"\n",
    "    latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "    latex_table += \"Outcome & Control Mean & Model & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    # Add rows\n",
    "    for outcome in outcomes:\n",
    "        outcome_rows = [row for row in results_data if row['Outcome'] == outcome]\n",
    "        first_row = True\n",
    "        for row in outcome_rows:\n",
    "            if first_row:\n",
    "                latex_table += f\"\\\\multirow{{2}}{{*}}{{{row['Outcome']}}} & \"\n",
    "                latex_table += f\"\\\\multirow{{2}}{{*}}{{{row['Control Mean']}}} \"\n",
    "                first_row = False\n",
    "            else:\n",
    "                latex_table += \"& \"\n",
    "            latex_table += f\"& {row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    # Add task-specific time limit to notes\n",
    "    time_limits = {\n",
    "        1: \"60\", 2: \"240\", 3: \"120\",\n",
    "        4: \"180\", 5: \"150\", 6: \"150\"\n",
    "    }\n",
    "\n",
    "    latex_table += \"\\\\multicolumn{7}{p{0.95\\\\linewidth}}{\\\\footnotesize \\\\textit{Notes:} \"\n",
    "    latex_table += f\"Effects shown relative to No AI control group. For quality criteria (Accuracy through Professionalism), \"\n",
    "    latex_table += f\"the scoring scale is 1-7, with Total Score ranging from 5-35. Time Spent shows minutes (time limit: {time_limits[task_num]} minutes). \"\n",
    "    latex_table += f\"Productivity measures points earned per minute. \"\n",
    "    latex_table += \"Percent changes calculated relative to control group mean. \"\n",
    "    latex_table += \"Robust standard errors in parentheses. \"\n",
    "    latex_table += \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$}\\n\"\n",
    "    latex_table += \"\\\\end{tabular}\\n\"\n",
    "    latex_table += \"\\\\end{table}\"\n",
    "\n",
    "    # Save LaTeX table\n",
    "    with open(f\"{analysis_path}/tables/task{task_num}_all_effects.tex\", \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Helper function for significance stars\n",
    "def get_stars(pval):\n",
    "    if pval < 0.01:\n",
    "        return \"***\"\n",
    "    elif pval < 0.05:\n",
    "        return \"**\"\n",
    "    elif pval < 0.1:\n",
    "        return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "# Create tables for all tasks\n",
    "task_names = {\n",
    "    1: \"Draft Client Email\",\n",
    "    2: \"Draft Legal Memo\",\n",
    "    3: \"Analysis of Complaint\",\n",
    "    4: \"Draft NDA\",\n",
    "    5: \"Draft Motion to Consolidate\",\n",
    "    6: \"Draft CNC Enforcement Letter\"\n",
    "}\n",
    "\n",
    "# Generate all task tables\n",
    "for task_num, task_name in task_names.items():\n",
    "    print(f\"\\nGenerating table for Task {task_num}: {task_name}\")\n",
    "    table = create_task_table(task_num, task_name)\n",
    "    print(f\"Table saved as task{task_num}_all_effects.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tasks with score across all treatment groups: 767\n",
      "Total tasks with time recorded: 764\n",
      "Total tasks with both score and time: 764\n",
      "Total tasks with productivity data: 764\n",
      "\n",
      "Breakdown by task:\n",
      "Task 1 (Draft Client Email):\n",
      "  Score completed count: 135\n",
      "  Time recorded count: 134\n",
      "  Both score and time recorded: 134\n",
      "  Productivity recorded count: 134\n",
      "Task 2 (Draft Legal Memo):\n",
      "  Score completed count: 125\n",
      "  Time recorded count: 124\n",
      "  Both score and time recorded: 124\n",
      "  Productivity recorded count: 124\n",
      "Task 3 (Analysis of Complaint):\n",
      "  Score completed count: 127\n",
      "  Time recorded count: 126\n",
      "  Both score and time recorded: 126\n",
      "  Productivity recorded count: 126\n",
      "Task 4 (Draft NDA):\n",
      "  Score completed count: 127\n",
      "  Time recorded count: 127\n",
      "  Both score and time recorded: 127\n",
      "  Productivity recorded count: 127\n",
      "Task 5 (Draft Motion to Consolidate):\n",
      "  Score completed count: 127\n",
      "  Time recorded count: 127\n",
      "  Both score and time recorded: 127\n",
      "  Productivity recorded count: 127\n",
      "Task 6 (Draft CNC Enforcement Letter):\n",
      "  Score completed count: 126\n",
      "  Time recorded count: 126\n",
      "  Both score and time recorded: 126\n",
      "  Productivity recorded count: 126\n"
     ]
    }
   ],
   "source": [
    "def analyze_complete_task_data():\n",
    "    \"\"\"\n",
    "    Analyzes tasks with complete data:\n",
    "    1. Tasks with non-null Total Score\n",
    "    2. Tasks with non-null Time Spent\n",
    "    3. Tasks with both Score and Time\n",
    "    4. Tasks with Productivity data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary of completion counts by task and total\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"by_task\": {}, \n",
    "        \"total_score_completed\": 0, \n",
    "        \"total_time_recorded\": 0,\n",
    "        \"total_both_recorded\": 0,\n",
    "        \"total_productivity_recorded\": 0\n",
    "    }\n",
    "    \n",
    "    # Iterate through all 6 tasks\n",
    "    for task_num in range(1, 7):\n",
    "        # Get the corresponding dataframe for this task\n",
    "        df = eval(f'task{task_num}_df')\n",
    "        \n",
    "        # Get the corresponding columns\n",
    "        score_col = outcome_mappings['Total Score'][task_num]\n",
    "        time_col = outcome_mappings['Time Spent'][task_num]\n",
    "        productivity_col = f'P{task_num}_Productivity'\n",
    "        \n",
    "        # Count tasks with non-null Total Score\n",
    "        score_completed_count = df[score_col].notna().sum()\n",
    "        \n",
    "        # Count tasks with non-null Time Spent\n",
    "        time_recorded_count = df[time_col].notna().sum()\n",
    "        \n",
    "        # Count tasks with both score and time\n",
    "        both_recorded_count = df[df[score_col].notna() & df[time_col].notna()].shape[0]\n",
    "        \n",
    "        # Count tasks with productivity data\n",
    "        productivity_recorded_count = df[productivity_col].notna().sum() if productivity_col in df.columns else 0\n",
    "        \n",
    "        # Store results for this task\n",
    "        results[\"by_task\"][task_num] = {\n",
    "            \"task_name\": task_names[task_num],\n",
    "            \"score_completed_count\": score_completed_count,\n",
    "            \"time_recorded_count\": time_recorded_count,\n",
    "            \"both_recorded_count\": both_recorded_count,\n",
    "            \"productivity_recorded_count\": productivity_recorded_count\n",
    "        }\n",
    "        \n",
    "        # Update totals\n",
    "        results[\"total_score_completed\"] += score_completed_count\n",
    "        results[\"total_time_recorded\"] += time_recorded_count\n",
    "        results[\"total_both_recorded\"] += both_recorded_count\n",
    "        results[\"total_productivity_recorded\"] += productivity_recorded_count\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "completion_analysis = analyze_complete_task_data()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total tasks with score across all treatment groups: {completion_analysis['total_score_completed']}\")\n",
    "print(f\"Total tasks with time recorded: {completion_analysis['total_time_recorded']}\")\n",
    "print(f\"Total tasks with both score and time: {completion_analysis['total_both_recorded']}\")\n",
    "print(f\"Total tasks with productivity data: {completion_analysis['total_productivity_recorded']}\")\n",
    "\n",
    "print(\"\\nBreakdown by task:\")\n",
    "for task_num, stats in completion_analysis[\"by_task\"].items():\n",
    "    print(f\"Task {task_num} ({stats['task_name']}):\")\n",
    "    print(f\"  Score completed count: {stats['score_completed_count']}\")\n",
    "    print(f\"  Time recorded count: {stats['time_recorded_count']}\")\n",
    "    print(f\"  Both score and time recorded: {stats['both_recorded_count']}\")\n",
    "    print(f\"  Productivity recorded count: {stats['productivity_recorded_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some nice figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots for Task 1: Draft Client Email\n",
      "Saved plots for Task 1\n",
      "Generating plots for Task 2: Draft Legal Memo\n",
      "Saved plots for Task 2\n",
      "Generating plots for Task 3: Analysis of Complaint\n",
      "Saved plots for Task 3\n",
      "Generating plots for Task 4: Draft NDA\n",
      "Saved plots for Task 4\n",
      "Generating plots for Task 5: Draft Motion to Consolidate\n",
      "Saved plots for Task 5\n",
      "Generating plots for Task 6: Draft CNC Enforcement Letter\n",
      "Saved plots for Task 6\n"
     ]
    }
   ],
   "source": [
    "def create_density_plots(task_num, task_name):\n",
    "    # Create the figures directory if it doesn't exist\n",
    "    figures_path = os.path.join(analysis_path, 'figures')\n",
    "    os.makedirs(figures_path, exist_ok=True)\n",
    "    \n",
    "    # Set the style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # Create figures for both Total Score and Time Spent\n",
    "    fig_score, ax_score = plt.subplots(figsize=(10, 6))\n",
    "    fig_time, ax_time = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Get data\n",
    "    df = eval(f'task{task_num}_df')\n",
    "    score_col = f'P{task_num}_Total_Score'\n",
    "    \n",
    "    time_col = time_cols[task_num]\n",
    "    \n",
    "    # Colors and display names mapping\n",
    "    colors = {\n",
    "        'No AI': ('lightblue', 'blue'),  # (fill color, mean line color)\n",
    "        'GPT 01': ('bisque', 'red'),     # Keep dataset variable name\n",
    "        'Vincent': ('lightgreen', 'darkgreen')\n",
    "    }\n",
    "    \n",
    "    # Display name mapping\n",
    "    display_names = {\n",
    "        'No AI': 'No AI',\n",
    "        'GPT 01': 'o1-preview',  # Map to display name\n",
    "        'Vincent': 'Vincent'\n",
    "    }\n",
    "    \n",
    "    # Plot density for each condition - Total Score\n",
    "    for condition in ['No AI', 'GPT 01', 'Vincent']:\n",
    "        score_data = df[df['AI_Condition'] == condition][score_col].dropna()\n",
    "        score_mean = score_data.mean()\n",
    "        display_name = display_names[condition]\n",
    "        \n",
    "        # Plot score density\n",
    "        sns.kdeplot(data=score_data,\n",
    "                   fill=True,\n",
    "                   alpha=0.5,\n",
    "                   color=colors[condition][0],\n",
    "                   label=display_name,\n",
    "                   ax=ax_score)\n",
    "        \n",
    "        # Add vertical line for score mean\n",
    "        ax_score.axvline(x=score_mean,\n",
    "                        color=colors[condition][1],\n",
    "                        linestyle='-',\n",
    "                        label=f'Mean ({display_name})')\n",
    "    \n",
    "    # Customize score plot\n",
    "    ax_score.set_title(f'Total Score Distribution: {task_name}',\n",
    "                      fontsize=14,\n",
    "                      pad=20)\n",
    "    ax_score.set_xlabel('Total Score', fontsize=12)\n",
    "    ax_score.set_ylabel('Density', fontsize=12)\n",
    "    ax_score.legend()\n",
    "    \n",
    "    # Plot density for each condition - Time Spent\n",
    "    for condition in ['No AI', 'GPT 01', 'Vincent']:\n",
    "        time_data = df[df['AI_Condition'] == condition][time_col].dropna()\n",
    "        time_mean = time_data.mean()\n",
    "        display_name = display_names[condition]\n",
    "        \n",
    "        # Plot time density\n",
    "        sns.kdeplot(data=time_data,\n",
    "                   fill=True,\n",
    "                   alpha=0.5,\n",
    "                   color=colors[condition][0],\n",
    "                   label=display_name,\n",
    "                   ax=ax_time)\n",
    "        \n",
    "        # Add vertical line for time mean\n",
    "        ax_time.axvline(x=time_mean,\n",
    "                       color=colors[condition][1],\n",
    "                       linestyle='-',\n",
    "                       label=f'Mean ({display_name})')\n",
    "    \n",
    "    # Customize time plot\n",
    "    ax_time.set_title(f'Time Spent Distribution: {task_name}',\n",
    "                     fontsize=14,\n",
    "                     pad=20)\n",
    "    ax_time.set_xlabel('Time Spent (minutes)', fontsize=12)\n",
    "    ax_time.set_ylabel('Density', fontsize=12)\n",
    "    ax_time.legend()\n",
    "    \n",
    "    # Save figures\n",
    "    score_file = os.path.join(figures_path, f'task{task_num}_score_density.png')\n",
    "    time_file = os.path.join(figures_path, f'task{task_num}_time_density.png')\n",
    "    \n",
    "    fig_score.savefig(score_file, dpi=300, bbox_inches='tight')\n",
    "    fig_time.savefig(time_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Close all figures to free memory\n",
    "    plt.close('all')\n",
    "\n",
    "# Create plots for each task\n",
    "task_names = {\n",
    "    1: \"Draft Client Email\",\n",
    "    2: \"Draft Legal Memo\",\n",
    "    3: \"Analysis of Complaint\",\n",
    "    4: \"Draft NDA\",\n",
    "    5: \"Draft Motion to Consolidate\",\n",
    "    6: \"Draft CNC Enforcement Letter\"\n",
    "}\n",
    "\n",
    "# Generate all plots\n",
    "for task_num, task_name in task_names.items():\n",
    "    print(f\"Generating plots for Task {task_num}: {task_name}\")\n",
    "    create_density_plots(task_num, task_name)\n",
    "    print(f\"Saved plots for Task {task_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running regression with controls \n",
    "\n",
    "First, getting doing mergers and gettings the controls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unmatched students: 0\n",
      "\n",
      "Warning: Found duplicates for these students:\n",
      "Student Number: af90ee0cf16ffd33, Name: af90ee0cf16ffd33\n",
      "Student Number: 191cebe1180b87c5, Name: 191cebe1180b87c5\n",
      "Student Number: 7dd7e803832f1b53, Name: 7dd7e803832f1b53\n",
      "Student Number: f3e93859c85d9caf, Name: f3e93859c85d9caf\n",
      "Student Number: b066caa360c869a0, Name: b066caa360c869a0\n",
      "Student Number: e0a9f0ffff131843, Name: e0a9f0ffff131843\n",
      "\n",
      "Merge Summary:\n",
      "Total students: 153\n",
      "Successfully matched: 153\n",
      "Missing survey data: 0\n",
      "\n",
      "Direct merge results saved to: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\debug\\direct_merge_results_20250306_143817.xlsx\n"
     ]
    }
   ],
   "source": [
    "qualtrics_folder = os.path.join(master_folder, \"Qualtrics surveys\")\n",
    "vincent_survey = pd.read_excel(f\"{qualtrics_folder}/Enrollment survey/Vincent AI RCT_November 27, 2024_04.01.xlsx\", skiprows=[1])\n",
    "\n",
    "# REVISED: First identify actual duplicates based on original Q3 (name) OR Q5 (email)\n",
    "name_duplicates = vincent_survey[vincent_survey.duplicated(subset=['Q3'], keep=False) & \n",
    "                                ~vincent_survey['Q3'].isna()]\n",
    "email_duplicates = vincent_survey[vincent_survey.duplicated(subset=['Q5'], keep=False) & \n",
    "                                 ~vincent_survey['Q5'].isna()]\n",
    "\n",
    "# Combine all identified duplicates\n",
    "all_duplicates_index = pd.concat([name_duplicates, email_duplicates]).index.unique()\n",
    "duplicate_records = vincent_survey.loc[all_duplicates_index].copy()\n",
    "\n",
    "# For the actual duplicates, sort by completeness and keep most complete\n",
    "if not duplicate_records.empty:\n",
    "    duplicate_records['completeness'] = duplicate_records.notna().sum(axis=1)\n",
    "    \n",
    "    # Create a temporary dataframe to store deduplicated records\n",
    "    deduplicated = []\n",
    "    \n",
    "    # Handle name duplicates\n",
    "    for name in duplicate_records['Q3'].dropna().unique():\n",
    "        name_group = duplicate_records[duplicate_records['Q3'] == name]\n",
    "        if len(name_group) > 1:  # Only process actual duplicates\n",
    "            best_record = name_group.sort_values('completeness', ascending=False).iloc[0]\n",
    "            deduplicated.append(best_record)\n",
    "    \n",
    "    # Handle email duplicates that weren't already handled by name\n",
    "    for email in duplicate_records['Q5'].dropna().unique():\n",
    "        email_group = duplicate_records[duplicate_records['Q5'] == email]\n",
    "        # Only include records not already deduplicated by name\n",
    "        if len(email_group) > 1 and not all(idx in [d.name for d in deduplicated] for idx in email_group.index):\n",
    "            best_record = email_group.sort_values('completeness', ascending=False).iloc[0]\n",
    "            deduplicated.append(best_record)\n",
    "    \n",
    "    # Create dataframe of deduplicated records\n",
    "    deduplicated_df = pd.DataFrame(deduplicated)\n",
    "    \n",
    "    # Get non-duplicate records\n",
    "    non_duplicates = vincent_survey.drop(all_duplicates_index)\n",
    "    \n",
    "    # Combine non-duplicates with deduplicated records\n",
    "    vincent_survey = pd.concat([non_duplicates, deduplicated_df])\n",
    "else:\n",
    "    # No duplicates found, keep all records\n",
    "    print(\"No duplicates found in the survey data.\")\n",
    "\n",
    "# Drop the temporary completeness column if it exists\n",
    "if 'completeness' in vincent_survey.columns:\n",
    "    vincent_survey = vincent_survey.drop('completeness', axis=1)\n",
    "\n",
    "# Merge datasets using original names\n",
    "merged_df = final_df.merge(\n",
    "    vincent_survey[['Q3', 'Q5', 'Q6', 'Q7', 'Q8']],\n",
    "    left_on='Student name',\n",
    "    right_on='Q3',\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Check for any unmatched records\n",
    "unmatched = merged_df[merged_df['_merge'] == 'left_only']\n",
    "print(f\"\\nUnmatched students: {len(unmatched)}\")\n",
    "if not unmatched.empty:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unmatched[['Student Number', 'Student name']].to_excel(\n",
    "        os.path.join(debug_path, f'unmatched_{timestamp}.xlsx'), index=False)\n",
    "\n",
    "# Check for any duplicates\n",
    "duplicates = merged_df[merged_df.duplicated(subset=['Student Number'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(\"\\nWarning: Found duplicates for these students:\")\n",
    "    for _, row in duplicates.drop_duplicates(subset=['Student Number']).iterrows():\n",
    "        print(f\"Student Number: {row['Student Number']}, Name: {row['Student name']}\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    duplicates.to_excel(os.path.join(debug_path, f'duplicates_{timestamp}.xlsx'), index=False)\n",
    "\n",
    "# Rename columns\n",
    "merged_df = merged_df.rename(columns={\n",
    "    'Q5': 'Email',\n",
    "    'Q6': 'Student_Type',\n",
    "    'Q7': 'GPA',\n",
    "    'Q8': 'AI_Use'\n",
    "})\n",
    "\n",
    "# If any duplicates remain, keep the most complete row\n",
    "if len(duplicates) > 0:\n",
    "    merged_df['completeness'] = merged_df.notna().sum(axis=1)\n",
    "    merged_df = merged_df.sort_values('completeness', ascending=False).drop_duplicates('Student Number')\n",
    "    merged_df = merged_df.drop('completeness', axis=1)\n",
    "\n",
    "# Save merge results with detailed statistics\n",
    "merge_stats = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Students', \n",
    "        'Matched Students', \n",
    "        'Missing Survey Data',\n",
    "        'Students with Email',\n",
    "        'Students with Student Type',\n",
    "        'Students with GPA',\n",
    "        'Students with AI Use'\n",
    "    ],\n",
    "    'Count': [\n",
    "        len(merged_df),\n",
    "        (merged_df['_merge'] == 'both').sum(),\n",
    "        (merged_df['_merge'] == 'left_only').sum(),\n",
    "        merged_df['Email'].notna().sum(),\n",
    "        merged_df['Student_Type'].notna().sum(),\n",
    "        merged_df['GPA'].notna().sum(),\n",
    "        merged_df['AI_Use'].notna().sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "with pd.ExcelWriter(os.path.join(debug_path, f'direct_merge_results_{timestamp}.xlsx')) as writer:\n",
    "    merged_df.to_excel(writer, sheet_name='Merged_Data', index=False)\n",
    "    merge_stats.to_excel(writer, sheet_name='Merge_Statistics', index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nMerge Summary:\")\n",
    "print(f\"Total students: {len(merged_df)}\")\n",
    "print(f\"Successfully matched: {(merged_df['_merge'] == 'both').sum()}\")\n",
    "print(f\"Missing survey data: {(merged_df['_merge'] == 'left_only').sum()}\")\n",
    "\n",
    "# Update final_df with the new data\n",
    "final_df_with_controls = merged_df.drop(['Q3', '_merge'], axis=1)\n",
    "\n",
    "print(f\"\\nDirect merge results saved to: {os.path.join(debug_path, f'direct_merge_results_{timestamp}.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting inconsistent GPA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the corrections dictionary (normalized keys)\n",
    "corrections = {\n",
    "    \"i received a 3.267 1l fall semester and a 3.333 1l spring semester. (not sure gpa for overall 1l year)\": (3.267 + 3.333) / 2,\n",
    "    \"3.461/4.333\": (3.461 / 4.333) * 4,  # Scale to 4.0 system\n",
    "    \"2.1 (british grading system)\": 3.5  # Approximate WES conversion\n",
    "}\n",
    "\n",
    "# Function to normalize text (to match dictionary keys)\n",
    "def normalize_text(value):\n",
    "    if isinstance(value, str):  # Ensure it's a string\n",
    "        return value.strip().lower().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    return value  # Keep non-string values unchanged\n",
    "\n",
    "# Create a copy for tracking changes\n",
    "original_gpa = final_df_with_controls[\"GPA\"].copy()\n",
    "\n",
    "# Normalize the GPA column for matching\n",
    "final_df_with_controls[\"normalized_GPA\"] = final_df_with_controls[\"GPA\"].map(normalize_text)\n",
    "\n",
    "# Apply corrections **only where the normalized GPA matches a key in corrections**\n",
    "mask = final_df_with_controls[\"normalized_GPA\"].isin(corrections.keys())\n",
    "final_df_with_controls.loc[mask, \"GPA\"] = final_df_with_controls[\"normalized_GPA\"].map(corrections)\n",
    "\n",
    "# Drop the temporary column used for matching\n",
    "final_df_with_controls.drop(columns=[\"normalized_GPA\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Controls file saved successfully at: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\controls.csv\n",
      "\n",
      "Numeric controls file saved successfully at: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\controls_numeric.csv\n"
     ]
    }
   ],
   "source": [
    "# Define path for saving the controls file\n",
    "controls_path = analysis_path\n",
    "os.makedirs(controls_path, exist_ok=True)\n",
    "\n",
    "# Remove duplicates from final_df_with_controls based on completeness\n",
    "final_df_with_controls['completeness'] = final_df_with_controls.notna().sum(axis=1)\n",
    "final_df_with_controls = final_df_with_controls.sort_values('completeness', ascending=False).drop_duplicates('Student name')\n",
    "final_df_with_controls = final_df_with_controls.drop('completeness', axis=1)\n",
    "\n",
    "# Save only the necessary columns\n",
    "controls_df = final_df_with_controls[['Student Number', 'Student name', 'GPA', 'Student_Type', 'AI_Use']]\n",
    "controls_df.columns = ['Student_Number', 'Student_Name', 'GPA', 'Student_Type', 'AI_Use']\n",
    "\n",
    "# Save original controls file\n",
    "controls_file = os.path.join(controls_path, \"controls.csv\")\n",
    "controls_df.to_csv(controls_file, index=False)\n",
    "print(f\"\\nControls file saved successfully at: {controls_file}\")\n",
    "\n",
    "# Create a numeric version of controls\n",
    "controls_numeric_df = controls_df.copy()\n",
    "\n",
    "# Convert GPA and AI Use to numeric, setting invalid values to NaN\n",
    "for col in ['GPA', 'AI_Use']:\n",
    "    controls_numeric_df[col] = pd.to_numeric(controls_numeric_df[col], errors='coerce')\n",
    "\n",
    "# Save numeric controls file\n",
    "controls_numeric_file = os.path.join(controls_path, \"controls_numeric.csv\")\n",
    "controls_numeric_df.to_csv(controls_numeric_file, index=False)\n",
    "print(f\"\\nNumeric controls file saved successfully at: {controls_numeric_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded controls from: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\controls_numeric.csv\n",
      "     Student_Number      Student_Name    GPA  Student_Type  AI_Use\n",
      "0  9e2e00fa7c285ff5  9e2e00fa7c285ff5  2.920           2.0     1.0\n",
      "1  b0eea11d8aa104e7  b0eea11d8aa104e7  3.366           2.0     2.0\n",
      "2  ad4e0a23d55a9bc2  ad4e0a23d55a9bc2  3.330           2.0     4.0\n",
      "3  22357cb4b713c556  22357cb4b713c556  3.400           2.0     1.0\n",
      "4  eab55a7284651fe8  eab55a7284651fe8  3.680           1.0     5.0\n",
      "\n",
      "==================================================\n",
      "Processing Task 1\n",
      "==================================================\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (119, 25)\n",
      "\n",
      "Analysis for P1_Criteria_1_Accuracy - Task 1 with Controls\n",
      "Number of observations: 119\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    119.000000\n",
      "mean       3.386555\n",
      "std        1.712908\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P1_Criteria_1_Accuracy, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  7.702324e-01  1.449043e+00  0.595041\n",
      "1               Vincent_dummy  1.046185e-01  3.973314e-01  0.792317\n",
      "2                 GPT01_dummy -4.659326e-01  4.042946e-01  0.249133\n",
      "3                         GPA  6.801374e-01  4.403956e-01  0.122497\n",
      "4    Student Type: 3L Student -3.877741e-02  3.188971e-01  0.903217\n",
      "5   Student Type: LLM Student -7.664701e-16  7.956772e-16  0.335401\n",
      "6           AI Use: 1-5 times  7.146028e-01  4.261424e-01  0.093560\n",
      "7          AI Use: 6-10 times  9.607849e-01  4.957236e-01  0.052605\n",
      "8         AI Use: 11-20 times  5.978183e-01  7.808729e-01  0.443928\n",
      "9  AI Use: More than 20 times  1.379525e-01  5.027438e-01  0.783778\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (119, 25)\n",
      "\n",
      "Analysis for P1_Criteria_2_Analysis - Task 1 with Controls\n",
      "Number of observations: 119\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    119.000000\n",
      "mean       3.831933\n",
      "std        1.525597\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P1_Criteria_2_Analysis, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  5.099830e-01  1.402891e+00  0.716214\n",
      "1               Vincent_dummy  3.553522e-01  3.567664e-01  0.319233\n",
      "2                 GPT01_dummy -1.689050e-01  3.703287e-01  0.648322\n",
      "3                         GPA  8.515638e-01  4.174293e-01  0.041348\n",
      "4    Student Type: 3L Student  9.369339e-02  2.850075e-01  0.742352\n",
      "5   Student Type: LLM Student -5.697763e-16  7.352855e-16  0.438396\n",
      "6           AI Use: 1-5 times  6.266625e-01  3.936055e-01  0.111360\n",
      "7          AI Use: 6-10 times  4.362340e-01  4.839557e-01  0.367380\n",
      "8         AI Use: 11-20 times  3.681457e-01  6.751355e-01  0.585553\n",
      "9  AI Use: More than 20 times  3.129851e-01  4.662495e-01  0.502041\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (119, 25)\n",
      "\n",
      "Analysis for P1_Criteria_3_Organization - Task 1 with Controls\n",
      "Number of observations: 119\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    119.000000\n",
      "mean       4.470588\n",
      "std        1.358111\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P1_Criteria_3_Organization, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.702096e+00  1.259798e+00  0.031964\n",
      "1               Vincent_dummy  3.651090e-01  3.346973e-01  0.275333\n",
      "2                 GPT01_dummy  1.913134e-01  3.274120e-01  0.559005\n",
      "3                         GPA  3.679105e-01  3.798195e-01  0.332722\n",
      "4    Student Type: 3L Student  8.134999e-02  2.680151e-01  0.761488\n",
      "5   Student Type: LLM Student -6.015133e-16  6.829954e-16  0.378481\n",
      "6           AI Use: 1-5 times  3.616048e-01  3.736410e-01  0.333151\n",
      "7          AI Use: 6-10 times  6.162683e-01  4.168522e-01  0.139305\n",
      "8         AI Use: 11-20 times  1.191186e-01  6.739877e-01  0.859715\n",
      "9  AI Use: More than 20 times  3.329773e-01  4.337072e-01  0.442638\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (119, 25)\n",
      "\n",
      "Analysis for P1_Criteria_4_Clarity - Task 1 with Controls\n",
      "Number of observations: 119\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    119.000000\n",
      "mean       4.957983\n",
      "std        1.304458\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P1_Criteria_4_Clarity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.434193e+00  1.034917e+00  0.018669\n",
      "1               Vincent_dummy  8.545169e-01  3.025272e-01  0.004734\n",
      "2                 GPT01_dummy  1.110289e+00  2.855566e-01  0.000101\n",
      "3                         GPA  3.614979e-01  3.239633e-01  0.264482\n",
      "4    Student Type: 3L Student  3.270002e-01  2.319969e-01  0.158687\n",
      "5   Student Type: LLM Student -1.719859e-15  5.780987e-16  0.002930\n",
      "6           AI Use: 1-5 times  5.934221e-01  3.220246e-01  0.065360\n",
      "7          AI Use: 6-10 times  8.357075e-01  3.203129e-01  0.009080\n",
      "8         AI Use: 11-20 times  6.046823e-01  5.381955e-01  0.261210\n",
      "9  AI Use: More than 20 times  4.132651e-01  4.016604e-01  0.303530\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (119, 25)\n",
      "\n",
      "Analysis for P1_Criteria_5_Professionalism - Task 1 with Controls\n",
      "Number of observations: 119\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    119.000000\n",
      "mean       5.092437\n",
      "std        1.780267\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        6.000000\n",
      "75%        7.000000\n",
      "max        7.000000\n",
      "Name: P1_Criteria_5_Professionalism, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.640499e+00  1.543664e+00  0.087166\n",
      "1               Vincent_dummy  5.970984e-01  4.356499e-01  0.170502\n",
      "2                 GPT01_dummy  1.038785e+00  4.119329e-01  0.011678\n",
      "3                         GPA  4.524164e-01  4.701388e-01  0.335897\n",
      "4    Student Type: 3L Student -1.320769e-01  3.402247e-01  0.697864\n",
      "5   Student Type: LLM Student -1.411303e-15  9.356544e-16  0.131463\n",
      "6           AI Use: 1-5 times  5.387945e-01  5.046929e-01  0.285715\n",
      "7          AI Use: 6-10 times  7.630406e-01  6.203010e-01  0.218655\n",
      "8         AI Use: 11-20 times  3.581255e-01  8.571206e-01  0.676076\n",
      "9  AI Use: More than 20 times  5.142260e-01  5.836427e-01  0.378284\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (119, 25)\n",
      "\n",
      "Analysis for P1_Total_Score - Task 1 with Controls\n",
      "Number of observations: 119\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    119.000000\n",
      "mean      21.739496\n",
      "std        6.682208\n",
      "min        5.000000\n",
      "25%       18.000000\n",
      "50%       22.000000\n",
      "75%       27.000000\n",
      "max       33.000000\n",
      "Name: P1_Total_Score, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  9.057003e+00  5.869105e+00  0.122790\n",
      "1               Vincent_dummy  2.276695e+00  1.642480e+00  0.165707\n",
      "2                 GPT01_dummy  1.705549e+00  1.607683e+00  0.288747\n",
      "3                         GPA  2.713526e+00  1.796291e+00  0.130883\n",
      "4    Student Type: 3L Student  3.311893e-01  1.274683e+00  0.795002\n",
      "5   Student Type: LLM Student -5.068921e-15  3.346748e-15  0.129878\n",
      "6           AI Use: 1-5 times  2.835087e+00  1.804385e+00  0.116131\n",
      "7          AI Use: 6-10 times  3.612035e+00  2.070996e+00  0.081141\n",
      "8         AI Use: 11-20 times  2.047890e+00  3.197456e+00  0.521864\n",
      "9  AI Use: More than 20 times  1.711406e+00  2.155761e+00  0.427268\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (118, 25)\n",
      "\n",
      "Analysis for Time_Spent_Assignment_1 - Task 1 with Controls\n",
      "Number of observations: 118\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    118.000000\n",
      "mean      45.847458\n",
      "std       12.758525\n",
      "min       15.000000\n",
      "25%       39.250000\n",
      "50%       49.500000\n",
      "75%       57.000000\n",
      "max       60.000000\n",
      "Name: Time_Spent_Assignment_1, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.113105e+01  1.120460e+01  0.000242\n",
      "1               Vincent_dummy -8.514826e+00  2.926189e+00  0.003616\n",
      "2                 GPT01_dummy -8.222777e+00  2.555524e+00  0.001292\n",
      "3                         GPA  2.670186e+00  3.281786e+00  0.415852\n",
      "4    Student Type: 3L Student -3.477681e+00  2.294200e+00  0.129555\n",
      "5   Student Type: LLM Student -1.104572e-14  1.019777e-14  0.278742\n",
      "6           AI Use: 1-5 times  4.010157e+00  2.987584e+00  0.179507\n",
      "7          AI Use: 6-10 times  7.497212e+00  3.782612e+00  0.047477\n",
      "8         AI Use: 11-20 times -5.044649e+00  5.915361e+00  0.393767\n",
      "9  AI Use: More than 20 times  3.527633e+00  4.004031e+00  0.378307\n",
      "\n",
      "Shape before cleaning: (135, 25)\n",
      "Shape after cleaning: (118, 25)\n",
      "\n",
      "Analysis for P1_Productivity - Task 1 with Controls\n",
      "Number of observations: 118\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     41\n",
      "Vincent    40\n",
      "No AI      37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    118.000000\n",
      "mean       0.530619\n",
      "std        0.278210\n",
      "min        0.083333\n",
      "25%        0.360000\n",
      "50%        0.487043\n",
      "75%        0.611538\n",
      "max        1.650000\n",
      "Name: P1_Productivity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.523042e-01  2.393906e-01  0.058839\n",
      "1               Vincent_dummy  2.175222e-01  6.459761e-02  0.000759\n",
      "2                 GPT01_dummy  1.612656e-01  5.319273e-02  0.002432\n",
      "3                         GPA -2.318059e-02  7.420910e-02  0.754760\n",
      "4    Student Type: 3L Student  6.829951e-02  4.948500e-02  0.167523\n",
      "5   Student Type: LLM Student  7.231799e-17  2.395980e-16  0.762781\n",
      "6           AI Use: 1-5 times -1.401090e-02  7.112976e-02  0.843846\n",
      "7          AI Use: 6-10 times -5.310933e-02  7.483672e-02  0.477909\n",
      "8         AI Use: 11-20 times  1.623940e-01  1.781144e-01  0.361906\n",
      "9  AI Use: More than 20 times -8.236635e-03  8.011975e-02  0.918118\n",
      "\n",
      "==================================================\n",
      "Processing Task 2\n",
      "==================================================\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (109, 25)\n",
      "\n",
      "Analysis for P2_Criteria_1_Accuracy - Task 2 with Controls\n",
      "Number of observations: 109\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    109.000000\n",
      "mean       3.183486\n",
      "std        1.225993\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        6.000000\n",
      "Name: P2_Criteria_1_Accuracy, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  6.772538e-01  8.837379e-01  0.443467\n",
      "1               Vincent_dummy  2.013419e-01  2.738238e-01  0.462158\n",
      "2                 GPT01_dummy -1.783533e-01  2.902052e-01  0.538834\n",
      "3                         GPA  7.210968e-01  2.642022e-01  0.006346\n",
      "4    Student Type: 3L Student  3.126341e-01  2.418432e-01  0.196110\n",
      "5   Student Type: LLM Student -3.627332e-17  2.352191e-16  0.877444\n",
      "6           AI Use: 1-5 times -3.157616e-01  3.385376e-01  0.350963\n",
      "7          AI Use: 6-10 times  8.030126e-02  4.074246e-01  0.843753\n",
      "8         AI Use: 11-20 times  4.140990e-01  6.034771e-01  0.492594\n",
      "9  AI Use: More than 20 times  1.213680e-01  4.136268e-01  0.769198\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (109, 25)\n",
      "\n",
      "Analysis for P2_Criteria_2_Analysis - Task 2 with Controls\n",
      "Number of observations: 109\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    109.000000\n",
      "mean       3.449541\n",
      "std        1.084284\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        6.000000\n",
      "Name: P2_Criteria_2_Analysis, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  6.580318e-01  8.617945e-01  0.445129\n",
      "1               Vincent_dummy  2.814799e-01  2.533995e-01  0.266648\n",
      "2                 GPT01_dummy  3.486855e-01  2.454311e-01  0.155402\n",
      "3                         GPA  7.671102e-01  2.484184e-01  0.002015\n",
      "4    Student Type: 3L Student  9.704564e-02  2.180431e-01  0.656265\n",
      "5   Student Type: LLM Student -1.431822e-16  2.175703e-16  0.510476\n",
      "6           AI Use: 1-5 times -9.582080e-02  3.272329e-01  0.769659\n",
      "7          AI Use: 6-10 times  2.710017e-02  3.749959e-01  0.942389\n",
      "8         AI Use: 11-20 times  2.904153e-01  5.651155e-01  0.607319\n",
      "9  AI Use: More than 20 times  2.544723e-02  3.783192e-01  0.946372\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (109, 25)\n",
      "\n",
      "Analysis for P2_Criteria_3_Organization - Task 2 with Controls\n",
      "Number of observations: 109\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    109.000000\n",
      "mean       4.504587\n",
      "std        1.463278\n",
      "min        0.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P2_Criteria_3_Organization, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  3.759495e+00  1.215484e+00  0.001981\n",
      "1               Vincent_dummy  4.508808e-02  3.681079e-01  0.902514\n",
      "2                 GPT01_dummy  7.291240e-01  3.164161e-01  0.021205\n",
      "3                         GPA  7.675301e-02  3.506250e-01  0.826725\n",
      "4    Student Type: 3L Student -4.385120e-02  2.792876e-01  0.875236\n",
      "5   Student Type: LLM Student -3.573931e-16  2.897955e-16  0.217479\n",
      "6           AI Use: 1-5 times  2.712733e-01  4.299991e-01  0.528126\n",
      "7          AI Use: 6-10 times  4.397332e-01  4.747484e-01  0.354319\n",
      "8         AI Use: 11-20 times  8.798290e-01  6.054375e-01  0.146165\n",
      "9  AI Use: More than 20 times  1.624782e-01  5.393468e-01  0.763224\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (109, 25)\n",
      "\n",
      "Analysis for P2_Criteria_4_Clarity - Task 2 with Controls\n",
      "Number of observations: 109\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    109.000000\n",
      "mean       3.917431\n",
      "std        1.147690\n",
      "min        0.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max        6.000000\n",
      "Name: P2_Criteria_4_Clarity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.740638e+00  9.869580e-01  0.005489\n",
      "1               Vincent_dummy  7.212286e-01  2.740221e-01  0.008488\n",
      "2                 GPT01_dummy  7.450419e-01  2.891749e-01  0.009982\n",
      "3                         GPA  2.606897e-01  2.599133e-01  0.315867\n",
      "4    Student Type: 3L Student  1.275446e-01  2.151218e-01  0.553251\n",
      "5   Student Type: LLM Student -2.125044e-16  2.213847e-16  0.337112\n",
      "6           AI Use: 1-5 times -2.599666e-01  3.204486e-01  0.417217\n",
      "7          AI Use: 6-10 times -2.794053e-01  3.779955e-01  0.459800\n",
      "8         AI Use: 11-20 times -6.641483e-01  7.359010e-01  0.366793\n",
      "9  AI Use: More than 20 times -2.132230e-01  3.827525e-01  0.577474\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (109, 25)\n",
      "\n",
      "Analysis for P2_Criteria_5_Professionalism - Task 2 with Controls\n",
      "Number of observations: 109\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    109.000000\n",
      "mean       4.321101\n",
      "std        1.483744\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P2_Criteria_5_Professionalism, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.927775e+00  1.220156e+00  0.114120\n",
      "1               Vincent_dummy  6.153656e-01  3.477440e-01  0.076795\n",
      "2                 GPT01_dummy  1.389829e+00  3.115731e-01  0.000008\n",
      "3                         GPA  4.471518e-01  3.506601e-01  0.202248\n",
      "4    Student Type: 3L Student  1.585463e-01  2.796077e-01  0.570693\n",
      "5   Student Type: LLM Student -5.497585e-16  2.859592e-16  0.054542\n",
      "6           AI Use: 1-5 times  2.314321e-01  4.176169e-01  0.579460\n",
      "7          AI Use: 6-10 times  3.499394e-01  4.779418e-01  0.464059\n",
      "8         AI Use: 11-20 times  1.382975e-01  6.068279e-01  0.819722\n",
      "9  AI Use: More than 20 times  1.157022e-01  4.771962e-01  0.808422\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (109, 25)\n",
      "\n",
      "Analysis for P2_Total_Score - Task 2 with Controls\n",
      "Number of observations: 109\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    109.000000\n",
      "mean      19.376147\n",
      "std        5.179713\n",
      "min        6.000000\n",
      "25%       16.000000\n",
      "50%       19.000000\n",
      "75%       23.000000\n",
      "max       30.000000\n",
      "Name: P2_Total_Score, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  9.763194e+00  3.983736e+00  0.014255\n",
      "1               Vincent_dummy  1.864504e+00  1.227900e+00  0.128901\n",
      "2                 GPT01_dummy  3.034327e+00  1.163795e+00  0.009127\n",
      "3                         GPA  2.272801e+00  1.065832e+00  0.032972\n",
      "4    Student Type: 3L Student  6.519195e-01  1.016257e+00  0.521204\n",
      "5   Student Type: LLM Student -1.299111e-15  1.063406e-15  0.221839\n",
      "6           AI Use: 1-5 times -1.688435e-01  1.581720e+00  0.914990\n",
      "7          AI Use: 6-10 times  6.176687e-01  1.787343e+00  0.729659\n",
      "8         AI Use: 11-20 times  1.058493e+00  2.455488e+00  0.666416\n",
      "9  AI Use: More than 20 times  2.117726e-01  1.866568e+00  0.909669\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (108, 25)\n",
      "\n",
      "Analysis for Time_Spent_Assignment_2 - Task 2 with Controls\n",
      "Number of observations: 108\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    36\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    108.000000\n",
      "mean     166.250000\n",
      "std       59.256314\n",
      "min       25.000000\n",
      "25%      121.500000\n",
      "50%      174.500000\n",
      "75%      211.000000\n",
      "max      240.000000\n",
      "Name: Time_Spent_Assignment_2, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.192578e+02  5.176109e+01  0.000023\n",
      "1               Vincent_dummy -2.908075e+01  1.256261e+01  0.020620\n",
      "2                 GPT01_dummy -2.898714e+01  1.428269e+01  0.042404\n",
      "3                         GPA -1.377274e+01  1.609959e+01  0.392290\n",
      "4    Student Type: 3L Student -9.418933e+00  1.178480e+01  0.424149\n",
      "5   Student Type: LLM Student -4.009962e-15  1.171802e-14  0.732197\n",
      "6           AI Use: 1-5 times  1.917631e+01  1.648214e+01  0.244643\n",
      "7          AI Use: 6-10 times  3.046275e+01  1.729206e+01  0.078127\n",
      "8         AI Use: 11-20 times  2.201133e+01  2.337301e+01  0.346325\n",
      "9  AI Use: More than 20 times  1.006180e+01  2.103276e+01  0.632375\n",
      "\n",
      "Shape before cleaning: (125, 25)\n",
      "Shape after cleaning: (108, 25)\n",
      "\n",
      "Analysis for P2_Productivity - Task 2 with Controls\n",
      "Number of observations: 108\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      38\n",
      "Vincent    36\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    108.000000\n",
      "mean       0.147443\n",
      "std        0.106765\n",
      "min        0.029167\n",
      "25%        0.087593\n",
      "50%        0.112588\n",
      "75%        0.163358\n",
      "max        0.680000\n",
      "Name: P2_Productivity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  5.929478e-02  1.013454e-01  0.558496\n",
      "1               Vincent_dummy  5.911658e-02  2.002973e-02  0.003163\n",
      "2                 GPT01_dummy  8.275810e-02  2.635790e-02  0.001691\n",
      "3                         GPA  1.960824e-02  3.130296e-02  0.531051\n",
      "4    Student Type: 3L Student  1.065282e-02  2.197045e-02  0.627768\n",
      "5   Student Type: LLM Student  2.265552e-17  1.983152e-17  0.253288\n",
      "6           AI Use: 1-5 times -3.635369e-02  2.838488e-02  0.200285\n",
      "7          AI Use: 6-10 times -5.724586e-02  2.815674e-02  0.042041\n",
      "8         AI Use: 11-20 times -5.137381e-02  2.856112e-02  0.072061\n",
      "9  AI Use: More than 20 times -1.684465e-03  4.178118e-02  0.967841\n",
      "\n",
      "==================================================\n",
      "Processing Task 3\n",
      "==================================================\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P3_Criteria_1_Accuracy - Task 3 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.342342\n",
      "std        1.148085\n",
      "min        2.000000\n",
      "25%        5.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P3_Criteria_1_Accuracy, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  3.938435e+00  1.092674e+00  0.000313\n",
      "1               Vincent_dummy  2.429589e-01  2.690286e-01  0.366475\n",
      "2                 GPT01_dummy  4.885484e-01  2.885225e-01  0.090403\n",
      "3                         GPA  3.336775e-01  3.326036e-01  0.315751\n",
      "4    Student Type: 3L Student -3.865146e-02  2.298380e-01  0.866451\n",
      "5   Student Type: LLM Student -6.583429e-16  4.126077e-16  0.110586\n",
      "6           AI Use: 1-5 times  1.763766e-01  3.385037e-01  0.602333\n",
      "7          AI Use: 6-10 times  4.043027e-01  3.663897e-01  0.269820\n",
      "8         AI Use: 11-20 times -7.451689e-01  7.802037e-01  0.339529\n",
      "9  AI Use: More than 20 times -1.893405e-01  3.766898e-01  0.615215\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P3_Criteria_2_Analysis - Task 3 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       4.909910\n",
      "std        1.254443\n",
      "min        0.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P3_Criteria_2_Analysis, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.532466e+00  1.157066e+00  0.000090\n",
      "1               Vincent_dummy  2.364444e-01  2.705150e-01  0.382089\n",
      "2                 GPT01_dummy  4.308596e-01  3.136474e-01  0.169533\n",
      "3                         GPA  1.083001e-02  3.496773e-01  0.975292\n",
      "4    Student Type: 3L Student -2.719684e-01  2.456945e-01  0.268321\n",
      "5   Student Type: LLM Student -5.425428e-16  4.296955e-16  0.206725\n",
      "6           AI Use: 1-5 times  4.646199e-01  3.039371e-01  0.126346\n",
      "7          AI Use: 6-10 times  6.395598e-01  3.518289e-01  0.069092\n",
      "8         AI Use: 11-20 times -1.068977e+00  9.426351e-01  0.256782\n",
      "9  AI Use: More than 20 times  4.772324e-02  4.019955e-01  0.905500\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P3_Criteria_3_Organization - Task 3 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.108108\n",
      "std        1.154842\n",
      "min        2.000000\n",
      "25%        4.500000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P3_Criteria_3_Organization, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.471882e+00  1.111604e+00  0.000057\n",
      "1               Vincent_dummy  3.975455e-01  2.815030e-01  0.157884\n",
      "2                 GPT01_dummy  5.151665e-01  2.915456e-01  0.077225\n",
      "3                         GPA  1.318606e-01  3.362101e-01  0.694913\n",
      "4    Student Type: 3L Student -1.885431e-01  2.351485e-01  0.422666\n",
      "5   Student Type: LLM Student -7.323468e-16  4.420047e-16  0.097545\n",
      "6           AI Use: 1-5 times  1.732476e-02  3.082921e-01  0.955186\n",
      "7          AI Use: 6-10 times  1.815026e-01  3.574011e-01  0.611566\n",
      "8         AI Use: 11-20 times -1.041016e+00  7.839035e-01  0.184181\n",
      "9  AI Use: More than 20 times -2.528349e-02  3.816212e-01  0.947177\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P3_Criteria_4_Clarity - Task 3 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.162162\n",
      "std        1.099922\n",
      "min        1.000000\n",
      "25%        5.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P3_Criteria_4_Clarity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  5.234402e+00  1.034759e+00  4.224079e-07\n",
      "1               Vincent_dummy  4.373324e-02  2.627385e-01  8.678016e-01\n",
      "2                 GPT01_dummy  2.054760e-01  2.822312e-01  4.665883e-01\n",
      "3                         GPA -6.091183e-02  3.068209e-01  8.426338e-01\n",
      "4    Student Type: 3L Student  2.208854e-02  2.226796e-01  9.209840e-01\n",
      "5   Student Type: LLM Student -2.659730e-16  4.189430e-16  5.255154e-01\n",
      "6           AI Use: 1-5 times  1.416818e-01  2.983531e-01  6.348728e-01\n",
      "7          AI Use: 6-10 times  1.369892e-01  3.432157e-01  6.897942e-01\n",
      "8         AI Use: 11-20 times -9.657913e-01  8.564705e-01  2.594715e-01\n",
      "9  AI Use: More than 20 times  3.972241e-02  3.939003e-01  9.196744e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P3_Criteria_5_Professionalism - Task 3 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.342342\n",
      "std        1.239468\n",
      "min        2.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P3_Criteria_5_Professionalism, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.139108e+00  1.101647e+00  0.000172\n",
      "1               Vincent_dummy  6.928050e-01  2.950089e-01  0.018853\n",
      "2                 GPT01_dummy  1.056547e+00  3.222989e-01  0.001045\n",
      "3                         GPA  1.669425e-01  3.180839e-01  0.599696\n",
      "4    Student Type: 3L Student -1.146263e-01  2.340356e-01  0.624289\n",
      "5   Student Type: LLM Student -1.291015e-15  4.736108e-16  0.006413\n",
      "6           AI Use: 1-5 times  1.284607e-01  2.916880e-01  0.659644\n",
      "7          AI Use: 6-10 times  4.850801e-01  3.267226e-01  0.137627\n",
      "8         AI Use: 11-20 times -1.345772e+00  7.217473e-01  0.062237\n",
      "9  AI Use: More than 20 times  2.135807e-01  3.598217e-01  0.552797\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P3_Total_Score - Task 3 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean      25.864865\n",
      "std        5.287183\n",
      "min        7.000000\n",
      "25%       22.000000\n",
      "50%       26.000000\n",
      "75%       30.000000\n",
      "max       34.000000\n",
      "Name: P3_Total_Score, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.231629e+01  4.787153e+00  0.000003\n",
      "1               Vincent_dummy  1.613487e+00  1.212506e+00  0.183286\n",
      "2                 GPT01_dummy  2.696597e+00  1.346073e+00  0.045144\n",
      "3                         GPA  5.823988e-01  1.458771e+00  0.689717\n",
      "4    Student Type: 3L Student -5.917007e-01  1.061084e+00  0.577092\n",
      "5   Student Type: LLM Student -3.490220e-15  1.953909e-15  0.074055\n",
      "6           AI Use: 1-5 times  9.284637e-01  1.390165e+00  0.504210\n",
      "7          AI Use: 6-10 times  1.847434e+00  1.547863e+00  0.232658\n",
      "8         AI Use: 11-20 times -5.166726e+00  3.985532e+00  0.194848\n",
      "9  AI Use: More than 20 times  8.640237e-02  1.686944e+00  0.959152\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (110, 24)\n",
      "\n",
      "Analysis for Time_Spent_Assignment_3 - Task 3 with Controls\n",
      "Number of observations: 110\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    110.000000\n",
      "mean      82.154545\n",
      "std       32.856984\n",
      "min       15.000000\n",
      "25%       57.000000\n",
      "50%       82.500000\n",
      "75%      118.000000\n",
      "max      120.000000\n",
      "Name: Time_Spent_Assignment_3, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  9.504030e+01  2.541254e+01  1.840949e-04\n",
      "1               Vincent_dummy -4.184449e+01  5.631371e+00  1.081028e-13\n",
      "2                 GPT01_dummy -2.785564e+01  6.798856e+00  4.183457e-05\n",
      "3                         GPA  3.626209e+00  7.259403e+00  6.174139e-01\n",
      "4    Student Type: 3L Student  2.736740e+00  5.329215e+00  6.075770e-01\n",
      "5   Student Type: LLM Student  1.360725e-13  2.726524e-14  6.016251e-07\n",
      "6           AI Use: 1-5 times -1.359444e+00  7.622505e+00  8.584512e-01\n",
      "7          AI Use: 6-10 times  2.499520e+00  8.002048e+00  7.547669e-01\n",
      "8         AI Use: 11-20 times  4.725314e+00  1.615106e+01  7.698509e-01\n",
      "9  AI Use: More than 20 times -1.198050e+01  8.878756e+00  1.772265e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (110, 24)\n",
      "\n",
      "Analysis for P3_Productivity - Task 3 with Controls\n",
      "Number of observations: 110\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    110.000000\n",
      "mean       0.412375\n",
      "std        0.316675\n",
      "min        0.091667\n",
      "25%        0.233696\n",
      "50%        0.305409\n",
      "75%        0.460714\n",
      "max        2.000000\n",
      "Name: P3_Productivity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.488420e-01  2.052905e-01  0.225457\n",
      "1               Vincent_dummy  2.845463e-01  6.493487e-02  0.000012\n",
      "2                 GPT01_dummy  1.923916e-01  5.343743e-02  0.000318\n",
      "3                         GPA -1.216630e-02  5.724271e-02  0.831687\n",
      "4    Student Type: 3L Student -2.209531e-02  5.117545e-02  0.665919\n",
      "5   Student Type: LLM Student -8.448938e-16  2.371235e-16  0.000367\n",
      "6           AI Use: 1-5 times  3.951970e-02  6.315280e-02  0.531460\n",
      "7          AI Use: 6-10 times  3.536381e-02  8.507187e-02  0.677634\n",
      "8         AI Use: 11-20 times -1.101530e-01  7.522597e-02  0.143113\n",
      "9  AI Use: More than 20 times  1.770729e-01  1.079836e-01  0.101044\n",
      "\n",
      "==================================================\n",
      "Processing Task 4\n",
      "==================================================\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Criteria_1_Accuracy - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.621622\n",
      "std        0.809647\n",
      "min        3.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P4_Criteria_1_Accuracy, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  5.539463e+00  7.566344e-01  2.457842e-13\n",
      "1               Vincent_dummy -6.960822e-02  1.883883e-01  7.117600e-01\n",
      "2                 GPT01_dummy -2.534650e-01  2.058190e-01  2.181379e-01\n",
      "3                         GPA  2.333656e-02  2.130874e-01  9.127929e-01\n",
      "4    Student Type: 3L Student  1.204281e-01  1.505632e-01  4.237973e-01\n",
      "5   Student Type: LLM Student  4.587974e-16  7.194901e-16  5.236884e-01\n",
      "6           AI Use: 1-5 times  5.317181e-02  2.470959e-01  8.296216e-01\n",
      "7          AI Use: 6-10 times  8.409459e-02  2.945334e-01  7.752473e-01\n",
      "8         AI Use: 11-20 times  6.847638e-02  2.993808e-01  8.190813e-01\n",
      "9  AI Use: More than 20 times  1.016558e-01  2.792630e-01  7.158471e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Criteria_2_Analysis - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       4.837838\n",
      "std        0.847891\n",
      "min        2.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P4_Criteria_2_Analysis, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  4.656509e+00  7.782439e-01  2.185885e-09\n",
      "1               Vincent_dummy -1.486993e-01  1.916077e-01  4.377128e-01\n",
      "2                 GPT01_dummy -2.646638e-01  2.090404e-01  2.054812e-01\n",
      "3                         GPA -4.583906e-03  2.271870e-01  9.839023e-01\n",
      "4    Student Type: 3L Student  1.990642e-01  1.651415e-01  2.280430e-01\n",
      "5   Student Type: LLM Student  1.300339e-15  8.050921e-16  1.062798e-01\n",
      "6           AI Use: 1-5 times  2.332146e-01  2.812664e-01  4.070143e-01\n",
      "7          AI Use: 6-10 times  2.980437e-01  3.031511e-01  3.255324e-01\n",
      "8         AI Use: 11-20 times  3.873192e-01  3.407258e-01  2.556439e-01\n",
      "9  AI Use: More than 20 times  3.965350e-01  2.990731e-01  1.848795e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Criteria_3_Organization - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.009009\n",
      "std        0.814589\n",
      "min        2.000000\n",
      "25%        5.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P4_Criteria_3_Organization, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  4.944906e+00  8.967789e-01  3.506194e-08\n",
      "1               Vincent_dummy  6.069918e-02  1.859870e-01  7.441502e-01\n",
      "2                 GPT01_dummy -4.212731e-01  1.714707e-01  1.401717e-02\n",
      "3                         GPA  2.097196e-02  2.701509e-01  9.381220e-01\n",
      "4    Student Type: 3L Student -1.846591e-01  1.548169e-01  2.329644e-01\n",
      "5   Student Type: LLM Student  7.840287e-16  6.701117e-16  2.420021e-01\n",
      "6           AI Use: 1-5 times  3.754209e-01  2.299015e-01  1.024765e-01\n",
      "7          AI Use: 6-10 times  2.287179e-01  2.582463e-01  3.758019e-01\n",
      "8         AI Use: 11-20 times  2.577766e-01  3.706883e-01  4.868047e-01\n",
      "9  AI Use: More than 20 times  9.757009e-02  2.538901e-01  7.007557e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Criteria_4_Clarity - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.126126\n",
      "std        0.810355\n",
      "min        2.000000\n",
      "25%        5.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P4_Criteria_4_Clarity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  5.157235e+00  9.059358e-01  1.250347e-08\n",
      "1               Vincent_dummy  4.471051e-02  1.568544e-01  7.756099e-01\n",
      "2                 GPT01_dummy -3.631286e-01  1.994507e-01  6.866113e-02\n",
      "3                         GPA -6.807188e-03  2.686693e-01  9.797864e-01\n",
      "4    Student Type: 3L Student -1.276561e-02  1.521731e-01  9.331449e-01\n",
      "5   Student Type: LLM Student  5.488810e-16  6.857703e-16  4.234871e-01\n",
      "6           AI Use: 1-5 times  2.497328e-01  2.444189e-01  3.069034e-01\n",
      "7          AI Use: 6-10 times  5.527283e-02  2.628505e-01  8.334473e-01\n",
      "8         AI Use: 11-20 times  2.504833e-01  4.026053e-01  5.338394e-01\n",
      "9  AI Use: More than 20 times -1.948989e-02  2.458537e-01  9.368144e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Criteria_5_Professionalism - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       5.567568\n",
      "std        1.164799\n",
      "min        2.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P4_Criteria_5_Professionalism, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.637602e+00  9.750393e-01  0.000002\n",
      "1               Vincent_dummy  1.953933e-01  2.354878e-01  0.406687\n",
      "2                 GPT01_dummy -4.803637e-01  2.768625e-01  0.082736\n",
      "3                         GPA  2.449887e-01  2.820159e-01  0.385008\n",
      "4    Student Type: 3L Student -1.117047e-01  2.272507e-01  0.623039\n",
      "5   Student Type: LLM Student  9.213996e-16  1.109066e-15  0.406093\n",
      "6           AI Use: 1-5 times  3.505359e-01  3.895111e-01  0.368153\n",
      "7          AI Use: 6-10 times  3.525874e-01  4.046889e-01  0.383615\n",
      "8         AI Use: 11-20 times  3.239906e-02  5.478076e-01  0.952838\n",
      "9  AI Use: More than 20 times  4.508324e-01  3.975309e-01  0.256760\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Total_Score - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean      26.162162\n",
      "std        3.779227\n",
      "min       12.000000\n",
      "25%       25.000000\n",
      "50%       27.000000\n",
      "75%       28.500000\n",
      "max       34.000000\n",
      "Name: P4_Total_Score, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error       p-value\n",
      "0                       const  2.493571e+01  3.698749e+00  1.565852e-11\n",
      "1               Vincent_dummy  8.249543e-02  7.893044e-01  9.167594e-01\n",
      "2                 GPT01_dummy -1.782894e+00  9.070304e-01  4.934034e-02\n",
      "3                         GPA  2.779061e-01  1.074963e+00  7.960009e-01\n",
      "4    Student Type: 3L Student  1.036295e-02  7.287171e-01  9.886538e-01\n",
      "5   Student Type: LLM Student  4.013445e-15  3.525270e-15  2.549205e-01\n",
      "6           AI Use: 1-5 times  1.262076e+00  1.242470e+00  3.097342e-01\n",
      "7          AI Use: 6-10 times  1.018716e+00  1.315358e+00  4.386481e-01\n",
      "8         AI Use: 11-20 times  9.964545e-01  1.666865e+00  5.499725e-01\n",
      "9  AI Use: More than 20 times  1.027103e+00  1.310414e+00  4.331572e-01\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for Time_Spent_Assignment_4 - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean      86.225225\n",
      "std       45.088738\n",
      "min       13.000000\n",
      "25%       54.500000\n",
      "50%       80.000000\n",
      "75%      118.000000\n",
      "max      180.000000\n",
      "Name: Time_Spent_Assignment_4, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.542105e+02  5.076671e+01  0.002384\n",
      "1               Vincent_dummy -1.770411e+00  1.128277e+01  0.875314\n",
      "2                 GPT01_dummy -1.014915e+01  9.507902e+00  0.285772\n",
      "3                         GPA -1.908654e+01  1.527100e+01  0.211352\n",
      "4    Student Type: 3L Student -1.935156e+01  8.689456e+00  0.025946\n",
      "5   Student Type: LLM Student  4.415308e-14  3.290576e-14  0.179660\n",
      "6           AI Use: 1-5 times  1.272242e+01  1.086361e+01  0.241557\n",
      "7          AI Use: 6-10 times  1.124108e+01  1.306944e+01  0.389731\n",
      "8         AI Use: 11-20 times  3.391576e+01  2.256635e+01  0.132856\n",
      "9  AI Use: More than 20 times  2.738807e-01  1.257133e+01  0.982619\n",
      "\n",
      "Shape before cleaning: (127, 24)\n",
      "Shape after cleaning: (111, 24)\n",
      "\n",
      "Analysis for P4_Productivity - Task 4 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "GPT 01     40\n",
      "No AI      37\n",
      "Vincent    34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       0.428431\n",
      "std        0.312721\n",
      "min        0.105556\n",
      "25%        0.216594\n",
      "50%        0.333333\n",
      "75%        0.516667\n",
      "max        1.687500\n",
      "Name: P4_Productivity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.739256e-01  3.228720e-01  0.396214\n",
      "1               Vincent_dummy  6.240829e-02  7.946671e-02  0.432255\n",
      "2                 GPT01_dummy  2.420648e-02  7.112873e-02  0.733616\n",
      "3                         GPA  3.193855e-02  1.034866e-01  0.757607\n",
      "4    Student Type: 3L Student  1.141137e-01  6.469369e-02  0.077748\n",
      "5   Student Type: LLM Student -1.724283e-16  2.221357e-16  0.437614\n",
      "6           AI Use: 1-5 times -5.835724e-02  8.672533e-02  0.501013\n",
      "7          AI Use: 6-10 times -5.952060e-02  8.800632e-02  0.498836\n",
      "8         AI Use: 11-20 times -1.347670e-01  1.114559e-01  0.226605\n",
      "9  AI Use: More than 20 times  3.185643e-02  1.068280e-01  0.765548\n",
      "\n",
      "==================================================\n",
      "Processing Task 5\n",
      "==================================================\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for P5_Criteria_1_Accuracy - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean       3.955357\n",
      "std        1.371449\n",
      "min        0.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max        6.000000\n",
      "Name: P5_Criteria_1_Accuracy, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.223871e+00  1.118915e+00  0.274042\n",
      "1               Vincent_dummy  1.713263e-01  3.454914e-01  0.619971\n",
      "2                 GPT01_dummy  3.928088e-01  2.772063e-01  0.156475\n",
      "3                         GPA  7.072559e-01  3.382328e-01  0.036525\n",
      "4    Student Type: 3L Student  2.013239e-01  2.689168e-01  0.454070\n",
      "5   Student Type: LLM Student -2.754652e-17  4.120424e-16  0.946698\n",
      "6           AI Use: 1-5 times  1.009466e-01  4.025422e-01  0.801990\n",
      "7          AI Use: 6-10 times  4.115983e-01  4.308824e-01  0.339454\n",
      "8         AI Use: 11-20 times -8.876224e-01  7.997412e-01  0.267048\n",
      "9  AI Use: More than 20 times  2.023579e-01  4.577982e-01  0.658472\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for P5_Criteria_2_Analysis - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean       3.803571\n",
      "std        1.272292\n",
      "min        0.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max        6.000000\n",
      "Name: P5_Criteria_2_Analysis, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.283869e+00  9.776613e-01  0.019488\n",
      "1               Vincent_dummy  4.032445e-01  2.939497e-01  0.170121\n",
      "2                 GPT01_dummy  8.193602e-01  2.838508e-01  0.003894\n",
      "3                         GPA  2.555306e-01  2.910172e-01  0.379911\n",
      "4    Student Type: 3L Student  4.313008e-01  2.423629e-01  0.075147\n",
      "5   Student Type: LLM Student -3.334364e-16  3.504431e-16  0.341365\n",
      "6           AI Use: 1-5 times  1.735212e-02  3.516894e-01  0.960649\n",
      "7          AI Use: 6-10 times  2.295383e-01  3.846209e-01  0.550647\n",
      "8         AI Use: 11-20 times -3.225012e-01  6.221322e-01  0.604193\n",
      "9  AI Use: More than 20 times  1.993234e-01  4.116454e-01  0.628236\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for P5_Criteria_3_Organization - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean       4.241071\n",
      "std        1.453455\n",
      "min        0.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        6.000000\n",
      "Name: P5_Criteria_3_Organization, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.456708e+00  1.081268e+00  0.023083\n",
      "1               Vincent_dummy  8.572803e-01  3.504855e-01  0.014446\n",
      "2                 GPT01_dummy  1.394902e+00  2.865991e-01  0.000001\n",
      "3                         GPA  2.620412e-01  3.423703e-01  0.444049\n",
      "4    Student Type: 3L Student  3.824239e-01  2.676416e-01  0.153043\n",
      "5   Student Type: LLM Student -4.690705e-16  4.121770e-16  0.255107\n",
      "6           AI Use: 1-5 times  1.366745e-01  4.211059e-01  0.745513\n",
      "7          AI Use: 6-10 times -1.275145e-01  4.118738e-01  0.756868\n",
      "8         AI Use: 11-20 times -2.546901e-01  5.812919e-01  0.661281\n",
      "9  AI Use: More than 20 times -1.939785e-02  4.587431e-01  0.966272\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P5_Criteria_4_Clarity - Task 5 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       3.855856\n",
      "std        0.932707\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        4.000000\n",
      "max        6.000000\n",
      "Name: P5_Criteria_4_Clarity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  2.575088e+00  8.287064e-01  0.001888\n",
      "1               Vincent_dummy  4.332004e-01  2.126370e-01  0.041622\n",
      "2                 GPT01_dummy  7.537408e-01  2.027294e-01  0.000201\n",
      "3                         GPA  1.921214e-01  2.448034e-01  0.432572\n",
      "4    Student Type: 3L Student  1.250876e-01  1.692324e-01  0.459818\n",
      "5   Student Type: LLM Student  6.705388e-16  2.719640e-16  0.013681\n",
      "6           AI Use: 1-5 times  2.688954e-01  2.426549e-01  0.267802\n",
      "7          AI Use: 6-10 times  1.025870e-02  2.895624e-01  0.971738\n",
      "8         AI Use: 11-20 times  3.902383e-01  3.207203e-01  0.223697\n",
      "9  AI Use: More than 20 times  4.363790e-01  2.627296e-01  0.096725\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for P5_Criteria_5_Professionalism - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean       4.080357\n",
      "std        1.622690\n",
      "min        0.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P5_Criteria_5_Professionalism, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  3.306852e+00  1.255674e+00  0.008450\n",
      "1               Vincent_dummy  5.081913e-01  3.810926e-01  0.182364\n",
      "2                 GPT01_dummy  1.449652e+00  3.319791e-01  0.000013\n",
      "3                         GPA -1.042173e-01  3.944203e-01  0.791603\n",
      "4    Student Type: 3L Student  6.163433e-01  2.895519e-01  0.033287\n",
      "5   Student Type: LLM Student -6.540496e-16  4.425391e-16  0.139422\n",
      "6           AI Use: 1-5 times  3.306913e-01  4.350979e-01  0.447231\n",
      "7          AI Use: 6-10 times  2.734988e-01  4.809697e-01  0.569600\n",
      "8         AI Use: 11-20 times -2.076763e-01  6.604545e-01  0.753183\n",
      "9  AI Use: More than 20 times  1.533557e-01  4.951481e-01  0.756776\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for P5_Total_Score - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean      19.901786\n",
      "std        5.855558\n",
      "min        2.000000\n",
      "25%       16.750000\n",
      "50%       21.000000\n",
      "75%       24.250000\n",
      "max       30.000000\n",
      "Name: P5_Total_Score, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.152383e+01  4.098697e+00  0.004930\n",
      "1               Vincent_dummy  2.344460e+00  1.417559e+00  0.098154\n",
      "2                 GPT01_dummy  4.708546e+00  1.202845e+00  0.000091\n",
      "3                         GPA  1.435937e+00  1.266679e+00  0.256952\n",
      "4    Student Type: 3L Student  1.677847e+00  1.090459e+00  0.123887\n",
      "5   Student Type: LLM Student -1.979697e-15  1.581789e-15  0.210732\n",
      "6           AI Use: 1-5 times  8.443654e-01  1.659292e+00  0.610843\n",
      "7          AI Use: 6-10 times  6.190254e-01  1.740342e+00  0.722071\n",
      "8         AI Use: 11-20 times -1.328760e+00  2.428716e+00  0.584307\n",
      "9  AI Use: More than 20 times  9.689317e-01  1.870029e+00  0.604363\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for Time_Spent_Assignment_5 - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean      83.357143\n",
      "std       38.297992\n",
      "min       10.000000\n",
      "25%       55.000000\n",
      "50%       78.000000\n",
      "75%      118.500000\n",
      "max      150.000000\n",
      "Name: Time_Spent_Assignment_5, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.250113e+02  4.543248e+01  0.005931\n",
      "1               Vincent_dummy -1.773135e+01  8.552062e+00  0.038140\n",
      "2                 GPT01_dummy -1.843519e+01  8.995642e+00  0.040428\n",
      "3                         GPA -5.664505e+00  1.338853e+01  0.672232\n",
      "4    Student Type: 3L Student -1.086518e+01  7.191044e+00  0.130806\n",
      "5   Student Type: LLM Student  1.565944e-14  9.540531e-15  0.100723\n",
      "6           AI Use: 1-5 times -6.797669e+00  1.001932e+01  0.497483\n",
      "7          AI Use: 6-10 times -1.673299e+00  1.231119e+01  0.891887\n",
      "8         AI Use: 11-20 times  1.851425e+00  1.722151e+01  0.914387\n",
      "9  AI Use: More than 20 times -1.678127e+01  1.180827e+01  0.155274\n",
      "\n",
      "Shape before cleaning: (127, 25)\n",
      "Shape after cleaning: (112, 25)\n",
      "\n",
      "Analysis for P5_Productivity - Task 5 with Controls\n",
      "Number of observations: 112\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "No AI      40\n",
      "Vincent    37\n",
      "GPT 01     35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    112.000000\n",
      "mean       0.326910\n",
      "std        0.290093\n",
      "min        0.046154\n",
      "25%        0.181264\n",
      "50%        0.244810\n",
      "75%        0.373750\n",
      "max        2.000000\n",
      "Name: P5_Productivity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.545969e-01  3.200032e-01  0.629017\n",
      "1               Vincent_dummy  8.756160e-02  5.392293e-02  0.104412\n",
      "2                 GPT01_dummy  1.792139e-01  7.437470e-02  0.015970\n",
      "3                         GPA  3.250616e-02  8.935015e-02  0.716003\n",
      "4    Student Type: 3L Student  8.430986e-02  5.470667e-02  0.123286\n",
      "5   Student Type: LLM Student  7.747662e-18  8.474214e-17  0.927154\n",
      "6           AI Use: 1-5 times -7.203403e-02  1.060725e-01  0.497073\n",
      "7          AI Use: 6-10 times -1.253017e-01  1.134939e-01  0.269576\n",
      "8         AI Use: 11-20 times -1.510308e-01  1.029621e-01  0.142415\n",
      "9  AI Use: More than 20 times -1.090036e-02  1.216930e-01  0.928627\n",
      "\n",
      "==================================================\n",
      "Processing Task 6\n",
      "==================================================\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Criteria_1_Accuracy - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       3.297297\n",
      "std        1.786793\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P6_Criteria_1_Accuracy, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  7.859202e-01  1.789027e+00  0.660444\n",
      "1               Vincent_dummy -7.337989e-01  4.215083e-01  0.081703\n",
      "2                 GPT01_dummy  4.309585e-01  4.094712e-01  0.292581\n",
      "3                         GPA  8.573233e-01  5.321345e-01  0.107157\n",
      "4    Student Type: 3L Student -4.942369e-01  3.284623e-01  0.132401\n",
      "5   Student Type: LLM Student -1.182102e-16  5.460153e-16  0.828601\n",
      "6           AI Use: 1-5 times  2.087474e-01  4.408434e-01  0.635844\n",
      "7          AI Use: 6-10 times  6.907403e-01  5.445602e-01  0.204642\n",
      "8         AI Use: 11-20 times -1.134766e+00  5.703025e-01  0.046617\n",
      "9  AI Use: More than 20 times -6.503463e-01  3.824314e-01  0.089026\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Criteria_2_Analysis - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       3.675676\n",
      "std        1.641298\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max        7.000000\n",
      "Name: P6_Criteria_2_Analysis, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  8.819584e-01  1.709537e+00  0.605921\n",
      "1               Vincent_dummy -3.736032e-01  4.133363e-01  0.366063\n",
      "2                 GPT01_dummy  7.749057e-01  3.869311e-01  0.045210\n",
      "3                         GPA  8.477182e-01  5.230050e-01  0.105048\n",
      "4    Student Type: 3L Student -1.601222e-01  3.133983e-01  0.609405\n",
      "5   Student Type: LLM Student -4.528711e-16  5.703779e-16  0.427205\n",
      "6           AI Use: 1-5 times -7.153984e-02  4.165264e-01  0.863631\n",
      "7          AI Use: 6-10 times  3.105515e-01  5.210124e-01  0.551139\n",
      "8         AI Use: 11-20 times -7.062619e-01  6.936136e-01  0.308566\n",
      "9  AI Use: More than 20 times -3.166559e-01  4.257216e-01  0.456992\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Criteria_3_Organization - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       4.216216\n",
      "std        1.795982\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P6_Criteria_3_Organization, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  6.289870e-01  1.817105e+00  0.729232\n",
      "1               Vincent_dummy -5.430558e-01  4.359876e-01  0.212920\n",
      "2                 GPT01_dummy  9.379475e-01  4.236757e-01  0.026840\n",
      "3                         GPA  1.193539e+00  5.259793e-01  0.023258\n",
      "4    Student Type: 3L Student -5.246648e-01  3.418492e-01  0.124837\n",
      "5   Student Type: LLM Student -4.353572e-16  5.905059e-16  0.460963\n",
      "6           AI Use: 1-5 times -3.499653e-01  4.344916e-01  0.420555\n",
      "7          AI Use: 6-10 times  1.513116e-01  5.473529e-01  0.782208\n",
      "8         AI Use: 11-20 times -1.130299e+00  5.015821e-01  0.024230\n",
      "9  AI Use: More than 20 times -3.655466e-01  4.591003e-01  0.425902\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Criteria_4_Clarity - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       4.810811\n",
      "std        1.254182\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P6_Criteria_4_Clarity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  1.477422e+00  1.286509e+00  0.250805\n",
      "1               Vincent_dummy  2.223714e-01  3.248764e-01  0.493672\n",
      "2                 GPT01_dummy  7.088339e-01  3.093212e-01  0.021930\n",
      "3                         GPA  8.947112e-01  3.712592e-01  0.015955\n",
      "4    Student Type: 3L Student -7.426380e-02  2.534722e-01  0.769533\n",
      "5   Student Type: LLM Student -4.367554e-16  4.501870e-16  0.331965\n",
      "6           AI Use: 1-5 times  4.809995e-02  3.058903e-01  0.875051\n",
      "7          AI Use: 6-10 times  1.458710e-01  3.966864e-01  0.713079\n",
      "8         AI Use: 11-20 times -2.325188e-01  4.260280e-01  0.585215\n",
      "9  AI Use: More than 20 times  3.011488e-01  3.138194e-01  0.337244\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Criteria_5_Professionalism - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       4.576577\n",
      "std        1.965843\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        7.000000\n",
      "Name: P6_Criteria_5_Professionalism, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  7.811289e-01  1.980565e+00  0.693288\n",
      "1               Vincent_dummy -3.503735e-01  4.731639e-01  0.459002\n",
      "2                 GPT01_dummy  1.216611e+00  4.307433e-01  0.004736\n",
      "3                         GPA  1.295929e+00  5.993160e-01  0.030592\n",
      "4    Student Type: 3L Student -4.408365e-01  3.705973e-01  0.234231\n",
      "5   Student Type: LLM Student -1.149955e-15  6.527497e-16  0.078118\n",
      "6           AI Use: 1-5 times -5.370450e-01  4.461607e-01  0.228704\n",
      "7          AI Use: 6-10 times -3.611970e-01  5.675029e-01  0.524472\n",
      "8         AI Use: 11-20 times -1.350516e+00  8.119094e-01  0.096236\n",
      "9  AI Use: More than 20 times -1.161558e+00  5.121693e-01  0.023334\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Total_Score - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean      20.576577\n",
      "std        7.421773\n",
      "min        6.000000\n",
      "25%       14.000000\n",
      "50%       21.000000\n",
      "75%       27.000000\n",
      "max       34.000000\n",
      "Name: P6_Total_Score, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  4.555416e+00  7.873841e+00  0.562892\n",
      "1               Vincent_dummy -1.778460e+00  1.840849e+00  0.333990\n",
      "2                 GPT01_dummy  4.069256e+00  1.736964e+00  0.019143\n",
      "3                         GPA  5.089221e+00  2.354221e+00  0.030638\n",
      "4    Student Type: 3L Student -1.694124e+00  1.413417e+00  0.230683\n",
      "5   Student Type: LLM Student -2.593149e-15  2.459856e-15  0.291797\n",
      "6           AI Use: 1-5 times -7.017029e-01  1.755499e+00  0.689365\n",
      "7          AI Use: 6-10 times  9.372774e-01  2.277666e+00  0.680700\n",
      "8         AI Use: 11-20 times -4.554362e+00  2.321031e+00  0.049737\n",
      "9  AI Use: More than 20 times -2.192958e+00  1.711879e+00  0.200185\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for Time_Spent_Assignment_6 - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean      85.918919\n",
      "std       40.934123\n",
      "min        8.000000\n",
      "25%       60.000000\n",
      "50%       86.000000\n",
      "75%      118.000000\n",
      "max      150.000000\n",
      "Name: Time_Spent_Assignment_6, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const  5.986043e+01  3.556714e+01  0.092370\n",
      "1               Vincent_dummy -4.070033e+01  8.737313e+00  0.000003\n",
      "2                 GPT01_dummy -2.656255e+01  9.085496e+00  0.003460\n",
      "3                         GPA  1.583648e+01  1.025513e+01  0.122528\n",
      "4    Student Type: 3L Student -4.335768e+00  6.920342e+00  0.530971\n",
      "5   Student Type: LLM Student  4.294064e-14  1.294511e-14  0.000909\n",
      "6           AI Use: 1-5 times -2.030199e+00  8.970677e+00  0.820956\n",
      "7          AI Use: 6-10 times  1.166646e+01  1.056670e+01  0.269559\n",
      "8         AI Use: 11-20 times  4.791644e+00  1.828264e+01  0.793254\n",
      "9  AI Use: More than 20 times -1.551687e+01  1.158079e+01  0.180284\n",
      "\n",
      "Shape before cleaning: (126, 25)\n",
      "Shape after cleaning: (111, 25)\n",
      "\n",
      "Analysis for P6_Productivity - Task 6 with Controls\n",
      "Number of observations: 111\n",
      "\n",
      "Sample breakdown:\n",
      "AI_Condition\n",
      "Vincent    39\n",
      "GPT 01     37\n",
      "No AI      35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome variable summary:\n",
      "count    111.000000\n",
      "mean       0.359671\n",
      "std        0.403436\n",
      "min        0.040000\n",
      "25%        0.178889\n",
      "50%        0.241379\n",
      "75%        0.354104\n",
      "max        2.750000\n",
      "Name: P6_Productivity, dtype: float64\n",
      "\n",
      "Regression Results:\n",
      "                     Variable   Coefficient    Std. Error   p-value\n",
      "0                       const -1.336994e-01  2.776038e-01  0.630076\n",
      "1               Vincent_dummy  1.680672e-01  5.258175e-02  0.001392\n",
      "2                 GPT01_dummy  2.743127e-01  9.421372e-02  0.003596\n",
      "3                         GPA  1.172497e-01  8.383735e-02  0.161952\n",
      "4    Student Type: 3L Student -3.229654e-02  7.136374e-02  0.650864\n",
      "5   Student Type: LLM Student -2.677678e-16  1.359615e-16  0.048903\n",
      "6           AI Use: 1-5 times -7.013052e-02  1.246812e-01  0.573790\n",
      "7          AI Use: 6-10 times -7.401431e-02  1.145869e-01  0.518329\n",
      "8         AI Use: 11-20 times -2.231988e-01  1.397198e-01  0.110160\n",
      "9  AI Use: More than 20 times  1.216142e-01  1.673957e-01  0.467528\n"
     ]
    }
   ],
   "source": [
    "# Load numeric controls (GPA, AI Use, and Student Type)\n",
    "controls_numeric_file = os.path.join(analysis_path, \"controls_numeric.csv\")\n",
    "controls_numeric_df = pd.read_csv(controls_numeric_file)\n",
    "\n",
    "print(f\"\\nLoaded controls from: {controls_numeric_file}\")\n",
    "print(controls_numeric_df.head())\n",
    "\n",
    "# Ensure correct data types for GPA\n",
    "controls_numeric_df['GPA'] = pd.to_numeric(controls_numeric_df['GPA'], errors='coerce')\n",
    "\n",
    "# ✅ **Fix: Convert Student_Type and AI_Use to integers explicitly**\n",
    "controls_numeric_df['Student_Type'] = controls_numeric_df['Student_Type'].fillna(0).astype(int)\n",
    "controls_numeric_df['AI_Use'] = controls_numeric_df['AI_Use'].fillna(0).astype(int)\n",
    "\n",
    "# Convert Student_Type and AI_Use to categorical dummies, dropping the first category to avoid multicollinearity\n",
    "controls_numeric_df = pd.get_dummies(controls_numeric_df, columns=['Student_Type', 'AI_Use'], drop_first=True)\n",
    "\n",
    "# Function to load task data and merge with controls\n",
    "def load_and_merge_task(task_num):\n",
    "    task_file = os.path.join(analysis_path, f\"task{task_num}_data_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(task_file):\n",
    "        print(f\"Warning: {task_file} not found!\")\n",
    "        return None\n",
    "\n",
    "    task_df = pd.read_csv(task_file)\n",
    "\n",
    "    # Merge with controls\n",
    "    merged_df = task_df.merge(controls_numeric_df, on='Student_Number', how='left')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Load all task dataframes\n",
    "task_dfs = {}\n",
    "for task_num in range(1, 7):\n",
    "    task_dfs[task_num] = load_and_merge_task(task_num)\n",
    "\n",
    "\n",
    "# Function to analyze outcome with controls (includes Student Type and AI Use)\n",
    "def analyze_outcome_with_controls(df, outcome_var, task_num):\n",
    "    if df is None or outcome_var not in df.columns:\n",
    "        print(f\"Skipping analysis for {outcome_var} - Task {task_num} (data missing)\")\n",
    "        return None\n",
    "\n",
    "    # Convert outcome variable to numeric\n",
    "    df[outcome_var] = pd.to_numeric(df[outcome_var], errors='coerce')\n",
    "\n",
    "    # Create treatment dummies\n",
    "    df['Vincent_dummy'] = (df['AI_Condition'] == 'Vincent').astype(float)\n",
    "    df['GPT01_dummy'] = (df['AI_Condition'] == 'GPT 01').astype(float)\n",
    "\n",
    "    # Identify control variables dynamically (GPA + all Student_Type and AI_Use dummies)\n",
    "    control_vars = ['Vincent_dummy', 'GPT01_dummy', 'GPA'] + \\\n",
    "                   [col for col in df.columns if 'Student_Type_' in col or 'AI_Use_' in col]\n",
    "\n",
    "    # Clean data for regression\n",
    "    df_clean = df.dropna(subset=[outcome_var] + control_vars)\n",
    "\n",
    "    # Print debugging info\n",
    "    print(f\"\\nShape before cleaning: {df.shape}\")\n",
    "    print(f\"Shape after cleaning: {df_clean.shape}\")\n",
    "\n",
    "    # Prepare X and y with control variables\n",
    "    X = df_clean[control_vars].astype(float)\n",
    "    X = sm.add_constant(X)\n",
    "    y = df_clean[outcome_var].astype(float)\n",
    "\n",
    "    # Run regression\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit(cov_type='HC1')\n",
    "\n",
    "    # Map AI Use and Student Type coefficients back to readable labels\n",
    "    def map_variable_names(var):\n",
    "        if \"AI_Use_\" in var:\n",
    "            num_value = int(var.split(\"_\")[-1])\n",
    "            return f\"AI Use: {ai_use_mapping.get(num_value, 'Unknown')}\"\n",
    "        elif \"Student_Type_\" in var:\n",
    "            num_value = int(var.split(\"_\")[-1])\n",
    "            return f\"Student Type: {student_type_mapping.get(num_value, 'Unknown')}\"\n",
    "        return var\n",
    "\n",
    "    # Rename coefficients for better readability\n",
    "    coef_labels = [map_variable_names(var) for var in results.params.index]\n",
    "\n",
    "    # Print output in readable format\n",
    "    print(f\"\\nAnalysis for {outcome_var} - Task {task_num} with Controls\")\n",
    "    print(f\"Number of observations: {len(df_clean)}\")\n",
    "    print(\"\\nSample breakdown:\")\n",
    "    print(df_clean['AI_Condition'].value_counts())\n",
    "    print(\"\\nOutcome variable summary:\")\n",
    "    print(df_clean[outcome_var].describe())\n",
    "    print(\"\\nRegression Results:\")\n",
    "    \n",
    "    # Format regression output with readable labels\n",
    "    summary_table = pd.DataFrame({\n",
    "        \"Variable\": coef_labels,\n",
    "        \"Coefficient\": results.params.values,\n",
    "        \"Std. Error\": results.bse.values,\n",
    "        \"p-value\": results.pvalues.values\n",
    "    })\n",
    "    print(summary_table)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run regressions for all tasks and outcomes with updated column names\n",
    "for task_num, df in task_dfs.items():\n",
    "    if df is None:\n",
    "        continue\n",
    "\n",
    "    outcomes = [\n",
    "        f'P{task_num}_Criteria_1_Accuracy',\n",
    "        f'P{task_num}_Criteria_2_Analysis',\n",
    "        f'P{task_num}_Criteria_3_Organization',\n",
    "        f'P{task_num}_Criteria_4_Clarity',\n",
    "        f'P{task_num}_Criteria_5_Professionalism',\n",
    "        f'P{task_num}_Total_Score',\n",
    "        time_cols[task_num],\n",
    "        f'P{task_num}_Productivity'\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing Task {task_num}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            results = analyze_outcome_with_controls(df, outcome, task_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {outcome}\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_treatment_effects_with_controls(df, outcome_var, task_num, controls_numeric_df=None, \n",
    "                                            student_type_mapping=None, ai_use_mapping=None):\n",
    "    \"\"\"Extract treatment effects and control variable coefficients with robust handling.\"\"\"\n",
    "    \n",
    "    if df is None:\n",
    "        print(f\"⚠️ No data for Task {task_num}\")\n",
    "        return None\n",
    "\n",
    "    if outcome_var not in df.columns:\n",
    "        print(f\"⚠️ Column {outcome_var} not found in task dataframe\")\n",
    "        return None\n",
    "\n",
    "    # Merge missing control variables (if needed)\n",
    "    if controls_numeric_df is not None and 'GPA' not in df.columns:\n",
    "        try:\n",
    "            common_cols = df.columns.intersection(controls_numeric_df.columns)\n",
    "            df = df.join(controls_numeric_df.drop(columns=common_cols), how='left')\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error joining control_numeric_df: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Convert outcome and control variables to numeric\n",
    "    df[outcome_var] = pd.to_numeric(df[outcome_var], errors='coerce')\n",
    "    df['GPA'] = pd.to_numeric(df.get('GPA'), errors='coerce')\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.startswith(('Student_Type_', 'AI_Use_')):\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Create treatment dummies\n",
    "    df['Vincent_dummy'] = (df['AI_Condition'] == 'Vincent').astype(float)\n",
    "    df['GPT01_dummy'] = (df['AI_Condition'] == 'GPT 01').astype(float)\n",
    "\n",
    "    # Define control variables\n",
    "    control_vars = ['Vincent_dummy', 'GPT01_dummy', 'GPA']\n",
    "    student_type_vars = sorted([col for col in df.columns if col.startswith('Student_Type_')])\n",
    "    ai_use_vars = sorted([col for col in df.columns if col.startswith('AI_Use_')])\n",
    "\n",
    "    # Ensure unique control variables\n",
    "    all_vars = list(dict.fromkeys(control_vars + student_type_vars + ai_use_vars))\n",
    "\n",
    "    # Drop missing values\n",
    "    df_clean = df.dropna(subset=[outcome_var] + all_vars)\n",
    "    if len(df_clean) < 10:\n",
    "        print(f\"⚠️ Too few observations ({len(df_clean)}) for Task {task_num}, Outcome {outcome_var}\")\n",
    "        return None\n",
    "\n",
    "    X_clean = df_clean[all_vars].astype(float)\n",
    "    y_clean = df_clean[outcome_var].astype(float)\n",
    "\n",
    "    # Calculate control group mean\n",
    "    control_mean = df_clean[df_clean['AI_Condition'] == 'No AI'][outcome_var].mean()\n",
    "\n",
    "    # Run regression\n",
    "    X = sm.add_constant(X_clean)\n",
    "    y = y_clean\n",
    "\n",
    "    try:\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit(cov_type='HC1')\n",
    "\n",
    "        # Extract treatment effects\n",
    "        effects = []\n",
    "        for label, dummy in [('Vincent', 'Vincent_dummy'), ('o1-preview', 'GPT01_dummy')]:\n",
    "            coef = results.params[dummy]\n",
    "            se = results.bse[dummy]\n",
    "            pval = results.pvalues[dummy]\n",
    "            pct_change = (coef / control_mean) * 100 if control_mean else None\n",
    "\n",
    "            effect_str, se_str = format_coefficient(coef, se, pval)\n",
    "            pct_str = format_pct_change(pct_change)\n",
    "\n",
    "            effects.append({\n",
    "                'Model': label,\n",
    "                'Effect': effect_str,\n",
    "                'SE': se_str,\n",
    "                'Pct Change': pct_str,\n",
    "                'N': len(df_clean)\n",
    "            })\n",
    "\n",
    "        # Extract control variable coefficients\n",
    "        controls = []\n",
    "        if 'GPA' in results.params:\n",
    "            coef = results.params['GPA']\n",
    "            se = results.bse['GPA']\n",
    "            pval = results.pvalues['GPA']\n",
    "            effect_str, se_str = format_coefficient(coef, se, pval)\n",
    "            controls.append({'name': 'GPA', 'coef': effect_str, 'se': se_str})\n",
    "\n",
    "        for var in results.params.index:\n",
    "            if var not in ['const', 'GPA', 'Vincent_dummy', 'GPT01_dummy']:\n",
    "                coef = results.params[var]\n",
    "                se = results.bse[var]\n",
    "                pval = results.pvalues[var]\n",
    "                effect_str, se_str = format_coefficient(coef, se, pval)\n",
    "\n",
    "                # Format variable name\n",
    "                if var.startswith('Student_Type_') and student_type_mapping:\n",
    "                    type_num = int(var.split('_')[-1])\n",
    "                    var_name = f\"{student_type_mapping.get(type_num, 'Unknown')} (vs. 2L)\"\n",
    "                elif var.startswith('AI_Use_') and ai_use_mapping:\n",
    "                    use_num = int(var.split('_')[-1])\n",
    "                    var_name = f\"{ai_use_mapping.get(use_num, 'Unknown')} (vs. 0 Times)\"\n",
    "                else:\n",
    "                    var_name = var\n",
    "\n",
    "                controls.append({'name': var_name, 'coef': effect_str, 'se': se_str})\n",
    "\n",
    "        return {\n",
    "            'effects': effects,\n",
    "            'controls': controls,\n",
    "            'control_mean': control_mean,\n",
    "            'n_obs': len(df_clean)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error in regression for Task {task_num}, Outcome {outcome_var}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_task_table_with_controls(task_num, task_name, df, tables_path):\n",
    "    \"\"\"Generate LaTeX table for a specific task including all controls\"\"\"\n",
    "    print(f\"\\nProcessing Task {task_num}: {task_name}\")\n",
    "    \n",
    "    if df is None:\n",
    "        print(f\"⚠️ No data for Task {task_num}\")\n",
    "        return\n",
    "    \n",
    "    # Define outcomes\n",
    "    outcomes = {\n",
    "        'Accuracy': f'P{task_num}_Criteria_1_Accuracy',\n",
    "        'Analysis': f'P{task_num}_Criteria_2_Analysis',\n",
    "        'Organization': f'P{task_num}_Criteria_3_Organization',\n",
    "        'Clarity': f'P{task_num}_Criteria_4_Clarity',\n",
    "        'Professionalism': f'P{task_num}_Criteria_5_Professionalism',\n",
    "        'Total Score': f'P{task_num}_Total_Score',\n",
    "        'Time Spent': f'Time_Spent_Assignment_{task_num}',\n",
    "        'Productivity': f'P{task_num}_Productivity'\n",
    "    }\n",
    "    \n",
    "    # Collect results\n",
    "    results_data = []\n",
    "    control_data = None\n",
    "    \n",
    "    for outcome_name, outcome_var in outcomes.items():\n",
    "        result = extract_treatment_effects_with_controls(df, outcome_var, task_num)\n",
    "        if result is None:\n",
    "            continue\n",
    "            \n",
    "        # Store treatment effects\n",
    "        for effect in result['effects']:\n",
    "            results_data.append({\n",
    "                'Outcome': outcome_name,\n",
    "                'Control Mean': f\"${result['control_mean']:.2f}$\",\n",
    "                **effect\n",
    "            })\n",
    "        \n",
    "        # Store control effects (only need to do this once)\n",
    "        if control_data is None:\n",
    "            control_data = result['controls']\n",
    "    \n",
    "    if not results_data:\n",
    "        print(f\"⚠️ No results to display for Task {task_num}\")\n",
    "        return\n",
    "    \n",
    "    # Generate LaTeX table\n",
    "    latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "    latex_table += f\"\\\\caption{{Treatment Effects for {task_name} (With Controls)}}\\n\"\n",
    "    latex_table += f\"\\\\label{{tab:task{task_num}_effects_controls}}\\n\"\n",
    "    latex_table += \"\\\\vspace{0.3cm}\\n\"  # vertical space after title\n",
    "    \n",
    "    # Panel A: Treatment Effects\n",
    "    latex_table += \"\\\\begin{tabular}{lcccccc}\\n\"\n",
    "    latex_table += \"\\\\multicolumn{7}{l}{\\\\textbf{Panel A: Treatment Effects}} \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "    latex_table += \"Outcome & Control Mean & Model & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "    \n",
    "    current_outcome = None\n",
    "    for row in results_data:\n",
    "        if current_outcome != row['Outcome']:\n",
    "            current_outcome = row['Outcome']\n",
    "            # First row: include multirow cells and then treatment effect\n",
    "            latex_table += (\n",
    "                f\"\\\\multirow{{2}}{{*}}{{{row['Outcome']}}} & \"\n",
    "                f\"\\\\multirow{{2}}{{*}}{{{row['Control Mean']}}} & \"\n",
    "                f\"{row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "            )\n",
    "        else:\n",
    "            # Second row: leave outcome and control mean cells empty\n",
    "            latex_table += (\n",
    "                f\"& & {row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "            )\n",
    "            latex_table += \"\\\\hline\\n\"\n",
    "    \n",
    "    latex_table += \"\\\\end{tabular}\\n\\n\"\n",
    "    latex_table += \"\\\\vspace{0.3cm}\\n\\n\"  # vertical space between Panel A and Panel B\n",
    "    \n",
    "    # Panel B: Control Variables\n",
    "    if control_data:\n",
    "        latex_table += \"\\\\begin{tabular}{lcc}\\n\"\n",
    "        latex_table += \"\\\\multicolumn{3}{l}{\\\\textbf{Panel B: Control Variables}} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "        latex_table += \"Variable & Coefficient & SE \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "        \n",
    "        for control in control_data:\n",
    "            latex_table += f\"{control['name']} & {control['coef']} & {control['se']} \\\\\\\\\\n\"\n",
    "        \n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "        latex_table += \"\\\\end{tabular}\\n\"\n",
    "    \n",
    "    # Add notes\n",
    "    latex_table += \"\\\\begin{tablenotes}\\n\\\\small\\n\"\n",
    "    latex_table += (\n",
    "        \"\\\\item \\\\textit{Notes:} Effects shown relative to No AI control group. \"\n",
    "        \"For quality criteria (Accuracy through Professionalism), scoring scale is 1-7. \"\n",
    "        \"Total Score ranges from 5-35. Time Spent shows minutes. \"\n",
    "        \"Productivity measures points earned per minute. \"\n",
    "        \"AI use frequency refers to the last three months. \"\n",
    "        \"Robust standard errors in parentheses. \"\n",
    "        \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$\\n\"\n",
    "    )\n",
    "    latex_table += \"\\\\end{tablenotes}\\n\"\n",
    "    \n",
    "    latex_table += \"\\\\end{table}\"\n",
    "    \n",
    "    # Save the table\n",
    "    os.makedirs(tables_path, exist_ok=True)\n",
    "    table_file_path = os.path.join(tables_path, f\"task{task_num}_effects_with_controls.tex\")\n",
    "    with open(table_file_path, \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "    \n",
    "    print(f\"✅ Saved LaTeX table: {table_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Task 1: Draft Client Email\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task1_effects_with_controls.tex\n",
      "\n",
      "Processing Task 2: Draft Legal Memo\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task2_effects_with_controls.tex\n",
      "\n",
      "Processing Task 3: Analysis of Complaint\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task3_effects_with_controls.tex\n",
      "\n",
      "Processing Task 4: Draft NDA\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task4_effects_with_controls.tex\n",
      "\n",
      "Processing Task 5: Draft Motion to Consolidate\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task5_effects_with_controls.tex\n",
      "\n",
      "Processing Task 6: Draft CNC Enforcement Letter\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task6_effects_with_controls.tex\n"
     ]
    }
   ],
   "source": [
    "def generate_all_tables(task_dfs, master_folder):\n",
    "    \"\"\"Generate tables for all tasks\"\"\"\n",
    "    \n",
    "    task_names = {\n",
    "        1: \"Draft Client Email\",\n",
    "        2: \"Draft Legal Memo\",\n",
    "        3: \"Analysis of Complaint\",\n",
    "        4: \"Draft NDA\",\n",
    "        5: \"Draft Motion to Consolidate\",\n",
    "        6: \"Draft CNC Enforcement Letter\"\n",
    "    }\n",
    "\n",
    "    for task_num, task_name in task_names.items():\n",
    "        if task_num in task_dfs:\n",
    "            create_task_table_with_controls(task_num, task_name, task_dfs[task_num], tables_path)\n",
    "        else:\n",
    "            print(f\"⚠️ No data for Task {task_num}\")\n",
    "\n",
    "# Now run the function\n",
    "generate_all_tables(task_dfs, master_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TABLE GENERATION FOR OUTCOMES ---\n",
    "def create_outcome_table_with_controls(outcome, outcome_map, task_dfs, tables_path):\n",
    "    \"\"\"Generate LaTeX table for a specific outcome across all tasks.\"\"\"\n",
    "    rows = []\n",
    "    control_data = None\n",
    "    for task in sorted(task_descriptions.keys()):\n",
    "        if task not in task_dfs:\n",
    "            print(f\"⚠️ No data for Task {task}\")\n",
    "            continue\n",
    "        df = task_dfs[task]\n",
    "        outcome_var = outcome_map.get(task)\n",
    "        if outcome_var is None:\n",
    "            print(f\"⚠️ Outcome mapping missing for Task {task} in {outcome}\")\n",
    "            continue\n",
    "        result = extract_treatment_effects_with_controls(df, outcome_var, task)\n",
    "        if result is None:\n",
    "            continue\n",
    "        control_mean_str = f\"${result['control_mean']:.2f}$\"\n",
    "        for eff in result['effects']:\n",
    "            rows.append({\n",
    "                'Task': task_descriptions[task],\n",
    "                'Control Mean': control_mean_str,\n",
    "                'Model': eff['Model'],\n",
    "                'Effect': eff['Effect'],\n",
    "                'SE': eff['SE'],\n",
    "                'Pct Change': eff['Pct Change'],\n",
    "                'N': eff['N']\n",
    "            })\n",
    "        if control_data is None:\n",
    "            control_data = result['controls']\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"⚠️ No results for outcome {outcome}\")\n",
    "        return\n",
    "\n",
    "    # Build LaTeX table\n",
    "    latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "    latex_table += f\"\\\\caption{{Treatment Effects on {outcome} Across Tasks}}\\n\"\n",
    "    latex_table += f\"\\\\label{{tab:{outcome.lower().replace(' ', '_')}_effects_controls}}\\n\"\n",
    "    latex_table += \"\\\\vspace{0.3cm}\\n\"\n",
    "    latex_table += \"\\\\begin{tabular}{lcccccc}\\n\"\n",
    "    latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "    latex_table += \"Task & Control Mean & Model & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    current_task = None\n",
    "    for row in rows:\n",
    "        if current_task != row['Task']:\n",
    "            current_task = row['Task']\n",
    "            latex_table += (\n",
    "                f\"\\\\multirow{{2}}{{*}}{{{row['Task']}}} & \"\n",
    "                f\"\\\\multirow{{2}}{{*}}{{{row['Control Mean']}}} & \"\n",
    "                f\"{row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "            )\n",
    "        else:\n",
    "            latex_table += (\n",
    "                f\"& & {row['Model']} & {row['Effect']} & {row['SE']} & {row['Pct Change']} & {row['N']} \\\\\\\\\\n\"\n",
    "                f\"\\\\hline\\n\"\n",
    "            )\n",
    "    latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "    latex_table += \"\\\\end{tabular}\\n\\n\"\n",
    "    latex_table += \"\\\\vspace{0.5cm}\\n\\n\"\n",
    "\n",
    "    # Panel B: Control Variables\n",
    "    if control_data:\n",
    "        latex_table += \"\\\\begin{tabular}{lcc}\\n\"\n",
    "        latex_table += \"\\\\multicolumn{3}{l}{\\\\textbf{Panel B: Control Variables}} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "        latex_table += \"Variable & Coefficient & SE \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "        for ctrl in control_data:\n",
    "            latex_table += f\"{ctrl['name']} & {ctrl['coef']} & {ctrl['se']} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "        latex_table += \"\\\\end{tabular}\\n\"\n",
    "\n",
    "    latex_table += \"\\\\begin{tablenotes}\\n\\\\small\\n\"\n",
    "    latex_table += (\"\\\\item \\\\textit{Notes:} Effects are shown relative to the No AI control group. \"\n",
    "                    \"Robust standard errors (in parentheses) are reported. \"\n",
    "                    \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$.\")\n",
    "    latex_table += \"\\n\\\\end{tablenotes}\\n\"\n",
    "    latex_table += \"\\\\end{table}\"\n",
    "\n",
    "    # Save the table\n",
    "    os.makedirs(tables_path, exist_ok=True)\n",
    "    table_file_path = os.path.join(tables_path, f\"{outcome.lower().replace(' ', '_')}_effects_controls.tex\")\n",
    "    with open(table_file_path, \"w\") as f:\n",
    "        f.write(latex_table)\n",
    "    print(f\"✅ Saved LaTeX table: {table_file_path}\")\n",
    "\n",
    "def generate_all_outcome_tables(task_dfs, master_folder):\n",
    "    \"\"\"Generate all outcome tables.\"\"\"\n",
    "    for outcome, outcome_map in outcome_mappings.items():\n",
    "        create_outcome_table_with_controls(outcome, outcome_map, task_dfs, tables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\accuracy_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\analysis_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\organization_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\clarity_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\professionalism_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\total_score_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\time_spent_effects_controls.tex\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\productivity_effects_controls.tex\n"
     ]
    }
   ],
   "source": [
    "generate_all_outcome_tables(task_dfs, master_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgroup analyis by GPA quartile and student type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Task 1: Draft Client Email\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task1_gpa_quartiles.tex\n",
      "\n",
      "Processing Task 2: Draft Legal Memo\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task2_gpa_quartiles.tex\n",
      "\n",
      "Processing Task 3: Analysis of Complaint\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task3_gpa_quartiles.tex\n",
      "\n",
      "Processing Task 4: Draft NDA\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task4_gpa_quartiles.tex\n",
      "\n",
      "Processing Task 5: Draft Motion to Consolidate\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task5_gpa_quartiles.tex\n",
      "\n",
      "Processing Task 6: Draft CNC Enforcement Letter\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\task6_gpa_quartiles.tex\n"
     ]
    }
   ],
   "source": [
    "def extract_subgroup_effects(df, outcome, task_num, subgroup_name, subgroup_value):\n",
    "    \"\"\"Extract treatment effects for a specific subgroup.\"\"\"\n",
    "    if df is None or outcome not in df.columns:\n",
    "        print(f\"Skipping {outcome} - Task {task_num} - {subgroup_name} {subgroup_value}\")\n",
    "        return None\n",
    "    \n",
    "    # Subset data for specific subgroup\n",
    "    df_subset = df[df[subgroup_name] == subgroup_value].copy()\n",
    "    \n",
    "    # Create treatment dummies\n",
    "    df_subset['Vincent_dummy'] = (df_subset['AI_Condition'] == 'Vincent').astype(int)\n",
    "    df_subset['GPT01_dummy'] = (df_subset['AI_Condition'] == 'GPT 01').astype(int)\n",
    "    \n",
    "    # Clean data\n",
    "    df_clean = df_subset.dropna(subset=[outcome, 'Vincent_dummy', 'GPT01_dummy'])\n",
    "    \n",
    "    if len(df_clean) < 10:\n",
    "        return None\n",
    "        \n",
    "    # Calculate control group mean\n",
    "    control_mean = df_clean[df_clean['AI_Condition'] == 'No AI'][outcome].mean()\n",
    "    \n",
    "    # Run regression\n",
    "    X = df_clean[['Vincent_dummy', 'GPT01_dummy']]\n",
    "    X = sm.add_constant(X)\n",
    "    y = df_clean[outcome]\n",
    "    \n",
    "    try:\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit(cov_type='HC1')\n",
    "        \n",
    "        return {\n",
    "            'control_mean': control_mean,\n",
    "            'vincent_coef': results.params['Vincent_dummy'],\n",
    "            'vincent_se': results.bse['Vincent_dummy'],\n",
    "            'vincent_p': results.pvalues['Vincent_dummy'],\n",
    "            'gpt_coef': results.params['GPT01_dummy'],\n",
    "            'gpt_se': results.bse['GPT01_dummy'],\n",
    "            'gpt_p': results.pvalues['GPT01_dummy'],\n",
    "            'n_obs': len(df_clean)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in regression for {outcome} - Task {task_num}: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_coefficient(coef, se, p):\n",
    "    \"\"\"Format coefficient with significance stars.\"\"\"\n",
    "    stars = \"\"\n",
    "    if p < 0.01:\n",
    "        stars = \"^{***}\"\n",
    "    elif p < 0.05:\n",
    "        stars = \"^{**}\"\n",
    "    elif p < 0.1:\n",
    "        stars = \"^{*}\"\n",
    "    \n",
    "    # Return the formatted string directly - not as a tuple\n",
    "    return f\"${coef:.2f}{stars}$\"\n",
    "\n",
    "def format_pct_change(pct):\n",
    "    \"\"\"Format percentage change with plus sign for positive values.\"\"\"\n",
    "    if pct >= 0:\n",
    "        return f\"$+{pct:.1f}\\\\%$\"\n",
    "    else:\n",
    "        return f\"${pct:.1f}\\\\%$\"\n",
    "\n",
    "def create_gpa_quartile_tables(task_dfs, analysis_path, controls_numeric_df):\n",
    "    \"\"\"Create LaTeX tables of treatment effects by GPA quartile for each task.\"\"\"\n",
    "    \n",
    "    outcome_names = [\n",
    "        'Accuracy', 'Analysis', 'Organization', 'Clarity', \n",
    "        'Professionalism', 'Total Score', 'Time Spent', 'Productivity'\n",
    "    ]\n",
    "    \n",
    "    # Define quartiles consistently\n",
    "    quartiles = ['Bottom 25\\\\%', '25-50\\\\%', '50-75\\\\%', 'Top 25\\\\%']\n",
    "    \n",
    "    for task_num, task_name in task_descriptions.items():\n",
    "        print(f\"\\nProcessing Task {task_num}: {task_name}\")\n",
    "        \n",
    "        df = task_dfs.get(task_num)\n",
    "        if df is None:\n",
    "            continue\n",
    "            \n",
    "        # Compute GPA quartiles\n",
    "        df = df.copy()\n",
    "        student_numbers = df['Student_Number'].unique()\n",
    "        gpa_df = controls_numeric_df[controls_numeric_df['Student_Number'].isin(student_numbers)].copy()\n",
    "        gpa_df['GPA_quartile'] = pd.qcut(gpa_df['GPA'], q=4, labels=quartiles)\n",
    "        \n",
    "        # Merge GPA quartiles back to main dataframe\n",
    "        df = df.merge(gpa_df[['Student_Number', 'GPA_quartile']], \n",
    "                     on='Student_Number', \n",
    "                     how='left')\n",
    "        \n",
    "        # Generate LaTeX table with 10 columns\n",
    "        latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "        latex_table += f\"\\\\caption{{Treatment Effects for {task_name} by GPA Quartile}}\\n\"\n",
    "        latex_table += f\"\\\\label{{tab:task{task_num}_gpa}}\\n\"\n",
    "        latex_table += \"\\\\begin{tabular}{lccccccccc}\\n\"\n",
    "        latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "        latex_table += \"& & \\\\multicolumn{4}{c}{Vincent} & \\\\multicolumn{4}{c}{o1-preview} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\cline{3-10}\\n\"\n",
    "        latex_table += \"Outcome & GPA Quartile & Effect & SE & \\\\% Change & N & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "        \n",
    "        # Process each outcome\n",
    "        for outcome_name in outcome_names:\n",
    "            if outcome_name == 'Productivity':\n",
    "                outcome_var = f'P{task_num}_Productivity'\n",
    "            else:\n",
    "                outcome_var = outcome_mappings[outcome_name][task_num]\n",
    "            \n",
    "            if outcome_var not in df.columns:\n",
    "                print(f\"Skipping {outcome_name} - column {outcome_var} not found\")\n",
    "                continue\n",
    "                \n",
    "            # We will generate four rows for each outcome (one per GPA quartile)\n",
    "            first_quartile = True\n",
    "            for quartile in quartiles:\n",
    "                results = extract_subgroup_effects(df, outcome_var, task_num, \n",
    "                                                    'GPA_quartile', quartile)\n",
    "                if results is None:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate percentage changes\n",
    "                vincent_pct = (results['vincent_coef']/results['control_mean']*100)\n",
    "                gpt_pct = (results['gpt_coef']/results['control_mean']*100)\n",
    "                \n",
    "                # For the first row, print the multirow cell; subsequent rows just add an empty placeholder\n",
    "                if first_quartile:\n",
    "                    prefix = f\"\\\\multirow{{4}}{{*}}{{{outcome_name}}} & \"\n",
    "                    first_quartile = False\n",
    "                else:\n",
    "                    prefix = \"& \"\n",
    "                \n",
    "                # Fixed: Add quartile column and directly use the formatting functions without creating tuples\n",
    "                latex_table += prefix\n",
    "                latex_table += f\"{quartile} & {format_coefficient(results['vincent_coef'], results['vincent_se'], results['vincent_p'])} & \"\n",
    "                latex_table += f\"(${results['vincent_se']:.2f}$) & \"\n",
    "                latex_table += f\"{format_pct_change(vincent_pct)} & {results['n_obs']} & \"\n",
    "                latex_table += f\"{format_coefficient(results['gpt_coef'], results['gpt_se'], results['gpt_p'])} & \"\n",
    "                latex_table += f\"(${results['gpt_se']:.2f}$) & \"\n",
    "                latex_table += f\"{format_pct_change(gpt_pct)} & {results['n_obs']} \\\\\\\\\\n\"\n",
    "            \n",
    "            # Add a horizontal line after the outcome rows (if any rows were added)\n",
    "            if not first_quartile:\n",
    "                latex_table += \"\\\\hline\\n\"\n",
    "        \n",
    "        latex_table += \"\\\\multicolumn{10}{p{0.95\\\\linewidth}}{\\\\footnotesize \\\\textit{Notes:} \"\n",
    "        latex_table += \"Effects shown relative to No AI control group within each GPA quartile. \"\n",
    "        latex_table += \"GPA quartiles divide students into four equal groups based on their cumulative GPA. \"\n",
    "        latex_table += \"Robust standard errors in parentheses. \"\n",
    "        latex_table += \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$}\\n\"\n",
    "        latex_table += \"\\\\end{tabular}\\n\"\n",
    "        latex_table += \"\\\\end{table}\\n\"\n",
    "        \n",
    "        # Save the table\n",
    "        output_path = os.path.join(tables_path, f\"task{task_num}_gpa_quartiles.tex\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "        \n",
    "        print(f\"✅ Saved LaTeX table: {output_path}\")\n",
    "\n",
    "# Execute the analysis (uncomment the line below once your variables are defined)\n",
    "create_gpa_quartile_tables(task_dfs, analysis_path, controls_numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Outcome: Accuracy\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\accuracy_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Analysis\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\analysis_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Organization\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\organization_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Clarity\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\clarity_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Professionalism\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\professionalism_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Total Score\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\total_score_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Time Spent\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\time_spent_gpa_quartiles.tex\n",
      "\n",
      "Processing Outcome: Productivity\n",
      "✅ Saved LaTeX table: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables\\productivity_gpa_quartiles.tex\n"
     ]
    }
   ],
   "source": [
    "def create_gpa_quartile_tables_by_criteria(task_dfs, analysis_path, controls_numeric_df):\n",
    "    \n",
    "    outcome_names = [\n",
    "        'Accuracy', 'Analysis', 'Organization', 'Clarity', \n",
    "        'Professionalism', 'Total Score', 'Time Spent', 'Productivity'\n",
    "    ]\n",
    "    \n",
    "    quartiles = ['Bottom 25\\\\%', '25-50\\\\%', '50-75\\\\%', 'Top 25\\\\%']\n",
    "    \n",
    "    for outcome_name in outcome_names:\n",
    "        print(f\"\\nProcessing Outcome: {outcome_name}\")\n",
    "        \n",
    "        # Begin the LaTeX table for the current criterion\n",
    "        latex_table = \"\\\\begin{table}[!htbp]\\n\\\\centering\\n\"\n",
    "        latex_table += f\"\\\\caption{{Treatment Effects for {outcome_name} by Task and GPA Quartile}}\\n\"\n",
    "        latex_table += f\"\\\\label{{tab:{outcome_name.lower().replace(' ', '_')}_gpa}}\\n\"\n",
    "        latex_table += \"\\\\begin{tabular}{lccccccccc}\\n\"\n",
    "        latex_table += \"\\\\hline\\\\hline\\n\"\n",
    "        latex_table += \"& & \\\\multicolumn{4}{c}{Vincent} & \\\\multicolumn{4}{c}{o1-preview} \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\cline{3-10}\\n\"\n",
    "        latex_table += \"Task & GPA Quartile & Effect & SE & \\\\% Change & N & Effect & SE & \\\\% Change & N \\\\\\\\\\n\"\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "        \n",
    "        # Loop through tasks\n",
    "        for task_num, task_name in task_descriptions.items():\n",
    "            df = task_dfs.get(task_num)\n",
    "            if df is None:\n",
    "                continue\n",
    "            \n",
    "            # Merge in GPA quartile info\n",
    "            df = df.copy()\n",
    "            student_numbers = df['Student_Number'].unique()\n",
    "            gpa_df = controls_numeric_df[controls_numeric_df['Student_Number'].isin(student_numbers)].copy()\n",
    "            gpa_df['GPA_quartile'] = pd.qcut(gpa_df['GPA'], q=4, labels=quartiles)\n",
    "            df = df.merge(gpa_df[['Student_Number', 'GPA_quartile']], on='Student_Number', how='left')\n",
    "            \n",
    "            first_quartile_for_task = True\n",
    "            for quartile in quartiles:\n",
    "                # Determine the outcome variable for the current task and criterion\n",
    "                if outcome_name == 'Productivity':\n",
    "                    outcome_var = f'P{task_num}_Productivity'\n",
    "                else:\n",
    "                    outcome_var = outcome_mappings[outcome_name][task_num]\n",
    "                \n",
    "                if outcome_var not in df.columns:\n",
    "                    print(f\"Skipping {outcome_name} for task {task_num} - column {outcome_var} not found\")\n",
    "                    continue\n",
    "                \n",
    "                results = extract_subgroup_effects(df, outcome_var, task_num, 'GPA_quartile', quartile)\n",
    "                if results is None:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate percentage changes\n",
    "                vincent_pct = (results['vincent_coef']/results['control_mean']*100)\n",
    "                gpt_pct = (results['gpt_coef']/results['control_mean']*100)\n",
    "                \n",
    "                # For the first GPA quartile row for this task, use a multirow for the task name\n",
    "                if first_quartile_for_task:\n",
    "                    prefix = f\"\\\\multirow{{4}}{{*}}{{{task_name}}} & \"\n",
    "                    first_quartile_for_task = False\n",
    "                else:\n",
    "                    prefix = \"& \"\n",
    "                    \n",
    "                latex_table += prefix\n",
    "                latex_table += f\"{quartile} & {format_coefficient(results['vincent_coef'], results['vincent_se'], results['vincent_p'])} & \"\n",
    "                latex_table += f\"(${results['vincent_se']:.2f}$) & \"\n",
    "                latex_table += f\"{format_pct_change(vincent_pct)} & {results['n_obs']} & \"\n",
    "                latex_table += f\"{format_coefficient(results['gpt_coef'], results['gpt_se'], results['gpt_p'])} & \"\n",
    "                latex_table += f\"(${results['gpt_se']:.2f}$) & \"\n",
    "                latex_table += f\"{format_pct_change(gpt_pct)} & {results['n_obs']} \\\\\\\\\\n\"\n",
    "            \n",
    "            # Add a horizontal line after each task (if any rows were added)\n",
    "            if not first_quartile_for_task:\n",
    "                latex_table += \"\\\\hline\\n\"\n",
    "        \n",
    "        latex_table += (\"\\\\multicolumn{10}{p{0.95\\\\linewidth}}{\\\\footnotesize \\\\textit{Notes:} \"\n",
    "                        \"Effects shown relative to No AI control group within each GPA quartile. \"\n",
    "                        \"GPA quartiles divide students into four equal groups based on their cumulative GPA. \"\n",
    "                        \"Robust standard errors in parentheses. \"\n",
    "                        \"$^{***}p<0.01$, $^{**}p<0.05$, $^{*}p<0.1$}\\n\")\n",
    "        latex_table += \"\\\\end{tabular}\\n\"\n",
    "        latex_table += \"\\\\end{table}\\n\"\n",
    "        \n",
    "        # Save the table to a file\n",
    "        output_path = os.path.join(tables_path, f\"{outcome_name.lower().replace(' ', '_')}_gpa_quartiles.tex\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "        \n",
    "        print(f\"✅ Saved LaTeX table: {output_path}\")\n",
    "\n",
    "# Execute the reversed table creation (ensure task_dfs, analysis_path, and controls_numeric_df are defined)\n",
    "create_gpa_quartile_tables_by_criteria(task_dfs, analysis_path, controls_numeric_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary stats and balance table across randomization groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_data(master_folder):\n",
    "    \"\"\"Load and prepare task data for summary statistics analysis.\"\"\"\n",
    "\n",
    "    task_files = [f for f in os.listdir(analysis_path) if f.startswith(\"task\") and f.endswith(\"_data_numeric.csv\")]\n",
    "    task_dfs = {file: pd.read_csv(os.path.join(analysis_path, file)) for file in task_files}\n",
    "\n",
    "    return task_dfs\n",
    "\n",
    "def compute_summary_stats(data, var, total_count):\n",
    "    \"\"\"Compute summary statistics including mean, SD, min, max, and percentiles.\"\"\"\n",
    "    var_data = data[var].dropna()\n",
    "\n",
    "    stats_dict = {\n",
    "        'Mean': var_data.mean(),\n",
    "        'SD': var_data.std(),\n",
    "        'Min': var_data.min(),\n",
    "        '25th Percentile': var_data.quantile(0.25),\n",
    "        'Median': var_data.median(),\n",
    "        '75th Percentile': var_data.quantile(0.75),\n",
    "        'Max': var_data.max(),\n",
    "        'N': len(var_data),\n",
    "        'Missing %': (1 - len(var_data) / total_count) * 100  # Corrected missing percentage\n",
    "    }\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "def create_summary_stats_table(task_dfs):\n",
    "    \"\"\"Create LaTeX summary statistics table for all tasks.\"\"\"\n",
    "    latex_lines = []\n",
    "    latex_lines.append(\"\\\\begin{table}[!htbp]\")\n",
    "    latex_lines.append(\"\\\\centering\")\n",
    "    latex_lines.append(\"\\\\caption{Summary Statistics for All Tasks}\")\n",
    "    latex_lines.append(\"\\\\label{tab:summary_stats}\")\n",
    "    latex_lines.append(\"\\\\begin{tabular}{lccccccccc}\")\n",
    "    latex_lines.append(\"\\\\hline\\\\hline\")\n",
    "    latex_lines.append(\"Variable & Mean & SD & Min & 25\\\\% & Median & 75\\\\% & Max & N & Missing \\\\% \\\\\\\\\")\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "\n",
    "    for task_file, df in sorted(task_dfs.items()):\n",
    "        task_num = ''.join(filter(str.isdigit, task_file))  # Extract task number from filename\n",
    "        total_count = len(df)\n",
    "\n",
    "        variables = {\n",
    "            f'P{task_num}_Total_Score': f'Total Score (Task {task_num})',\n",
    "            f'P{task_num}_Productivity': f'Productivity (Task {task_num})',\n",
    "            f'Time_Spent_Assignment_{task_num}': f'Time Spent (Task {task_num})'\n",
    "        }\n",
    "\n",
    "        for var, var_label in variables.items():\n",
    "            if var in df.columns:\n",
    "                stats = compute_summary_stats(df, var, total_count)\n",
    "\n",
    "                # Format line\n",
    "                line = f\"{var_label} & {stats['Mean']:.2f} & {stats['SD']:.2f} & {stats['Min']:.2f} & \"\n",
    "                line += f\"{stats['25th Percentile']:.2f} & {stats['Median']:.2f} & {stats['75th Percentile']:.2f} & \"\n",
    "                line += f\"{stats['Max']:.2f} & {stats['N']} & {stats['Missing %']:.1f}\\\\% \\\\\\\\\"\n",
    "\n",
    "                latex_lines.append(line)\n",
    "\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\multicolumn{10}{p{0.95\\\\linewidth}}{\\\\footnotesize \\\\textit{Notes:} \")\n",
    "    latex_lines.append(\"SD: Standard Deviation. Missing \\\\% represents percentage of missing values in each variable.} \\\\\\\\\")\n",
    "    latex_lines.append(\"\\\\end{tabular}\")\n",
    "    latex_lines.append(\"\\\\end{table}\")\n",
    "\n",
    "    return \"\\n\".join(latex_lines)\n",
    "\n",
    "\n",
    "\n",
    "# Load task data\n",
    "task_dfs = load_task_data(master_folder)\n",
    "\n",
    "# Create summary statistics table\n",
    "latex_table = create_summary_stats_table(task_dfs)\n",
    "\n",
    "# Save table\n",
    "os.makedirs(tables_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(tables_path, \"summary_stats_table.tex\"), \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "# Display summary statistics in a DataFrame for user\n",
    "summary_data = []\n",
    "for task_file, df in sorted(task_dfs.items()):\n",
    "    task_num = ''.join(filter(str.isdigit, task_file))\n",
    "    total_count = len(df)\n",
    "\n",
    "    variables = {\n",
    "        f'P{task_num}_Total_Score': f'Total Score (Task {task_num})',\n",
    "        f'P{task_num}_Productivity': f'Productivity (Task {task_num})',\n",
    "        f'Time_Spent_Assignment_{task_num}': f'Time Spent (Task {task_num})'\n",
    "    }\n",
    "\n",
    "    for var, var_label in variables.items():\n",
    "        if var in df.columns:\n",
    "            stats = compute_summary_stats(df, var, total_count)\n",
    "            summary_data.append([var_label] + list(stats.values()))\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = [\"Variable\", \"Mean\", \"SD\", \"Min\", \"25th Percentile\", \"Median\", \"75th Percentile\", \"Max\", \"N\", \"Missing %\"]\n",
    "summary_df = pd.DataFrame(summary_data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance table saved successfully at C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\tables!\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as scipy_stats  # Import with a different name to avoid conflicts\n",
    "\n",
    "def load_data(master_folder):\n",
    "    \"\"\"Load and prepare the data for balance analysis.\"\"\"\n",
    "        \n",
    "    # Load controls and task1 data\n",
    "    controls = pd.read_csv(os.path.join(analysis_path, \"controls_numeric.csv\"))\n",
    "    task1 = pd.read_csv(os.path.join(analysis_path, \"task1_data_numeric.csv\"))\n",
    "    \n",
    "    # Create group mapping\n",
    "    task1['Group'] = task1['AI_Condition'].map({\n",
    "        'No AI': 'Group A',\n",
    "        'GPT 01': 'Group B',\n",
    "        'Vincent': 'Group C'\n",
    "    })\n",
    "    \n",
    "    # Merge datasets\n",
    "    data = task1.merge(controls[['Student_Number', 'GPA', 'AI_Use', 'Student_Type']], \n",
    "                      on='Student_Number', \n",
    "                      how='left')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def compute_group_stats_continuous(data, var):\n",
    "    \"\"\"Compute statistics for continuous variables by treatment group.\"\"\"\n",
    "    stats_dict = {}\n",
    "    for group in ['Group A', 'Group B', 'Group C']:\n",
    "        group_data = data[data['Group'] == group]\n",
    "        group_var = group_data[var].dropna()\n",
    "        \n",
    "        stats_dict[group] = {\n",
    "            'mean': group_var.mean(),\n",
    "            'sd': group_var.std(),\n",
    "            'n': len(group_var),\n",
    "            'total_n': len(group_data),\n",
    "            'missing_rate': (1 - len(group_var) / len(group_data)) * 100 if len(group_data) > 0 else 0\n",
    "        }\n",
    "    return stats_dict\n",
    "\n",
    "def compute_group_stats_categorical(data, var, categories):\n",
    "    \"\"\"Compute proportions for categorical variables by treatment group.\"\"\"\n",
    "    stats_dict = {}\n",
    "    for group in ['Group A', 'Group B', 'Group C']:\n",
    "        group_data = data[data['Group'] == group]\n",
    "        total_valid = group_data[var].notna().sum()\n",
    "        total_n = len(group_data)\n",
    "        \n",
    "        stats_dict[group] = {\n",
    "            'categories': {},\n",
    "            'missing_rate': (1 - total_valid / total_n) * 100 if total_n > 0 else 0,\n",
    "            'total_n': total_n,\n",
    "            'valid_n': total_valid\n",
    "        }\n",
    "        \n",
    "        for cat in categories:\n",
    "            count = (group_data[var] == cat).sum()\n",
    "            prop = count / total_valid if total_valid > 0 else 0\n",
    "            stats_dict[group]['categories'][cat] = {\n",
    "                'count': count,\n",
    "                'proportion': prop\n",
    "            }\n",
    "    return stats_dict\n",
    "\n",
    "def compute_chi_square_test(data, var):\n",
    "    \"\"\"Compute chi-square test for categorical variables across groups.\"\"\"\n",
    "    contingency_table = pd.crosstab(data['Group'], data[var])\n",
    "    chi2, p_val = scipy_stats.chi2_contingency(contingency_table)[:2]\n",
    "    return p_val\n",
    "\n",
    "def compute_f_test(data, var):\n",
    "    \"\"\"Compute F-test for continuous variables across groups.\"\"\"\n",
    "    groups = []\n",
    "    for group in ['Group A', 'Group B', 'Group C']:\n",
    "        group_data = data[data['Group'] == group][var].dropna()\n",
    "        if len(group_data) > 0:  # Only append non-empty groups\n",
    "            groups.append(group_data)\n",
    "    \n",
    "    if len(groups) >= 2:  # Need at least 2 groups for F-test\n",
    "        f_stat, p_val = scipy_stats.f_oneway(*groups)\n",
    "        return p_val\n",
    "    return float('nan')  # Return NaN if not enough groups\n",
    "\n",
    "def create_balance_table(data):\n",
    "    \"\"\"Create comprehensive balance table with adjusted formatting.\"\"\"\n",
    "    \n",
    "    latex_lines = []\n",
    "    latex_lines.append(\"\\\\begin{table}[!htbp]\")\n",
    "    latex_lines.append(\"\\\\setlength{\\\\tabcolsep}{6pt}\")\n",
    "    latex_lines.append(\"\\\\renewcommand{\\\\arraystretch}{1.0}\")\n",
    "    latex_lines.append(\"\\\\centering\")\n",
    "    latex_lines.append(\"\\\\caption{Balance Across Randomized Groups}\")\n",
    "    latex_lines.append(\"\\\\label{tab:balance}\")\n",
    "    latex_lines.append(\"\\\\begin{tabular*}{0.85\\\\textwidth}{@{\\\\extracolsep{\\\\fill}}lccccr@{}}\")\n",
    "    latex_lines.append(\"\\\\hline\\\\hline\")\n",
    "    latex_lines.append(\"Variable & Group A & Group B & Group C & N & p-value \\\\\\\\\")\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    \n",
    "    # Add group sizes\n",
    "    group_sizes = data.groupby('Group').size()\n",
    "    size_line = f\"Group Size & {group_sizes['Group A']} & {group_sizes['Group B']} & {group_sizes['Group C']} & {len(data)} & \\\\\\\\\"\n",
    "    latex_lines.append(size_line)\n",
    "    \n",
    "    # Panel A: Continuous Variables\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\multicolumn{6}{l}{\\\\textbf{Panel A: Continuous Variables}} \\\\\\\\\")\n",
    "    \n",
    "    # Add GPA statistics\n",
    "    gpa_stats = compute_group_stats_continuous(data, 'GPA')\n",
    "    f_test_p = compute_f_test(data, 'GPA')\n",
    "    total_n = sum(group_stat['n'] for group_stat in gpa_stats.values())\n",
    "    \n",
    "    gpa_line = f\"GPA & {gpa_stats['Group A']['mean']:.3f} & {gpa_stats['Group B']['mean']:.3f} & {gpa_stats['Group C']['mean']:.3f} & {total_n} & {f_test_p:.3f} \\\\\\\\\"\n",
    "    latex_lines.append(gpa_line)\n",
    "    \n",
    "    sd_line = f\"& ({gpa_stats['Group A']['sd']:.3f}) & ({gpa_stats['Group B']['sd']:.3f}) & ({gpa_stats['Group C']['sd']:.3f}) & & \\\\\\\\\"\n",
    "    latex_lines.append(sd_line)\n",
    "    \n",
    "    missing_line = f\"Missing (\\\\%) & {gpa_stats['Group A']['missing_rate']:.1f}\\\\% & {gpa_stats['Group B']['missing_rate']:.1f}\\\\% & {gpa_stats['Group C']['missing_rate']:.1f}\\\\% & & \\\\\\\\\"\n",
    "    latex_lines.append(missing_line)\n",
    "    \n",
    "    # Panel B: Student Type\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\multicolumn{6}{l}{\\\\textbf{Panel B: Student Type}} \\\\\\\\\")\n",
    "    \n",
    "    student_type_stats = compute_group_stats_categorical(data, 'Student_Type', student_type_mapping.keys())\n",
    "    chi2_p = compute_chi_square_test(data, 'Student_Type')\n",
    "    \n",
    "    for type_code, type_label in student_type_mapping.items():\n",
    "        props = [student_type_stats[group]['categories'][type_code]['proportion'] * 100 \n",
    "                for group in ['Group A', 'Group B', 'Group C']]\n",
    "        counts = [student_type_stats[group]['categories'][type_code]['count'] \n",
    "                 for group in ['Group A', 'Group B', 'Group C']]\n",
    "        total_count = sum(counts)\n",
    "        \n",
    "        p_value = f\"{chi2_p:.3f}\" if type_code == 1 else \"\"\n",
    "        props_line = f\"{type_label} & {props[0]:.1f}\\\\% & {props[1]:.1f}\\\\% & {props[2]:.1f}\\\\% & {total_count} & {p_value} \\\\\\\\\"\n",
    "        latex_lines.append(props_line)\n",
    "    \n",
    "    missing_line = f\"Missing (\\\\%) & {student_type_stats['Group A']['missing_rate']:.1f}\\\\% & {student_type_stats['Group B']['missing_rate']:.1f}\\\\% & {student_type_stats['Group C']['missing_rate']:.1f}\\\\% & & \\\\\\\\\"\n",
    "    latex_lines.append(missing_line)\n",
    "    \n",
    "    # Panel C: AI Use\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\multicolumn{6}{l}{\\\\textbf{Panel C: Prior AI Use}} \\\\\\\\\")\n",
    "    \n",
    "    ai_use_stats = compute_group_stats_categorical(data, 'AI_Use', ai_use_mapping.keys())\n",
    "    chi2_p = compute_chi_square_test(data, 'AI_Use')\n",
    "    \n",
    "    for use_code, use_label in ai_use_mapping.items():\n",
    "        props = [ai_use_stats[group]['categories'][use_code]['proportion'] * 100 \n",
    "                for group in ['Group A', 'Group B', 'Group C']]\n",
    "        counts = [ai_use_stats[group]['categories'][use_code]['count'] \n",
    "                 for group in ['Group A', 'Group B', 'Group C']]\n",
    "        total_count = sum(counts)\n",
    "        \n",
    "        p_value = f\"{chi2_p:.3f}\" if use_code == 1 else \"\"\n",
    "        props_line = f\"{use_label} & {props[0]:.1f}\\\\% & {props[1]:.1f}\\\\% & {props[2]:.1f}\\\\% & {total_count} & {p_value} \\\\\\\\\"\n",
    "        latex_lines.append(props_line)\n",
    "    \n",
    "    missing_line = f\"Missing (\\\\%) & {ai_use_stats['Group A']['missing_rate']:.1f}\\\\% & {ai_use_stats['Group B']['missing_rate']:.1f}\\\\% & {ai_use_stats['Group C']['missing_rate']:.1f}\\\\% & & \\\\\\\\\"\n",
    "    latex_lines.append(missing_line)\n",
    "    \n",
    "    # Add table footer\n",
    "    latex_lines.append(\"\\\\hline\")\n",
    "    latex_lines.append(\"\\\\multicolumn{6}{p{0.85\\\\textwidth}}{\\\\footnotesize \\\\textit{Notes:} \")\n",
    "    latex_lines.append(\"Standard deviations shown in parentheses for continuous variables. \")\n",
    "    latex_lines.append(\"Missing (\\\\%) shows percentage of students with missing data in each group. \")\n",
    "    latex_lines.append(\"P-values from F-test of equality of means for continuous variables and chi-square test of independence for categorical variables. \")\n",
    "    latex_lines.append(\"N shows number of non-missing observations. \")\n",
    "    latex_lines.append(\"Groups are rotated through different treatment conditions (No AI, o1-preview, Vincent) across tasks.} \\\\\\\\\")\n",
    "    latex_lines.append(\"\\\\end{tabular*}\")\n",
    "    latex_lines.append(\"\\\\end{table}\")\n",
    "    \n",
    "    return \"\\n\".join(latex_lines)\n",
    "\n",
    "\n",
    "data = load_data(master_folder)\n",
    "    \n",
    "# Create balance table\n",
    "latex_table = create_balance_table(data)\n",
    "    \n",
    "with open(os.path.join(tables_path, \"balance_table.tex\"), \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "    \n",
    "print(f\"Balance table saved successfully at {tables_path}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# differential effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with complete students saved to C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\complete_students_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all task files\n",
    "def load_task_data(analysis_path):\n",
    "    task_dfs = {}\n",
    "    for task_num in range(1, 7):\n",
    "        file_path = os.path.join(analysis_path, f\"task{task_num}_data_cleaned.csv\")\n",
    "        task_dfs[task_num] = pd.read_csv(file_path)\n",
    "    return task_dfs\n",
    "\n",
    "# Create dataframe with only students who completed all tasks\n",
    "def get_complete_students_df(task_dfs):\n",
    "    all_students = set.intersection(*[set(df['Student_Number'].dropna().unique()) for df in task_dfs.values()])\n",
    "    complete_df = []\n",
    "    \n",
    "    for student in all_students:\n",
    "        student_data = {'Student_Number': student}\n",
    "        for task_num, df in task_dfs.items():\n",
    "            student_row = df[df['Student_Number'] == student]\n",
    "            if not student_row.empty:\n",
    "                student_data[f'Task{task_num}_Score'] = student_row[f'P{task_num}_Total_Score'].iloc[0]\n",
    "                student_data[f'Task{task_num}_Productivity'] = student_row[f'P{task_num}_Productivity'].iloc[0]\n",
    "                student_data[f'Task{task_num}_AI_Condition'] = student_row['AI_Condition'].iloc[0]\n",
    "        complete_df.append(student_data)\n",
    "    \n",
    "    return pd.DataFrame(complete_df)\n",
    "\n",
    "# Load data\n",
    "task_dfs = load_task_data(analysis_path)\n",
    "complete_students_df = get_complete_students_df(task_dfs)\n",
    "\n",
    "# Save dataframe\n",
    "output_path = os.path.join(analysis_path, \"complete_students_data.csv\")\n",
    "complete_students_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataframe with complete students saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs have been saved in the directory: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\figures\n"
     ]
    }
   ],
   "source": [
    "def regression_line(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Fit an OLS model on the non-missing data and return predicted y values\n",
    "    over a grid of x values, along with 95% confidence intervals.\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    if len(x_clean) < 2:\n",
    "        return np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    X = sm.add_constant(x_clean)\n",
    "    model = sm.OLS(y_clean, X).fit()\n",
    "    x_range = np.linspace(x_clean.min(), x_clean.max(), 100)\n",
    "    X_range = sm.add_constant(x_range)\n",
    "    pred = model.get_prediction(X_range)\n",
    "    pred_summary = pred.summary_frame(alpha=0.05)  # 95% CI\n",
    "    y_pred = pred_summary['mean'].values\n",
    "    ci_lower = pred_summary['mean_ci_lower'].values\n",
    "    ci_upper = pred_summary['mean_ci_upper'].values\n",
    "    return x_range, y_pred, ci_lower, ci_upper\n",
    "\n",
    "def plot_gpa_graph(df: pd.DataFrame, y1_col: str, y2_col: str, title: str,\n",
    "                   y1_label: str, y2_label: str, output_path: str, y_label: str = \"Mean Value\"):\n",
    "    \"\"\"\n",
    "    Plot GPA vs. an outcome for two conditions.\n",
    "\n",
    "    - Scatter points are drawn for both outcomes.\n",
    "    - Regression lines with 95% confidence intervals are plotted.\n",
    "    - Legend labels drop the word \"regression\" and any mention of GPT is replaced with o1-preview.\n",
    "    - A note is added on the right of the plot.\n",
    "    - The x-axis is fixed from 2.5 to 4.\n",
    "    - Zero outcomes are dropped, yet the y-axis still starts at 0 with some slack.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Filter valid data and drop rows with zero outcomes\n",
    "    df_plot = df[['GPA', y1_col, y2_col]].dropna()\n",
    "    df_plot = df_plot[(df_plot[y1_col] != 0) & (df_plot[y2_col] != 0)]\n",
    "    \n",
    "    x = df_plot['GPA'].values\n",
    "    y1 = df_plot[y1_col].values\n",
    "    y2 = df_plot[y2_col].values\n",
    "    \n",
    "    # Plot scatter points (each dot represents a student)\n",
    "    plt.scatter(x, y1, color='blue', alpha=0.6, s=50)\n",
    "    plt.scatter(x, y2, color='red', alpha=0.6, s=50)\n",
    "    \n",
    "    # Regression and CI for y1 (blue)\n",
    "    x_range, y1_line, y1_ci_lower, y1_ci_upper = regression_line(x, y1)\n",
    "    if x_range.size > 0:\n",
    "        plt.plot(x_range, y1_line, color='blue', linewidth=2)\n",
    "        plt.fill_between(x_range, y1_ci_lower, y1_ci_upper, color='blue', alpha=0.2)\n",
    "        \n",
    "    # Regression and CI for y2 (red)\n",
    "    x_range, y2_line, y2_ci_lower, y2_ci_upper = regression_line(x, y2)\n",
    "    if x_range.size > 0:\n",
    "        plt.plot(x_range, y2_line, color='red', linewidth=2)\n",
    "        plt.fill_between(x_range, y2_ci_lower, y2_ci_upper, color='red', alpha=0.2)\n",
    "    \n",
    "    plt.xlabel(\"GPA\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Clean legend labels: remove \"regression\" and replace any GPT/GPT 01 with o1-preview\n",
    "    legend_label1 = y1_label.replace(\"GPT\", \"o1-preview\").replace(\"GPT 01\", \"o1-preview\")\n",
    "    legend_label2 = y2_label.replace(\"GPT\", \"o1-preview\").replace(\"GPT 01\", \"o1-preview\")\n",
    "    \n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], color='blue', lw=2, label=legend_label1),\n",
    "        Line2D([0], [0], color='red', lw=2, label=legend_label2)\n",
    "    ]\n",
    "    plt.legend(handles=legend_handles, loc='upper left')\n",
    "    \n",
    "    # Set x-axis limits fixed from 2.5 to 4\n",
    "    plt.xlim(2.5, 4)\n",
    "    \n",
    "    # Set y-axis starting at 0 and add some slack on top\n",
    "    if not df_plot.empty:\n",
    "        ymax = max(df_plot[y1_col].max(), df_plot[y2_col].max())\n",
    "        plt.ylim(0, ymax * 1.1)\n",
    "    else:\n",
    "        plt.ylim(0, 1)\n",
    "    \n",
    "    # Adjust layout to leave space on the right and add a note there\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    plt.figtext(0.65, 0,\n",
    "                \"Note:\\nEach dot represents a student\\nShaded areas denote 95% confidence intervals\",\n",
    "                ha=\"left\", va=\"center\", fontsize=10, color=\"gray\")\n",
    "    \n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # File paths\n",
    "    gpa_file = os.path.join(analysis_path, \"controls_numeric.csv\")\n",
    "    tasks_file = os.path.join(analysis_path, \"complete_students_data.csv\")\n",
    "    # Load GPA data (expects columns: Student_Number, GPA, etc.)\n",
    "    df_gpa = pd.read_csv(gpa_file)\n",
    "    \n",
    "    # Load task-level data in wide format\n",
    "    df_tasks = pd.read_csv(tasks_file)\n",
    "    \n",
    "    # Reshape task data from wide to long format.\n",
    "    dfs = []\n",
    "    for i in range(1, 7):\n",
    "        score_col = f\"Task{i}_Score\"\n",
    "        prod_col = f\"Task{i}_Productivity\"\n",
    "        cond_col = f\"Task{i}_AI_Condition\"\n",
    "        if score_col in df_tasks.columns:\n",
    "            temp = df_tasks[[\"Student_Number\", score_col, prod_col, cond_col]].copy()\n",
    "            temp = temp.rename(columns={\n",
    "                score_col: \"Score\",\n",
    "                prod_col: \"Productivity\",\n",
    "                cond_col: \"AI_Condition\"\n",
    "            })\n",
    "            temp[\"Task\"] = i\n",
    "            dfs.append(temp)\n",
    "    df_long = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Merge GPA into the long-format task data using Student_Number\n",
    "    df_long = pd.merge(df_long, df_gpa[['Student_Number', 'GPA']], on=\"Student_Number\", how=\"inner\")\n",
    "    \n",
    "    # Group by Student_Number and AI_Condition to compute mean Score and Productivity per student\n",
    "    df_means = df_long.groupby(['Student_Number', 'AI_Condition'], as_index=False).agg({\n",
    "        'Score': 'mean',\n",
    "        'Productivity': 'mean',\n",
    "        'GPA': 'first'  # GPA is the same for each student\n",
    "    })\n",
    "    \n",
    "    # Pivot the table so that each AI condition becomes its own column for Score and Productivity\n",
    "    df_score = df_means.pivot(index=\"Student_Number\", columns=\"AI_Condition\", values=\"Score\").reset_index()\n",
    "    df_prod = df_means.pivot(index=\"Student_Number\", columns=\"AI_Condition\", values=\"Productivity\").reset_index()\n",
    "    \n",
    "    # Rename columns to match the specification\n",
    "    df_score.rename(columns={\n",
    "        \"No AI\": \"Mean_Score_no_AI\",\n",
    "        \"Vincent\": \"Mean_Score_Vincent\",\n",
    "        \"GPT 01\": \"Mean_Score_GPT_01\"\n",
    "    }, inplace=True)\n",
    "    df_prod.rename(columns={\n",
    "        \"No AI\": \"Mean_Productivity_no_AI\",\n",
    "        \"Vincent\": \"Mean_Productivity_Vincent\",\n",
    "        \"GPT 01\": \"Mean_Productivity_GPT_01\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Merge the score and productivity dataframes, then merge back GPA\n",
    "    df_final = pd.merge(df_score, df_prod, on=\"Student_Number\", how=\"outer\")\n",
    "    df_final = pd.merge(df_gpa[['Student_Number', 'GPA']], df_final, on=\"Student_Number\", how=\"inner\")\n",
    "    \n",
    "    # Create output directory for graphs\n",
    "    output_dir = figures_path \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Graph 1: Productivity comparison (No AI vs o1-preview)\n",
    "    plot_gpa_graph(\n",
    "        df_final,\n",
    "        y1_col=\"Mean_Productivity_no_AI\",\n",
    "        y2_col=\"Mean_Productivity_GPT_01\",  # originally labeled as GPT 01\n",
    "        title=\"Mean Task Productivity Comparison for o1-preview Tasks and No AI Tasks, by Participant GPA\",\n",
    "        y1_label=\"No AI Productivity\",\n",
    "        y2_label=\"o1-preview Productivity\",\n",
    "        output_path=os.path.join(output_dir, \"graph1_productivity_noAI_vs_o1-preview.png\"),\n",
    "        y_label=\"Mean Value (Mean Total Productivity Across o1-preview Tasks)\"\n",
    "    )\n",
    "    \n",
    "    # Graph 2: Score comparison (No AI vs o1-preview)\n",
    "    plot_gpa_graph(\n",
    "        df_final,\n",
    "        y1_col=\"Mean_Score_no_AI\",\n",
    "        y2_col=\"Mean_Score_GPT_01\",  # originally labeled as GPT 01\n",
    "        title=\"Mean Task Score Comparison for o1-preview Tasks and No AI Tasks, by Participant GPA\",\n",
    "        y1_label=\"No AI Score\",\n",
    "        y2_label=\"o1-preview Score\",\n",
    "        output_path=os.path.join(output_dir, \"graph2_score_noAI_vs_o1-preview.png\"),\n",
    "        y_label=\"Mean Value (Mean Total Score Across o1-preview Tasks)\"\n",
    "    )\n",
    "    \n",
    "    # Graph 3: Productivity comparison (No AI vs Vincent)\n",
    "    plot_gpa_graph(\n",
    "        df_final,\n",
    "        y1_col=\"Mean_Productivity_no_AI\",\n",
    "        y2_col=\"Mean_Productivity_Vincent\",\n",
    "        title=\"Mean Task Productivity Comparison for Vincent AI Tasks and No AI Tasks, by Participant GPA\",\n",
    "        y1_label=\"No AI Productivity\",\n",
    "        y2_label=\"Vincent Productivity\",\n",
    "        output_path=os.path.join(output_dir, \"graph3_productivity_noAI_vs_Vincent.png\"),\n",
    "        y_label=\"Mean Value (Mean Total Productivity Across Vincent AI Tasks)\"\n",
    "    )\n",
    "    \n",
    "    # Graph 4: Score comparison (No AI vs Vincent)\n",
    "    plot_gpa_graph(\n",
    "        df_final,\n",
    "        y1_col=\"Mean_Score_no_AI\",\n",
    "        y2_col=\"Mean_Score_Vincent\",\n",
    "        title=\"Mean Task Score Comparison for Vincent AI Tasks and No AI Tasks, by Participant GPA\",\n",
    "        y1_label=\"No AI Score\",\n",
    "        y2_label=\"Vincent Score\",\n",
    "        output_path=os.path.join(output_dir, \"graph4_score_noAI_vs_Vincent.png\"),\n",
    "        y_label=\"Mean Value (Mean Total Score Across Vincent AI Tasks)\"\n",
    "    )\n",
    "    \n",
    "    print(\"Graphs have been saved in the directory:\", output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_plot_style()\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots have been saved in: C:\\Users\\tomas\\AI-Powered Lawyering - Anonymized Replication Package as of March 6th 2025\\analysis\\data\\working_20250306_143808\\figures\n"
     ]
    }
   ],
   "source": [
    "def setup_plot_style():\n",
    "    \"\"\"Configure enhanced plot style.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.size': 12,\n",
    "        'figure.figsize': (12, 8),\n",
    "        'axes.grid': True,\n",
    "        'grid.color': '#E5E5E5',\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.alpha': 0.7,\n",
    "        'axes.axisbelow': True,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 16,\n",
    "        'axes.titleweight': 'bold',\n",
    "        'figure.facecolor': 'white'\n",
    "    })\n",
    "\n",
    "def add_trend_line(ax, x, y):\n",
    "    \"\"\"Add a trend line with confidence interval.\"\"\"\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    if len(x_clean) < 2:\n",
    "        return\n",
    "        \n",
    "    X = sm.add_constant(x_clean)\n",
    "    model = sm.OLS(y_clean, X).fit()\n",
    "    \n",
    "    x_range = np.linspace(x_clean.min(), x_clean.max(), 100)\n",
    "    X_range = sm.add_constant(x_range)\n",
    "    \n",
    "    # Get predictions and confidence intervals\n",
    "    predictions = model.get_prediction(X_range)\n",
    "    y_pred = predictions.predicted_mean\n",
    "    ci = predictions.conf_int(alpha=0.05)\n",
    "    \n",
    "    # Plot trend line and confidence interval\n",
    "    ax.plot(x_range, y_pred, color='#FF6B6B', linestyle='-', linewidth=2.5, alpha=0.8, \n",
    "            label='Trend Line')\n",
    "    ax.fill_between(x_range, ci[:, 0], ci[:, 1], color='#FF6B6B', alpha=0.1,\n",
    "                    label='95% CI')\n",
    "\n",
    "def create_scatter_plot(df, x_col, y_col, title, xlabel, ylabel, output_path):\n",
    "    \"\"\"Create an enhanced scatter plot with trend line.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create scatter plot with improved aesthetics\n",
    "    scatter = ax.scatter(df[x_col], df[y_col], \n",
    "                        color='#4A90E2',  # Nice blue color\n",
    "                        alpha=0.6,\n",
    "                        s=100,            # Larger points\n",
    "                        edgecolor='white',\n",
    "                        linewidth=0.5)\n",
    "    \n",
    "    # Add trend line with confidence interval\n",
    "    add_trend_line(ax, df[x_col], df[y_col])\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_title(title, pad=20)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    # Enhance grid\n",
    "    ax.grid(True, linestyle='--', alpha=0.4, color='gray')\n",
    "    \n",
    "    # Add a subtle box around the plot\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(['Data Points', 'Trend Line', '95% CI'],\n",
    "              loc='upper right',\n",
    "              frameon=True,\n",
    "              framealpha=0.9)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # File paths\n",
    "    tasks_file = os.path.join(analysis_path, \"complete_students_data.csv\")\n",
    "    gpa_file = os.path.join(analysis_path, \"controls_numeric.csv\")\n",
    "    output_dir = figures_path \n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df_tasks = pd.read_csv(tasks_file)\n",
    "    df_gpa = pd.read_csv(gpa_file)\n",
    "    \n",
    "    # Prepare the data\n",
    "    task_means = []\n",
    "    for student in df_tasks['Student_Number'].unique():\n",
    "        student_data = {'Student_Number': student}\n",
    "        \n",
    "        # Calculate mean scores for each condition\n",
    "        for condition in ['No AI', 'Vincent', 'GPT 01']:\n",
    "            scores = []\n",
    "            for i in range(1, 7):\n",
    "                task_col = f'Task{i}_Score'\n",
    "                cond_col = f'Task{i}_AI_Condition'\n",
    "                if task_col in df_tasks.columns:\n",
    "                    mask = (df_tasks['Student_Number'] == student) & (df_tasks[cond_col] == condition)\n",
    "                    if any(mask):\n",
    "                        score = df_tasks.loc[mask, task_col].iloc[0]\n",
    "                        if pd.notna(score):\n",
    "                            scores.append(score)\n",
    "            \n",
    "            if scores:\n",
    "                student_data[f'mean_{condition.lower().replace(\" \", \"_\")}_score'] = np.mean(scores)\n",
    "        \n",
    "        task_means.append(student_data)\n",
    "    \n",
    "    df_means = pd.DataFrame(task_means)\n",
    "    \n",
    "    # Merge with GPA data\n",
    "    df_final = pd.merge(df_means, df_gpa[['Student_Number', 'GPA']], on='Student_Number')\n",
    "    \n",
    "    # Calculate boosts\n",
    "    df_final['mean_o1_boost'] = df_final['mean_gpt_01_score'] - df_final['mean_no_ai_score']\n",
    "    df_final['mean_vincent_boost'] = df_final['mean_vincent_score'] - df_final['mean_no_ai_score']\n",
    "    \n",
    "    # Define plots with enhanced titles\n",
    "    plots = [\n",
    "        {\n",
    "            'x_col': 'GPA',\n",
    "            'y_col': 'mean_o1_boost',\n",
    "            'title': 'o1-preview Performance Boost vs. Student GPA',\n",
    "            'xlabel': 'Student GPA',\n",
    "            'ylabel': 'o1-preview Score Boost',\n",
    "            'filename': 'plot1_o1_boost_vs_gpa.png'\n",
    "        },\n",
    "        {\n",
    "            'x_col': 'GPA',\n",
    "            'y_col': 'mean_vincent_boost',\n",
    "            'title': 'Vincent Performance Boost vs. Student GPA',\n",
    "            'xlabel': 'Student GPA',\n",
    "            'ylabel': 'Vincent Score Boost',\n",
    "            'filename': 'plot2_vincent_boost_vs_gpa.png'\n",
    "        },\n",
    "        {\n",
    "            'x_col': 'mean_no_ai_score',\n",
    "            'y_col': 'mean_o1_boost',\n",
    "            'title': 'o1-preview Performance Boost vs. Baseline Score',\n",
    "            'xlabel': 'Mean No AI Score',\n",
    "            'ylabel': 'o1-preview Score Boost',\n",
    "            'filename': 'plot3_o1_boost_vs_noai.png'\n",
    "        },\n",
    "        {\n",
    "            'x_col': 'mean_no_ai_score',\n",
    "            'y_col': 'mean_vincent_boost',\n",
    "            'title': 'Vincent Performance Boost vs. Baseline Score',\n",
    "            'xlabel': 'Mean No AI Score',\n",
    "            'ylabel': 'Vincent Score Boost',\n",
    "            'filename': 'plot4_vincent_boost_vs_noai.png'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Generate all plots\n",
    "    for plot in plots:\n",
    "        output_path = os.path.join(output_dir, plot['filename'])\n",
    "        create_scatter_plot(\n",
    "            df_final,\n",
    "            plot['x_col'],\n",
    "            plot['y_col'],\n",
    "            plot['title'],\n",
    "            plot['xlabel'],\n",
    "            plot['ylabel'],\n",
    "            output_path\n",
    "        )\n",
    "    \n",
    "    print(\"Plots have been saved in:\", output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_plot_style()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Experiment Survey visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original number of responses: 119\n",
      "Number of responses after deduplication: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_51124\\3042756922.py:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  file_path = os.path.join(master_folder, 'Qualtrics surveys\\Post completion survey\\GPT o1 Post Experiment Survey_November 27, 2024_03.58.xlsx')\n"
     ]
    }
   ],
   "source": [
    "# Define file path and load the Excel file\n",
    "file_path = os.path.join(master_folder, 'Qualtrics surveys\\Post completion survey\\GPT o1 Post Experiment Survey_November 27, 2024_03.58.xlsx') \n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create a clean dataset by keeping only the latest entry for each name\n",
    "def create_deduplicated_dataset(df):\n",
    "    # Create a copy of the dataframe without the header row (row 0)\n",
    "    clean_df = df[1:].copy()\n",
    "    \n",
    "    # Sort by StartDate to ensure we keep the latest entry\n",
    "    clean_df = clean_df.sort_values('StartDate')\n",
    "    \n",
    "    # Drop duplicates based on name (column '1'), keeping the last entry\n",
    "    clean_df = clean_df.drop_duplicates(subset='1', keep='last')\n",
    "    \n",
    "    # Reset the index\n",
    "    clean_df = clean_df.reset_index(drop=True)\n",
    "    \n",
    "    # Add back the header row at the top\n",
    "    header_row = df.iloc[0:1]\n",
    "    final_df = pd.concat([header_row, clean_df])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Create deduplicated dataset\n",
    "deduplicated_df = create_deduplicated_dataset(df)\n",
    "\n",
    "# Define output path in the same directory as the input file\n",
    "analysis_path = os.path.dirname(file_path)\n",
    "#output_filename = 'deduplicated_survey_responses.xlsx'\n",
    "#output_path = os.path.join(analysis_path, output_filename)\n",
    "\n",
    "# Save the deduplicated dataset\n",
    "#deduplicated_df.to_excel(output_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nOriginal number of responses: {len(df)}\")\n",
    "print(f\"Number of responses after deduplication: {len(deduplicated_df)}\")\n",
    "#print(f\"Deduplicated dataset saved to: {output_path}\")\n",
    "\n",
    "# Optional: Print removed duplicates\n",
    "original_names = set(df['1'][1:])  # Skip header row\n",
    "deduplicated_names = set(deduplicated_df['1'][1:])  # Skip header row\n",
    "removed_names = original_names - deduplicated_names\n",
    "\n",
    "if removed_names:\n",
    "    print(\"\\nRemoved duplicate entries for:\")\n",
    "    for name in removed_names:\n",
    "        print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "\n",
      "Perceived Quality Impact:\n",
      "GPT o1: n=113, Mean = 3.65, SEM = 0.09\n",
      "Vincent AI: n=113, Mean = 3.84, SEM = 0.10\n",
      "\n",
      "Perceived Speed Impact:\n",
      "GPT o1: n=113, Mean = 4.20, SEM = 0.07\n",
      "Vincent AI: n=113, Mean = 3.92, SEM = 0.11\n",
      "\n",
      "Self-Reported Satisfaction:\n",
      "GPT o1: n=113, Mean = 3.19, SEM = 0.12\n",
      "Vincent AI: n=112, Mean = 3.45, SEM = 0.12\n",
      "\n",
      "Self-Assessed Improvement:\n",
      "GPT o1: n=113, Mean = 3.13, SEM = 0.10\n",
      "Vincent AI: n=113, Mean = 3.32, SEM = 0.11\n",
      "\n",
      "Intended Future Use:\n",
      "GPT o1: n=113, Mean = 3.78, SEM = 0.10\n",
      "Vincent AI: n=113, Mean = 3.81, SEM = 0.11\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats #reimport\n",
    "\n",
    "# Use the deduplicated dataset\n",
    "numeric_data = deduplicated_df.iloc[1:].copy()\n",
    "\n",
    "# Define the question pairs with clearer self-assessment labels\n",
    "question_pairs = {\n",
    "    'Perceived Quality Impact': ('Q1', 'Q7'),\n",
    "    'Perceived Speed Impact': ('Q2', 'Q8'),\n",
    "    'Self-Reported Satisfaction': ('Q3', 'Q9'),\n",
    "    'Self-Assessed Improvement': ('Q5', 'Q10'),\n",
    "    'Intended Future Use': ('Q6', 'Q11')\n",
    "}\n",
    "\n",
    "# Data processing\n",
    "columns_to_analyze = ['Q1', 'Q2', 'Q3', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11']\n",
    "\n",
    "# Convert to numeric and handle zeros as missing values\n",
    "for col in columns_to_analyze:\n",
    "    numeric_data[col] = pd.to_numeric(numeric_data[col], errors='coerce')\n",
    "    numeric_data[col] = numeric_data[col].replace(0, np.nan)  # Convert zeros to NaN\n",
    "\n",
    "# Calculate means and standard errors for each pair\n",
    "gpt_means = []\n",
    "vincent_means = []\n",
    "gpt_sems = []\n",
    "vincent_sems = []\n",
    "n_responses = []\n",
    "\n",
    "for gpt_col, vincent_col in question_pairs.values():\n",
    "    # Calculate statistics for GPT o1\n",
    "    gpt_valid = numeric_data[gpt_col].dropna()\n",
    "    gpt_means.append(gpt_valid.mean())\n",
    "    gpt_sems.append(stats.sem(gpt_valid, nan_policy='omit'))\n",
    "    \n",
    "    # Calculate statistics for Vincent AI\n",
    "    vincent_valid = numeric_data[vincent_col].dropna()\n",
    "    vincent_means.append(vincent_valid.mean())\n",
    "    vincent_sems.append(stats.sem(vincent_valid, nan_policy='omit'))\n",
    "    \n",
    "    # Store number of valid responses\n",
    "    n_responses.append((len(gpt_valid), len(vincent_valid)))\n",
    "\n",
    "# Create figure with adjusted dimensions\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Set up positions\n",
    "x = np.arange(len(question_pairs))\n",
    "width = 0.35\n",
    "\n",
    "# Create bars with refined styling\n",
    "rects1 = ax.barh(x - width/2, gpt_means, width, label='GPT o1', \n",
    "                 color='#87CEEB',  # Lighter, more muted blue\n",
    "                 xerr=gpt_sems, capsize=3,\n",
    "                 error_kw={'elinewidth': 1.5, 'capthick': 1.5})\n",
    "rects2 = ax.barh(x + width/2, vincent_means, width, label='Vincent AI', \n",
    "                 color='#90EE90',  # Lighter, more muted green\n",
    "                 xerr=vincent_sems, capsize=3,\n",
    "                 error_kw={'elinewidth': 1.5, 'capthick': 1.5})\n",
    "\n",
    "# Add value labels with refined styling\n",
    "def add_labels(rects):\n",
    "    for rect in rects:\n",
    "        width = rect.get_width()\n",
    "        ax.text(width + 0.15, rect.get_y() + rect.get_height()/2,\n",
    "                f'{width:.2f}', ha='left', va='center',\n",
    "                fontsize=10, fontweight='bold', color='#444444')\n",
    "\n",
    "add_labels(rects1)\n",
    "add_labels(rects2)\n",
    "\n",
    "# Customize chart with refined styling\n",
    "ax.set_xlabel('Mean Self-Reported Score (1-5 scale)', fontsize=11)\n",
    "ax.set_title('Self-Reported Impact of GPT o1 vs Vincent AI', fontsize=13, pad=15)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(list(question_pairs.keys()), fontsize=10)\n",
    "\n",
    "# Set x-axis limits and ticks\n",
    "ax.set_xlim(0, max(max(gpt_means), max(vincent_means)) * 1.2)\n",
    "ax.set_xticks(np.arange(0, 5.1, 1.0))\n",
    "\n",
    "# Add refined grid\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.2, color='gray')\n",
    "\n",
    "# Customize spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(0.5)\n",
    "ax.spines['bottom'].set_linewidth(0.5)\n",
    "\n",
    "# Add legend with refined styling\n",
    "ax.legend(loc='lower right', framealpha=0.9, fontsize=10)\n",
    "\n",
    "# Add sample size note with refined styling\n",
    "min_n = min(min(n) for n in n_responses)\n",
    "max_n = max(max(n) for n in n_responses)\n",
    "if min_n != max_n:\n",
    "    plt.figtext(0.01, 0.02, f'n = {min_n}-{max_n}', fontsize=9, color='#666666')\n",
    "else:\n",
    "    plt.figtext(0.01, 0.02, f'n = {min_n}', fontsize=9, color='#666666')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "plt.savefig(os.path.join(figures_path, \"gpt_vs_vincent_self_reported_impact_comparison.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  \n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "for (metric, (gpt_col, vincent_col)), n in zip(question_pairs.items(), n_responses):\n",
    "    print(f\"\\n{metric}:\")\n",
    "    gpt_valid = numeric_data[gpt_col].dropna()\n",
    "    vincent_valid = numeric_data[vincent_col].dropna()\n",
    "    \n",
    "    print(f\"GPT o1: n={len(gpt_valid)}, Mean = {gpt_valid.mean():.2f}, SEM = {stats.sem(gpt_valid, nan_policy='omit'):.2f}\")\n",
    "    print(f\"Vincent AI: n={len(vincent_valid)}, Mean = {vincent_valid.mean():.2f}, SEM = {stats.sem(vincent_valid, nan_policy='omit'):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "\n",
      "Legal Memo:\n",
      "Vincent AI: n=41, Mean = 3.41, SEM = 0.15\n",
      "GPT o1: n=37, Mean = 3.41, SEM = 0.18\n",
      "\n",
      "Client Email:\n",
      "Vincent AI: n=37, Mean = 3.51, SEM = 0.19\n",
      "GPT o1: n=35, Mean = 3.49, SEM = 0.18\n",
      "\n",
      "Complaint Analysis:\n",
      "Vincent AI: n=35, Mean = 3.91, SEM = 0.18\n",
      "GPT o1: n=41, Mean = 3.37, SEM = 0.15\n",
      "\n",
      "NDA:\n",
      "Vincent AI: n=37, Mean = 3.30, SEM = 0.23\n",
      "GPT o1: n=35, Mean = 3.20, SEM = 0.18\n",
      "\n",
      "Motion to Consolidate:\n",
      "Vincent AI: n=41, Mean = 3.22, SEM = 0.18\n",
      "GPT o1: n=37, Mean = 3.38, SEM = 0.23\n",
      "\n",
      "Persuasive Letter:\n",
      "Vincent AI: n=35, Mean = 3.66, SEM = 0.19\n",
      "GPT o1: n=41, Mean = 3.34, SEM = 0.20\n"
     ]
    }
   ],
   "source": [
    "# Map tasks to their corresponding question columns for each AI tool\n",
    "task_columns = {\n",
    "   'Legal Memo': ('Q16', 'Q26'),         # (Vincent, GPT o1)\n",
    "   'Client Email': ('Q25', 'Q21'),       # Vincent Q25, GPT Q21\n",
    "   'Complaint Analysis': ('Q22', 'Q18'),  # Vincent Q22, GPT Q18 \n",
    "   'NDA': ('Q27', 'Q23'),               # Vincent Q27, GPT Q23\n",
    "   'Motion to Consolidate': ('Q19', 'Q28'), # Vincent Q19, GPT Q28\n",
    "   'Persuasive Letter': ('Q24', 'Q20')  # Vincent Q24, GPT Q20\n",
    "}\n",
    "\n",
    "# Data processing\n",
    "numeric_data = deduplicated_df.iloc[1:].copy()\n",
    "columns_to_analyze = [col for pair in task_columns.values() for col in pair]\n",
    "\n",
    "# Convert to numeric and handle zeros as missing values\n",
    "for col in columns_to_analyze:\n",
    "   numeric_data[col] = pd.to_numeric(numeric_data[col], errors='coerce')\n",
    "   numeric_data[col] = numeric_data[col].replace(0, np.nan)  # Convert zeros to NaN\n",
    "\n",
    "# Calculate means and standard errors for each task\n",
    "vincent_means = []\n",
    "gpt_means = []\n",
    "vincent_sems = []\n",
    "gpt_sems = []\n",
    "n_responses = []\n",
    "\n",
    "for vincent_col, gpt_col in task_columns.values():\n",
    "   # Calculate statistics for Vincent AI\n",
    "   vincent_valid = numeric_data[vincent_col].dropna()\n",
    "   vincent_means.append(vincent_valid.mean())\n",
    "   vincent_sems.append(stats.sem(vincent_valid, nan_policy='omit'))\n",
    "   \n",
    "   # Calculate statistics for GPT o1\n",
    "   gpt_valid = numeric_data[gpt_col].dropna()\n",
    "   gpt_means.append(gpt_valid.mean())\n",
    "   gpt_sems.append(stats.sem(gpt_valid, nan_policy='omit'))\n",
    "   \n",
    "   # Store number of valid responses\n",
    "   n_responses.append((len(vincent_valid), len(gpt_valid)))\n",
    "\n",
    "# Create figure with adjusted dimensions\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(task_columns))\n",
    "width = 0.35\n",
    "\n",
    "# Create bars with refined styling\n",
    "rects1 = ax.bar(x - width/2, vincent_means, width, label='Vincent AI', \n",
    "               color='#90EE90',  # Lighter, more muted green\n",
    "               yerr=vincent_sems, capsize=3,\n",
    "               error_kw={'elinewidth': 1.5, 'capthick': 1.5})\n",
    "rects2 = ax.bar(x + width/2, gpt_means, width, label='GPT o1', \n",
    "               color='#87CEEB',  # Lighter, more muted blue\n",
    "               yerr=gpt_sems, capsize=3,\n",
    "               error_kw={'elinewidth': 1.5, 'capthick': 1.5})\n",
    "\n",
    "# Add value labels with refined styling and increased vertical offset\n",
    "def add_labels(rects):\n",
    "   for rect in rects:\n",
    "       height = rect.get_height()\n",
    "       ax.text(rect.get_x() + rect.get_width()/2, height + 0.25,\n",
    "               f'{height:.2f}', ha='center', va='bottom',\n",
    "               fontsize=10, fontweight='bold', color='#444444')\n",
    "\n",
    "add_labels(rects1)\n",
    "add_labels(rects2)\n",
    "\n",
    "# Customize chart with refined styling\n",
    "ax.set_ylabel('Self-reported Helpfulness of AI Tools (1-5 scale)', fontsize=11)\n",
    "ax.set_title('Perceived Helpfulness by Task and AI Tool', fontsize=13, pad=15)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(task_columns.keys(), rotation=30, ha='right', fontsize=10)\n",
    "\n",
    "# Set y-axis limits and ticks\n",
    "ax.set_ylim(0, 5.2)  # Increased upper limit to accommodate higher labels\n",
    "ax.set_yticks(np.arange(0, 5.1, 1.0))\n",
    "\n",
    "# Add refined grid\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.2, color='gray')\n",
    "\n",
    "# Customize spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(0.5)\n",
    "ax.spines['bottom'].set_linewidth(0.5)\n",
    "\n",
    "# Add legend with refined styling\n",
    "ax.legend(loc='upper right', framealpha=0.9, fontsize=10)\n",
    "\n",
    "# Add sample size note with refined styling\n",
    "min_n = min(min(n) for n in n_responses)\n",
    "max_n = max(max(n) for n in n_responses)\n",
    "if min_n != max_n:\n",
    "   plt.figtext(0.01, 0.02, f'n = {min_n}-{max_n}', fontsize=9, color='#666666')\n",
    "else:\n",
    "   plt.figtext(0.01, 0.02, f'n = {min_n}', fontsize=9, color='#666666')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "plt.savefig(os.path.join(figures_path, \"gpt_vs_vincent_perceived_helpfulness.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  \n",
    "\n",
    "# Print detailed summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "for (task, (vincent_col, gpt_col)), n in zip(task_columns.items(), n_responses):\n",
    "   print(f\"\\n{task}:\")\n",
    "   vincent_valid = numeric_data[vincent_col].dropna()\n",
    "   gpt_valid = numeric_data[gpt_col].dropna()\n",
    "   \n",
    "   print(f\"Vincent AI: n={len(vincent_valid)}, Mean = {vincent_valid.mean():.2f}, SEM = {stats.sem(vincent_valid, nan_policy='omit'):.2f}\")\n",
    "   print(f\"GPT o1: n={len(gpt_valid)}, Mean = {gpt_valid.mean():.2f}, SEM = {stats.sem(gpt_valid, nan_policy='omit'):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
